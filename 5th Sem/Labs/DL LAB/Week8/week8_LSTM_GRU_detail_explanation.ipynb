{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Refer:\n",
        "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
        "\n",
        "and\n",
        "https://www.youtube.com/watch?v=f-JCCOHwx1c"
      ],
      "metadata": {
        "id": "XaaqtWDacTj7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NINKdU3_LBGu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#learn the extrac and load part now just direct downloading\n",
        "!!curl -O http://www.manythings.org/anki/hin-eng.zip\n",
        "!!unzip hin-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDet7MhSZZW_",
        "outputId": "75d10e79-e152-4599-dcf0-c4cbc050aa09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Archive:  hin-eng.zip',\n",
              " '  inflating: hin.txt                 ',\n",
              " '  inflating: _about.txt              ']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=256\n",
        "epochs=300\n",
        "latent_dim=64\n",
        "num_samples=900\n",
        "data_path='/content/hin.txt'\n",
        "#In an LSTM, the hidden state is a vector that holds information about the sequence it has processed so far. The latent dimension specifies the length of this vector.\n",
        "#For example, if the latent dimension is set to 64, each LSTM cell's hidden state is represented as a 64-dimensional vector at every time step"
      ],
      "metadata": {
        "id": "7h01eEudZhm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = []#to hold all input texts(eng)\n",
        "target_texts = []#to hold all output texts(hin)\n",
        "#both to get the unique in each\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path,'r',encoding = 'utf-8') as f:\n",
        "  lines = f.read().split('\\n')#reading all lines\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines)-1)]:\n",
        "  #for each line take the input text and target text then for each add the unique characters\n",
        "  input_text,target_text,_ = line.split('\\t') #so divide based on a tab space one at end is there ignore that\n",
        "  #Now to the target_text i.e hinde add start and end with \\t and \\n so can easily identify\n",
        "  target_text = '\\t' + target_text + '\\n'\n",
        "\n",
        "  #now append\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "\n",
        "  #now append the characters and only the unique ones\n",
        "  for char in input_text:\n",
        "    if char not in input_characters:\n",
        "      input_characters.add(char)#add as set\n",
        "  for char in target_text:#same for target text\n",
        "    if char not in target_characters:\n",
        "      target_characters.add(char)"
      ],
      "metadata": {
        "id": "b9GtVvY7aF_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oimkBThvcvtk",
        "outputId": "4496de3f-56e4-4862-cad1-b36e0922178e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow!',\n",
              " 'Duck!',\n",
              " 'Duck!',\n",
              " 'Help!',\n",
              " 'Jump.',\n",
              " 'Jump.',\n",
              " 'Jump.',\n",
              " 'Hello!',\n",
              " 'Hello!',\n",
              " 'Cheers!',\n",
              " 'Cheers!',\n",
              " 'Exhale.',\n",
              " 'Exhale.',\n",
              " 'Got it?',\n",
              " \"I'm OK.\",\n",
              " 'Inhale.',\n",
              " 'Inhale.',\n",
              " 'Thanks!',\n",
              " 'We won.',\n",
              " 'Awesome!']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters#all the unique characters in the input texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smy2JIXjc9XJ",
        "outputId": "85f2df81-da96-4a39-df06-4713df032a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " '!',\n",
              " '\"',\n",
              " \"'\",\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '3',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'W',\n",
              " 'Y',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '€'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_texts[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4xlOub3dERb",
        "outputId": "d7d0feec-765c-47ce-bf83-121d7474f14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\tवाह!\\n',\n",
              " '\\tझुको!\\n',\n",
              " '\\tबतख़!\\n',\n",
              " '\\tबचाओ!\\n',\n",
              " '\\tउछलो.\\n',\n",
              " '\\tकूदो.\\n',\n",
              " '\\tछलांग.\\n',\n",
              " '\\tनमस्ते।\\n',\n",
              " '\\tनमस्कार।\\n',\n",
              " '\\tवाह-वाह!\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy0tPR0-dMp9",
        "outputId": "a0a18ed7-752e-4f08-96e9-4fbb3b1bc7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\t',\n",
              " '\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '7',\n",
              " '9',\n",
              " '?',\n",
              " 'I',\n",
              " 'ँ',\n",
              " 'ं',\n",
              " 'अ',\n",
              " 'आ',\n",
              " 'इ',\n",
              " 'ई',\n",
              " 'उ',\n",
              " 'ऊ',\n",
              " 'ए',\n",
              " 'ऐ',\n",
              " 'ओ',\n",
              " 'औ',\n",
              " 'क',\n",
              " 'ख',\n",
              " 'ग',\n",
              " 'घ',\n",
              " 'च',\n",
              " 'छ',\n",
              " 'ज',\n",
              " 'झ',\n",
              " 'ञ',\n",
              " 'ट',\n",
              " 'ठ',\n",
              " 'ड',\n",
              " 'ढ',\n",
              " 'ण',\n",
              " 'त',\n",
              " 'थ',\n",
              " 'द',\n",
              " 'ध',\n",
              " 'न',\n",
              " 'प',\n",
              " 'फ',\n",
              " 'ब',\n",
              " 'भ',\n",
              " 'म',\n",
              " 'य',\n",
              " 'र',\n",
              " 'ल',\n",
              " 'व',\n",
              " 'श',\n",
              " 'ष',\n",
              " 'स',\n",
              " 'ह',\n",
              " '़',\n",
              " 'ा',\n",
              " 'ि',\n",
              " 'ी',\n",
              " 'ु',\n",
              " 'ू',\n",
              " 'ृ',\n",
              " 'ॅ',\n",
              " 'े',\n",
              " 'ै',\n",
              " 'ॉ',\n",
              " 'ो',\n",
              " 'ौ',\n",
              " '्',\n",
              " '।',\n",
              " '०',\n",
              " '१',\n",
              " '५',\n",
              " '६',\n",
              " '७',\n",
              " '८',\n",
              " '९',\n",
              " '€'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Turn the sentences into 3 Numpy arrays,\n",
        "\n",
        "encoder_input_data, decoder_input_data, decoder_target_data:\n",
        "\n",
        "encoder_input_data is a 3D array of shape (num_pairs, max_english_sentence_length, num_english_characters) containing a one-hot vectorization of the English sentences.\n",
        "\n",
        "decoder_input_data is a 3D array of shape (num_pairs, max_french_sentence_length, num_french_characters) containg a one-hot vectorization of the French sentences.\n",
        "\n",
        "decoder_target_data is the same as decoder_input_data but offset by one timestep. decoder_target_data[:, t, :] will be the same as decoder_input_data[:, t + 1, :]."
      ],
      "metadata": {
        "id": "fAHozAq5d-50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "#so sort both\n",
        "\n",
        "num_encoder_tokens = len(input_characters)#so len of unique\n",
        "num_decoder_tokens = len(target_characters)\n",
        "\n",
        "#so get the max length of both\n",
        "max_encoder_seq_length = max([len(x) for x in input_texts])\n",
        "max_decoder_seq_length = max([len(x) for x in target_texts])\n",
        "\n",
        "#so all these are required for representing encoder input,decoder input and decoder target also"
      ],
      "metadata": {
        "id": "lVPlnrFjdPNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_samples)#this is the num of pairs\n",
        "print(num_encoder_tokens) #this is num_engilish_characters\n",
        "print(num_decoder_tokens) #this is num_hindi_characters\n",
        "print(max_encoder_seq_length)#this is max english sentence length\n",
        "print(max_decoder_seq_length)#of hindi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nvCCaL4d-DX",
        "outputId": "ff3b330e-bcab-460f-8a67-56eef2530915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900\n",
            "66\n",
            "81\n",
            "24\n",
            "60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we associate each char the index and make a dict\n",
        "input_token_dict = dict(\n",
        "    [(char,i) for i,char in enumerate(input_characters)]\n",
        ")\n",
        "\n",
        "target_token_dict = dict(\n",
        "    [(char,i) for i,char in enumerate(target_characters)]\n",
        ")\n",
        "input_token_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fxu4pK5enS1",
        "outputId": "46f724b5-a5e1-49f6-c2dc-75e04c06ebc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '!': 1,\n",
              " '\"': 2,\n",
              " \"'\": 3,\n",
              " ',': 4,\n",
              " '-': 5,\n",
              " '.': 6,\n",
              " '0': 7,\n",
              " '1': 8,\n",
              " '3': 9,\n",
              " '5': 10,\n",
              " '6': 11,\n",
              " '7': 12,\n",
              " '8': 13,\n",
              " '9': 14,\n",
              " ':': 15,\n",
              " '?': 16,\n",
              " 'A': 17,\n",
              " 'B': 18,\n",
              " 'C': 19,\n",
              " 'D': 20,\n",
              " 'E': 21,\n",
              " 'F': 22,\n",
              " 'G': 23,\n",
              " 'H': 24,\n",
              " 'I': 25,\n",
              " 'J': 26,\n",
              " 'K': 27,\n",
              " 'L': 28,\n",
              " 'M': 29,\n",
              " 'N': 30,\n",
              " 'O': 31,\n",
              " 'P': 32,\n",
              " 'R': 33,\n",
              " 'S': 34,\n",
              " 'T': 35,\n",
              " 'U': 36,\n",
              " 'W': 37,\n",
              " 'Y': 38,\n",
              " 'a': 39,\n",
              " 'b': 40,\n",
              " 'c': 41,\n",
              " 'd': 42,\n",
              " 'e': 43,\n",
              " 'f': 44,\n",
              " 'g': 45,\n",
              " 'h': 46,\n",
              " 'i': 47,\n",
              " 'j': 48,\n",
              " 'k': 49,\n",
              " 'l': 50,\n",
              " 'm': 51,\n",
              " 'n': 52,\n",
              " 'o': 53,\n",
              " 'p': 54,\n",
              " 'q': 55,\n",
              " 'r': 56,\n",
              " 's': 57,\n",
              " 't': 58,\n",
              " 'u': 59,\n",
              " 'v': 60,\n",
              " 'w': 61,\n",
              " 'x': 62,\n",
              " 'y': 63,\n",
              " 'z': 64,\n",
              " '€': 65}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now to do the representation of 3d for each first put all zeros that above wala refer to see for each ka\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype = 'float32'\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(target_texts), max_decoder_seq_length,num_decoder_tokens),\n",
        "    dtype = 'float32'\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(target_texts), max_decoder_seq_length,num_decoder_tokens),\n",
        "    dtype = 'float32'\n",
        ")#this is same as decoder input just change is in offset this is decoder output actually"
      ],
      "metadata": {
        "id": "lfcyCpsNfXkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now do the one hot encoding so for each char in input text in that i of input text we go on to put 1 same for target text also\n",
        "\n",
        "for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)): #so enumerate gives us index just that\n",
        "  for t,char in enumerate(input_text): #here t is index and char is actual char in the input_text\n",
        "    #so just at that pos put 1 in the encoder_input_data\n",
        "    encoder_input_data[i,t,input_token_dict[char]] = 1 #so use of dict which we created above used here\n",
        "  #once done then a space where is there there we put 1\n",
        "  encoder_input_data[i,t+1:,input_token_dict[' ']] = 1\n",
        "\n",
        "  #now for decoder\n",
        "  for t,char in enumerate(target_text):\n",
        "    decoder_input_data[i,t,target_token_dict[char]] = 1\n",
        "    #now for the target of decoder which is ahead and wont contain the start token\n",
        "    if t > 0:\n",
        "      decoder_target_data[i,t-1,target_token_dict[char]] = 1\n",
        "  #once done then a space\n",
        "  decoder_input_data[i,t+1:,target_token_dict[' ']] = 1\n",
        "  decoder_target_data[i,t:,target_token_dict[' ']] = 1\n",
        "\n",
        "#basically it is for each sequence(input) for each char the one hot encoding of it wrt the input_token_dict meaning each char ohe of unique input characters"
      ],
      "metadata": {
        "id": "T8GnnIhNgpS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your approach to performing one-hot encoding for `encoder_input_data`, `decoder_input_data`, and `decoder_target_data` looks conceptually correct. However, I'll walk you through the logic to ensure everything is clear and address any potential issues.\n",
        "\n",
        "### Explanation of Your Code:\n",
        "1. **Enumerating `input_texts` and `target_texts`**:\n",
        "   - `for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):`:\n",
        "     - `i` is the index for each sentence pair.\n",
        "     - `input_text` is the source (Hindi) sentence.\n",
        "     - `target_text` is the target (English) sentence.\n",
        "   \n",
        "2. **One-Hot Encoding `encoder_input_data`**:\n",
        "   - `for t, char in enumerate(input_text):`:\n",
        "     - `t` is the index for each character in `input_text`.\n",
        "     - `char` is the character at position `t` in `input_text`.\n",
        "   - `encoder_input_data[i, t, input_token_dict[char]] = 1`:\n",
        "     - Sets the position `(i, t, input_token_dict[char])` in `encoder_input_data` to 1, where `input_token_dict` maps each character to its index in the character set.\n",
        "\n",
        "   - `encoder_input_data[i, t+1:, input_token_dict[' ']] = 1`:\n",
        "     - This fills the remaining positions after the last character in `input_text` with the one-hot encoding for a space character. This step pads sequences with spaces, which may not be needed unless specifically required by your model setup.\n",
        "\n",
        "3. **One-Hot Encoding `decoder_input_data` and `decoder_target_data`**:\n",
        "   - `for t, char in enumerate(target_text):`:\n",
        "     - Similar to the encoder loop, `t` is the index, and `char` is the character at position `t` in `target_text`.\n",
        "   - `decoder_input_data[i, t, target_token_dict[char]] = 1`:\n",
        "     - Sets the position `(i, t, target_token_dict[char])` in `decoder_input_data` to 1.\n",
        "   - `if t > 0: decoder_target_data[i, t-1, target_token_dict[char]] = 1`:\n",
        "     - Offsets the one-hot assignment by one position for `decoder_target_data`, ensuring that the output target is one step ahead (for teacher forcing during training).\n",
        "   - `decoder_input_data[i, t+1:, target_token_dict[' ']] = 1` and `decoder_target_data[i, t:, target_token_dict[' ']] = 1`:\n",
        "     - These lines fill the remaining positions after the last character with the one-hot encoding for a space character, similar to the encoder padding.\n",
        "\n",
        "### Points to Consider:\n",
        "- **Padding with Spaces**: Adding spaces (`' '`) to pad sequences may or may not be necessary depending on how your model handles padding. Ensure that your model architecture can process padded sequences correctly, or use an appropriate masking mechanism.\n",
        "- **Boundary Conditions**: Check that `t + 1:` does not exceed the predefined maximum length of `encoder_input_data` and `decoder_input_data`. This is generally controlled by the maximum length of your sequences.\n",
        "- **Efficiency**: Filling all remaining positions with a space after the last character works but may be unnecessary if you handle padding differently (e.g., using `numpy`'s default zero padding).\n",
        "\n",
        "### Correctness:\n",
        "The logic in your code is sound for creating one-hot encoded data matrices for training a seq2seq model. It maps each character in `input_texts` and `target_texts` to its respective one-hot position. Make sure your dictionaries (`input_token_dict` and `target_token_dict`) cover all unique characters in `input_texts` and `target_texts` for smooth operation.\n",
        "\n",
        "### Suggestion:\n",
        "If you're certain that your model does not need trailing spaces filled after the last character, you could remove the `t+1:` lines for a cleaner approach. If padding is required, using `' '` as a placeholder is fine as long as your tokenizer and model know how to handle it."
      ],
      "metadata": {
        "id": "Ghtq6E_gjZ9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4LzpRUGixVM",
        "outputId": "19b37669-c3b7-4116-abda-65b2bc8fab91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now Define the encoder and decoder\n",
        "##### Train a basic LSTM-based Seq2Seq model to predict decoder_target_data given encoder_input_data and decoder_input_data. Our model uses teacher forcing.\n",
        "\n",
        "This is our training model. It leverages three key features of Keras RNNs:\n",
        "\n",
        "The return_state contructor argument, configuring a RNN layer to return a list where the first entry is the outputs and the next entries are the internal RNN states. This is used to recover the states of the encoder.\n",
        "\n",
        "The inital_state call argument, specifying the initial state(s) of a RNN. This is used to pass the encoder states to the decoder as initial states.\n",
        "\n",
        "The return_sequences constructor argument, configuring a RNN to return its full sequence of outputs (instead of just the last output, which the defaults behavior). This is used in the decoder."
      ],
      "metadata": {
        "id": "Taz-ydKBjn0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,LSTM,Dense\n",
        "\n",
        "encoder_inputs = Input(shape = (None,num_encoder_tokens))#says take varied input length but each char has num_econder_tokens basically each char is ohe so\n",
        "\n",
        "encoder = LSTM(latent_dim,return_state=True)\n",
        "#so here latent dim i.e to have that many neurnons basically what we put as normal neurons as 32 and all\n",
        "#no return sequences as output we dont need and return_state = True so to get the last state from lstm\n",
        "encoder_outputs,state_h,state_c = encoder(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h,state_c] #so dont need encoder outputs so only this\n",
        "\n",
        "decoder_inputs = Input(shape = (None, num_decoder_tokens)) #same here decoder i.e ohe with unique decoder characters\n",
        "\n",
        "decoder = LSTM(latent_dim,return_sequences=True,return_state=True) #here return seq also as we need to get each step output\n",
        "\n",
        "decoder_outputs,_,_ = decoder(decoder_inputs,initial_state = encoder_states)#so here we need only decoder_outputs and\n",
        "#The LSTM is initialized with the encoder's final hidden and cell states. This step allows the decoder to start its predictions with the context\n",
        "#provided by the encoder.\n",
        "\n",
        "decoder_dense = Dense(num_decoder_tokens,activation = 'softmax')#so since any among the unique target ka we do that and softmax\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n"
      ],
      "metadata": {
        "id": "APyOPVmejgKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Let's break down the code block step by step, as it describes the architecture for the **encoder-decoder model** using LSTM layers, which is typically used for **sequence-to-sequence (seq2seq) tasks**, such as machine translation.\n",
        "\n",
        "### 1. Encoder Setup\n",
        "```python\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "```\n",
        "- **`Input` Layer**: Defines the input layer for the encoder. The input shape is `(None, num_encoder_tokens)`, meaning it expects variable-length sequences (`None` for the time dimension) where each time step has `num_encoder_tokens` features (one-hot encoded vectors for each character in the input sentence).\n",
        "- This is the placeholder for the input data that will be fed into the model.\n",
        "\n",
        "```python\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "```\n",
        "- **`LSTM` Layer**: The LSTM layer for the encoder has a `latent_dim` size, which specifies the number of units (neurons) in the LSTM cell.\n",
        "- **`return_state=True`**: Indicates that the LSTM layer should return its last hidden state (`state_h`) and cell state (`state_c`). This is crucial for passing information from the encoder to the decoder.\n",
        "- **Outputs**:\n",
        "  - `encoder_outputs`: The LSTM outputs for each time step (not used here).\n",
        "  - `state_h`: The last hidden state of the LSTM.\n",
        "  - `state_c`: The last cell state of the LSTM.\n",
        "- **Purpose**: The hidden state and cell state capture the context of the input sequence and are passed to the decoder to initialize it.\n",
        "\n",
        "```python\n",
        "encoder_states = [state_h, state_c]\n",
        "```\n",
        "- **Encoder States**: The final hidden state and cell state are stored in `encoder_states`, which will be used to initialize the decoder's LSTM layer. These states represent the \"context vector\" and summarize the input sequence information.\n",
        "\n",
        "### 2. Decoder Setup\n",
        "```python\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "```\n",
        "- **`Input` Layer**: Defines the input for the decoder. The shape `(None, num_decoder_tokens)` means it takes variable-length sequences as input, where each time step has `num_decoder_tokens` features (one-hot encoded vectors for each character in the target sentence).\n",
        "- This layer is the placeholder for the target data fed into the model during training (typically shifted sequences of the target).\n",
        "\n",
        "```python\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "```\n",
        "- **`LSTM` Layer for Decoder**:\n",
        "  - The `decoder_lstm` is an LSTM layer with the same `latent_dim` size as the encoder.\n",
        "  - **`return_sequences=True`**: Ensures that the decoder outputs the full sequence of predictions at each time step.\n",
        "  - **`return_state=True`**: The decoder LSTM returns not only the output sequence but also its last hidden and cell states. However, these states (`_, _`) are not used during training but are needed during inference for generating subsequent sequences.\n",
        "  - **`initial_state=encoder_states`**: The LSTM is initialized with the encoder's final hidden and cell states. This step allows the decoder to start its predictions with the context provided by the encoder.\n",
        "\n",
        "```python\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "```\n",
        "- **`Dense` Layer**:\n",
        "  - A fully connected (`Dense`) layer is applied to each time step of the decoder's output.\n",
        "  - **`num_decoder_tokens`**: The number of output units matches the number of possible tokens (characters or words) in the target language.\n",
        "  - **`activation='softmax'`**: Applies a softmax activation function to output probabilities for each possible token, ensuring that each time step's output is a probability distribution over the target vocabulary.\n",
        "\n",
        "### Summary:\n",
        "- **Encoder**:\n",
        "  - Processes the input sequence and returns its last hidden and cell states (`state_h`, `state_c`).\n",
        "- **Decoder**:\n",
        "  - Takes the target sequence (shifted by one step) as input and uses the encoder's final states as its initial states.\n",
        "  - Produces output sequences by predicting the next token at each time step.\n",
        "  - Outputs from the `Dense` layer represent probabilities for each token in the target language.\n",
        "\n",
        "### Key Concepts:\n",
        "- **Encoder-Decoder Model**: A type of seq2seq model where the encoder summarizes the input into a context vector (hidden states), and the decoder generates the output sequence based on this context.\n",
        "- **Latent Dimension**: Specifies the size of the LSTM's hidden states, controlling the model's capacity.\n",
        "- **Teacher Forcing (During Training)**: The decoder receives the actual previous token from the target sequence to predict the next token, enhancing training stability."
      ],
      "metadata": {
        "id": "bnhYInr2nbPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs,decoder_inputs],decoder_outputs)#then create the model using Model api with input and outputs\n",
        "\n",
        "#now compile\n",
        "model.compile(optimizer = 'rmsprop', loss ='categorical_crossentropy',metrics = ['accuracy'])\n",
        "#since each as ohe and many outputs we do categorical crossentory\n",
        "\n",
        "history = model.fit([encoder_input_data,decoder_input_data],decoder_target_data,batch_size = batch_size,epochs = epochs,validation_split = 0.2)\n",
        "#so fit the model with the data\n",
        "\n",
        "#save the model\n",
        "model.save('s2s_rms_prop.h5')\n",
        "\n",
        "#plot of the model\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.plot(history.history['loss'],label = 'training loss')\n",
        "plt.plot(history.history['val_loss'],label = 'validation loss')\n",
        "plt.title('loss vs epochs')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Up5zb7LvnV5w",
        "outputId": "b52065ab-fa4e-413a-cbcc-a88118d65e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - accuracy: 0.0946 - loss: 4.3558 - val_accuracy: 0.6269 - val_loss: 4.1835\n",
            "Epoch 2/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7007 - loss: 4.0625 - val_accuracy: 0.6373 - val_loss: 3.6211\n",
            "Epoch 3/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7073 - loss: 3.2676 - val_accuracy: 0.6375 - val_loss: 2.6701\n",
            "Epoch 4/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7049 - loss: 2.3342 - val_accuracy: 0.6375 - val_loss: 2.2378\n",
            "Epoch 5/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7094 - loss: 1.8903 - val_accuracy: 0.6375 - val_loss: 2.0753\n",
            "Epoch 6/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7067 - loss: 1.7342 - val_accuracy: 0.6375 - val_loss: 2.0073\n",
            "Epoch 7/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7078 - loss: 1.6544 - val_accuracy: 0.6375 - val_loss: 1.9633\n",
            "Epoch 8/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7071 - loss: 1.6109 - val_accuracy: 0.6375 - val_loss: 1.9274\n",
            "Epoch 9/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7084 - loss: 1.5698 - val_accuracy: 0.6375 - val_loss: 1.8902\n",
            "Epoch 10/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7078 - loss: 1.5381 - val_accuracy: 0.6375 - val_loss: 1.8516\n",
            "Epoch 11/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7047 - loss: 1.5310 - val_accuracy: 0.6375 - val_loss: 1.9435\n",
            "Epoch 12/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7067 - loss: 1.5444 - val_accuracy: 0.6375 - val_loss: 1.8250\n",
            "Epoch 13/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7066 - loss: 1.4821 - val_accuracy: 0.6375 - val_loss: 1.7961\n",
            "Epoch 14/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7050 - loss: 1.4634 - val_accuracy: 0.6375 - val_loss: 1.8169\n",
            "Epoch 15/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7090 - loss: 1.4954 - val_accuracy: 0.6375 - val_loss: 1.8327\n",
            "Epoch 16/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7063 - loss: 1.4647 - val_accuracy: 0.6375 - val_loss: 1.7667\n",
            "Epoch 17/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7092 - loss: 1.4158 - val_accuracy: 0.6375 - val_loss: 1.7474\n",
            "Epoch 18/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 1.3953 - val_accuracy: 0.6375 - val_loss: 1.7971\n",
            "Epoch 19/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7063 - loss: 1.4633 - val_accuracy: 0.6375 - val_loss: 1.7255\n",
            "Epoch 20/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7078 - loss: 1.3853 - val_accuracy: 0.6375 - val_loss: 1.7233\n",
            "Epoch 21/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7029 - loss: 1.4410 - val_accuracy: 0.6375 - val_loss: 1.7124\n",
            "Epoch 22/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7032 - loss: 1.3915 - val_accuracy: 0.6375 - val_loss: 1.6897\n",
            "Epoch 23/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7077 - loss: 1.3520 - val_accuracy: 0.6375 - val_loss: 1.6782\n",
            "Epoch 24/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7082 - loss: 1.3832 - val_accuracy: 0.6375 - val_loss: 1.8039\n",
            "Epoch 25/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7084 - loss: 1.3886 - val_accuracy: 0.6375 - val_loss: 1.6626\n",
            "Epoch 26/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7089 - loss: 1.3267 - val_accuracy: 0.6375 - val_loss: 1.6448\n",
            "Epoch 27/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7040 - loss: 1.3323 - val_accuracy: 0.6375 - val_loss: 1.6362\n",
            "Epoch 28/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7047 - loss: 1.3607 - val_accuracy: 0.6375 - val_loss: 1.7337\n",
            "Epoch 29/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7054 - loss: 1.3558 - val_accuracy: 0.6375 - val_loss: 1.6216\n",
            "Epoch 30/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7092 - loss: 1.2957 - val_accuracy: 0.6375 - val_loss: 1.6304\n",
            "Epoch 31/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7073 - loss: 1.2981 - val_accuracy: 0.6375 - val_loss: 1.6075\n",
            "Epoch 32/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7074 - loss: 1.3157 - val_accuracy: 0.6375 - val_loss: 1.6478\n",
            "Epoch 33/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7094 - loss: 1.2806 - val_accuracy: 0.6375 - val_loss: 1.5886\n",
            "Epoch 34/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7052 - loss: 1.2837 - val_accuracy: 0.6375 - val_loss: 1.6152\n",
            "Epoch 35/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7062 - loss: 1.2854 - val_accuracy: 0.6380 - val_loss: 1.6127\n",
            "Epoch 36/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7070 - loss: 1.3036 - val_accuracy: 0.6387 - val_loss: 1.5956\n",
            "Epoch 37/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7110 - loss: 1.2545 - val_accuracy: 0.6405 - val_loss: 1.5633\n",
            "Epoch 38/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7155 - loss: 1.2425 - val_accuracy: 0.6405 - val_loss: 1.5897\n",
            "Epoch 39/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7130 - loss: 1.2575 - val_accuracy: 0.6405 - val_loss: 1.5710\n",
            "Epoch 40/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7117 - loss: 1.2747 - val_accuracy: 0.6405 - val_loss: 1.5813\n",
            "Epoch 41/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7120 - loss: 1.2427 - val_accuracy: 0.6406 - val_loss: 1.5438\n",
            "Epoch 42/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7143 - loss: 1.2353 - val_accuracy: 0.6406 - val_loss: 1.5688\n",
            "Epoch 43/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7146 - loss: 1.2300 - val_accuracy: 0.6410 - val_loss: 1.5390\n",
            "Epoch 44/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7101 - loss: 1.2511 - val_accuracy: 0.6410 - val_loss: 1.5642\n",
            "Epoch 45/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7146 - loss: 1.2214 - val_accuracy: 0.6410 - val_loss: 1.5310\n",
            "Epoch 46/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7125 - loss: 1.2407 - val_accuracy: 0.6410 - val_loss: 1.5487\n",
            "Epoch 47/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7118 - loss: 1.2254 - val_accuracy: 0.6410 - val_loss: 1.5205\n",
            "Epoch 48/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7123 - loss: 1.2129 - val_accuracy: 0.6410 - val_loss: 1.5163\n",
            "Epoch 49/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7141 - loss: 1.2031 - val_accuracy: 0.6410 - val_loss: 1.5428\n",
            "Epoch 50/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7129 - loss: 1.2247 - val_accuracy: 0.6369 - val_loss: 1.5537\n",
            "Epoch 51/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7115 - loss: 1.2404 - val_accuracy: 0.6410 - val_loss: 1.5118\n",
            "Epoch 52/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7140 - loss: 1.1924 - val_accuracy: 0.6410 - val_loss: 1.5063\n",
            "Epoch 53/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7142 - loss: 1.1898 - val_accuracy: 0.6410 - val_loss: 1.5065\n",
            "Epoch 54/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7113 - loss: 1.2012 - val_accuracy: 0.6407 - val_loss: 1.5128\n",
            "Epoch 55/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7115 - loss: 1.2133 - val_accuracy: 0.6410 - val_loss: 1.5161\n",
            "Epoch 56/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7147 - loss: 1.1900 - val_accuracy: 0.6411 - val_loss: 1.4895\n",
            "Epoch 57/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7129 - loss: 1.1867 - val_accuracy: 0.6410 - val_loss: 1.4950\n",
            "Epoch 58/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7102 - loss: 1.1929 - val_accuracy: 0.6407 - val_loss: 1.4880\n",
            "Epoch 59/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7133 - loss: 1.1876 - val_accuracy: 0.6410 - val_loss: 1.5654\n",
            "Epoch 60/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7116 - loss: 1.2142 - val_accuracy: 0.6411 - val_loss: 1.4809\n",
            "Epoch 61/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7132 - loss: 1.1724 - val_accuracy: 0.6411 - val_loss: 1.4822\n",
            "Epoch 62/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7116 - loss: 1.1769 - val_accuracy: 0.6411 - val_loss: 1.4787\n",
            "Epoch 63/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7141 - loss: 1.1652 - val_accuracy: 0.6410 - val_loss: 1.4850\n",
            "Epoch 64/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7141 - loss: 1.1681 - val_accuracy: 0.6326 - val_loss: 1.4840\n",
            "Epoch 65/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7119 - loss: 1.1732 - val_accuracy: 0.6410 - val_loss: 1.4774\n",
            "Epoch 66/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7123 - loss: 1.1719 - val_accuracy: 0.6397 - val_loss: 1.4722\n",
            "Epoch 67/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7142 - loss: 1.1588 - val_accuracy: 0.6410 - val_loss: 1.4749\n",
            "Epoch 68/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7123 - loss: 1.1654 - val_accuracy: 0.6399 - val_loss: 1.4654\n",
            "Epoch 69/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7116 - loss: 1.1627 - val_accuracy: 0.6409 - val_loss: 1.4776\n",
            "Epoch 70/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7133 - loss: 1.1555 - val_accuracy: 0.6403 - val_loss: 1.4583\n",
            "Epoch 71/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7124 - loss: 1.1567 - val_accuracy: 0.6409 - val_loss: 1.4636\n",
            "Epoch 72/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7113 - loss: 1.1598 - val_accuracy: 0.6375 - val_loss: 1.4602\n",
            "Epoch 73/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7102 - loss: 1.1586 - val_accuracy: 0.6411 - val_loss: 1.4671\n",
            "Epoch 74/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7131 - loss: 1.1481 - val_accuracy: 0.6355 - val_loss: 1.4518\n",
            "Epoch 75/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7094 - loss: 1.1615 - val_accuracy: 0.6405 - val_loss: 1.4665\n",
            "Epoch 76/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7123 - loss: 1.1478 - val_accuracy: 0.6399 - val_loss: 1.4446\n",
            "Epoch 77/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7119 - loss: 1.1454 - val_accuracy: 0.6409 - val_loss: 1.4528\n",
            "Epoch 78/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7128 - loss: 1.1404 - val_accuracy: 0.6311 - val_loss: 1.4680\n",
            "Epoch 79/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7093 - loss: 1.1584 - val_accuracy: 0.6413 - val_loss: 1.4534\n",
            "Epoch 80/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7130 - loss: 1.1339 - val_accuracy: 0.6397 - val_loss: 1.4330\n",
            "Epoch 81/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7107 - loss: 1.1443 - val_accuracy: 0.6418 - val_loss: 1.4463\n",
            "Epoch 82/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7144 - loss: 1.1251 - val_accuracy: 0.6405 - val_loss: 1.4318\n",
            "Epoch 83/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7138 - loss: 1.1266 - val_accuracy: 0.6416 - val_loss: 1.4490\n",
            "Epoch 84/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7126 - loss: 1.1375 - val_accuracy: 0.6393 - val_loss: 1.4366\n",
            "Epoch 85/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7126 - loss: 1.1320 - val_accuracy: 0.6410 - val_loss: 1.4257\n",
            "Epoch 86/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7171 - loss: 1.1116 - val_accuracy: 0.6423 - val_loss: 1.4346\n",
            "Epoch 87/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7151 - loss: 1.1142 - val_accuracy: 0.6424 - val_loss: 1.4237\n",
            "Epoch 88/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7136 - loss: 1.1242 - val_accuracy: 0.6410 - val_loss: 1.5597\n",
            "Epoch 89/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7117 - loss: 1.2160 - val_accuracy: 0.6413 - val_loss: 1.4504\n",
            "Epoch 90/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7134 - loss: 1.1205 - val_accuracy: 0.6419 - val_loss: 1.4348\n",
            "Epoch 91/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7138 - loss: 1.1130 - val_accuracy: 0.6424 - val_loss: 1.4289\n",
            "Epoch 92/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7145 - loss: 1.1117 - val_accuracy: 0.6425 - val_loss: 1.4257\n",
            "Epoch 93/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7167 - loss: 1.1041 - val_accuracy: 0.6431 - val_loss: 1.4233\n",
            "Epoch 94/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7152 - loss: 1.1054 - val_accuracy: 0.6437 - val_loss: 1.4199\n",
            "Epoch 95/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7158 - loss: 1.1051 - val_accuracy: 0.6459 - val_loss: 1.4195\n",
            "Epoch 96/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7185 - loss: 1.0965 - val_accuracy: 0.6459 - val_loss: 1.4182\n",
            "Epoch 97/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7173 - loss: 1.0991 - val_accuracy: 0.6440 - val_loss: 1.4109\n",
            "Epoch 98/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7150 - loss: 1.1051 - val_accuracy: 0.6491 - val_loss: 1.4233\n",
            "Epoch 99/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7209 - loss: 1.0956 - val_accuracy: 0.6416 - val_loss: 1.4004\n",
            "Epoch 100/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7174 - loss: 1.0966 - val_accuracy: 0.6481 - val_loss: 1.4064\n",
            "Epoch 101/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7169 - loss: 1.1022 - val_accuracy: 0.6451 - val_loss: 1.4000\n",
            "Epoch 102/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7181 - loss: 1.0915 - val_accuracy: 0.6505 - val_loss: 1.4020\n",
            "Epoch 103/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7177 - loss: 1.0982 - val_accuracy: 0.6529 - val_loss: 1.4040\n",
            "Epoch 104/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7231 - loss: 1.0942 - val_accuracy: 0.6423 - val_loss: 1.3907\n",
            "Epoch 105/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7180 - loss: 1.0907 - val_accuracy: 0.6507 - val_loss: 1.4062\n",
            "Epoch 106/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7207 - loss: 1.0889 - val_accuracy: 0.6501 - val_loss: 1.3818\n",
            "Epoch 107/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7222 - loss: 1.0820 - val_accuracy: 0.6486 - val_loss: 1.3941\n",
            "Epoch 108/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7215 - loss: 1.0807 - val_accuracy: 0.6608 - val_loss: 1.3822\n",
            "Epoch 109/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7257 - loss: 1.0900 - val_accuracy: 0.6440 - val_loss: 1.3779\n",
            "Epoch 110/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7211 - loss: 1.0712 - val_accuracy: 0.6529 - val_loss: 1.3893\n",
            "Epoch 111/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7231 - loss: 1.0733 - val_accuracy: 0.6534 - val_loss: 1.3683\n",
            "Epoch 112/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7219 - loss: 1.0776 - val_accuracy: 0.6515 - val_loss: 1.3944\n",
            "Epoch 113/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7249 - loss: 1.0801 - val_accuracy: 0.6697 - val_loss: 1.3825\n",
            "Epoch 114/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7350 - loss: 1.0666 - val_accuracy: 0.6454 - val_loss: 1.3615\n",
            "Epoch 115/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7212 - loss: 1.0656 - val_accuracy: 0.6588 - val_loss: 1.3727\n",
            "Epoch 116/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7274 - loss: 1.0622 - val_accuracy: 0.6500 - val_loss: 1.3537\n",
            "Epoch 117/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7234 - loss: 1.0584 - val_accuracy: 0.6589 - val_loss: 1.3684\n",
            "Epoch 118/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7302 - loss: 1.0480 - val_accuracy: 0.6594 - val_loss: 1.3498\n",
            "Epoch 119/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7308 - loss: 1.0545 - val_accuracy: 0.6526 - val_loss: 1.3630\n",
            "Epoch 120/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7312 - loss: 1.0539 - val_accuracy: 0.6719 - val_loss: 1.3678\n",
            "Epoch 121/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7399 - loss: 1.0510 - val_accuracy: 0.6615 - val_loss: 1.3457\n",
            "Epoch 122/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7326 - loss: 1.0446 - val_accuracy: 0.6644 - val_loss: 1.3391\n",
            "Epoch 123/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7342 - loss: 1.0419 - val_accuracy: 0.6573 - val_loss: 1.3340\n",
            "Epoch 124/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7310 - loss: 1.0417 - val_accuracy: 0.6694 - val_loss: 1.3601\n",
            "Epoch 125/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7382 - loss: 1.0427 - val_accuracy: 0.6731 - val_loss: 1.3304\n",
            "Epoch 126/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7382 - loss: 1.0393 - val_accuracy: 0.6591 - val_loss: 1.3427\n",
            "Epoch 127/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7345 - loss: 1.0488 - val_accuracy: 0.6784 - val_loss: 1.3445\n",
            "Epoch 128/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7412 - loss: 1.0492 - val_accuracy: 0.6649 - val_loss: 1.3195\n",
            "Epoch 129/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7392 - loss: 1.0173 - val_accuracy: 0.6768 - val_loss: 1.3268\n",
            "Epoch 130/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7431 - loss: 1.0228 - val_accuracy: 0.6639 - val_loss: 1.3111\n",
            "Epoch 131/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7380 - loss: 1.0212 - val_accuracy: 0.6758 - val_loss: 1.3195\n",
            "Epoch 132/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7416 - loss: 1.0267 - val_accuracy: 0.6704 - val_loss: 1.3056\n",
            "Epoch 133/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7401 - loss: 1.0159 - val_accuracy: 0.6866 - val_loss: 1.3166\n",
            "Epoch 134/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7501 - loss: 1.0163 - val_accuracy: 0.6675 - val_loss: 1.3123\n",
            "Epoch 135/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7449 - loss: 1.0037 - val_accuracy: 0.6847 - val_loss: 1.2948\n",
            "Epoch 136/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7508 - loss: 1.0077 - val_accuracy: 0.6748 - val_loss: 1.3076\n",
            "Epoch 137/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7487 - loss: 0.9985 - val_accuracy: 0.6899 - val_loss: 1.3032\n",
            "Epoch 138/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7559 - loss: 0.9942 - val_accuracy: 0.6665 - val_loss: 1.2905\n",
            "Epoch 139/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7455 - loss: 0.9973 - val_accuracy: 0.6894 - val_loss: 1.2850\n",
            "Epoch 140/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7579 - loss: 0.9850 - val_accuracy: 0.6818 - val_loss: 1.2862\n",
            "Epoch 141/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7513 - loss: 0.9952 - val_accuracy: 0.6828 - val_loss: 1.2828\n",
            "Epoch 142/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7539 - loss: 0.9907 - val_accuracy: 0.6923 - val_loss: 1.2771\n",
            "Epoch 143/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7606 - loss: 0.9773 - val_accuracy: 0.6693 - val_loss: 1.2730\n",
            "Epoch 144/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7469 - loss: 0.9895 - val_accuracy: 0.6966 - val_loss: 1.2666\n",
            "Epoch 145/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7606 - loss: 0.9792 - val_accuracy: 0.6842 - val_loss: 1.2697\n",
            "Epoch 146/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7556 - loss: 0.9772 - val_accuracy: 0.6972 - val_loss: 1.2580\n",
            "Epoch 147/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7655 - loss: 0.9662 - val_accuracy: 0.6903 - val_loss: 1.2691\n",
            "Epoch 148/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7578 - loss: 0.9801 - val_accuracy: 0.6821 - val_loss: 1.2538\n",
            "Epoch 149/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7563 - loss: 0.9686 - val_accuracy: 0.6969 - val_loss: 1.2594\n",
            "Epoch 150/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7663 - loss: 0.9634 - val_accuracy: 0.6853 - val_loss: 1.2455\n",
            "Epoch 151/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7602 - loss: 0.9565 - val_accuracy: 0.6944 - val_loss: 1.2550\n",
            "Epoch 152/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7686 - loss: 0.9447 - val_accuracy: 0.6992 - val_loss: 1.2365\n",
            "Epoch 153/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7681 - loss: 0.9561 - val_accuracy: 0.6844 - val_loss: 1.2520\n",
            "Epoch 154/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7601 - loss: 0.9555 - val_accuracy: 0.7000 - val_loss: 1.2381\n",
            "Epoch 155/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7687 - loss: 0.9468 - val_accuracy: 0.6935 - val_loss: 1.2255\n",
            "Epoch 156/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7655 - loss: 0.9398 - val_accuracy: 0.6956 - val_loss: 1.2451\n",
            "Epoch 157/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7675 - loss: 0.9401 - val_accuracy: 0.7024 - val_loss: 1.2203\n",
            "Epoch 158/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7686 - loss: 0.9434 - val_accuracy: 0.6905 - val_loss: 1.2274\n",
            "Epoch 159/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7649 - loss: 0.9377 - val_accuracy: 0.6996 - val_loss: 1.2234\n",
            "Epoch 160/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7703 - loss: 0.9323 - val_accuracy: 0.6971 - val_loss: 1.2085\n",
            "Epoch 161/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7681 - loss: 0.9286 - val_accuracy: 0.6965 - val_loss: 1.2201\n",
            "Epoch 162/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7667 - loss: 0.9384 - val_accuracy: 0.7027 - val_loss: 1.2050\n",
            "Epoch 163/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7719 - loss: 0.9188 - val_accuracy: 0.6905 - val_loss: 1.2166\n",
            "Epoch 164/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7669 - loss: 0.9201 - val_accuracy: 0.7023 - val_loss: 1.2004\n",
            "Epoch 165/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7738 - loss: 0.9137 - val_accuracy: 0.6969 - val_loss: 1.1964\n",
            "Epoch 166/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7708 - loss: 0.9110 - val_accuracy: 0.7014 - val_loss: 1.2041\n",
            "Epoch 167/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7727 - loss: 0.9148 - val_accuracy: 0.7015 - val_loss: 1.1903\n",
            "Epoch 168/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7716 - loss: 0.9142 - val_accuracy: 0.6936 - val_loss: 1.2133\n",
            "Epoch 169/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7656 - loss: 0.9279 - val_accuracy: 0.6977 - val_loss: 1.2094\n",
            "Epoch 170/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7722 - loss: 0.9283 - val_accuracy: 0.7034 - val_loss: 1.1825\n",
            "Epoch 171/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7759 - loss: 0.8942 - val_accuracy: 0.7031 - val_loss: 1.1809\n",
            "Epoch 172/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7744 - loss: 0.8975 - val_accuracy: 0.7036 - val_loss: 1.1759\n",
            "Epoch 173/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7772 - loss: 0.8926 - val_accuracy: 0.7032 - val_loss: 1.1781\n",
            "Epoch 174/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7797 - loss: 0.8828 - val_accuracy: 0.7054 - val_loss: 1.1702\n",
            "Epoch 175/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7764 - loss: 0.8918 - val_accuracy: 0.7050 - val_loss: 1.1796\n",
            "Epoch 176/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7754 - loss: 0.8945 - val_accuracy: 0.7054 - val_loss: 1.1652\n",
            "Epoch 177/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7806 - loss: 0.8805 - val_accuracy: 0.7083 - val_loss: 1.1680\n",
            "Epoch 178/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7786 - loss: 0.8862 - val_accuracy: 0.7041 - val_loss: 1.1661\n",
            "Epoch 179/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7762 - loss: 0.8837 - val_accuracy: 0.7131 - val_loss: 1.1589\n",
            "Epoch 180/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7795 - loss: 0.8856 - val_accuracy: 0.7025 - val_loss: 1.1704\n",
            "Epoch 181/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7779 - loss: 0.8789 - val_accuracy: 0.7076 - val_loss: 1.1615\n",
            "Epoch 182/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7802 - loss: 0.8835 - val_accuracy: 0.7080 - val_loss: 1.1589\n",
            "Epoch 183/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7825 - loss: 0.8702 - val_accuracy: 0.7098 - val_loss: 1.1504\n",
            "Epoch 184/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7802 - loss: 0.8781 - val_accuracy: 0.7087 - val_loss: 1.1591\n",
            "Epoch 185/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7819 - loss: 0.8752 - val_accuracy: 0.7095 - val_loss: 1.1497\n",
            "Epoch 186/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7827 - loss: 0.8664 - val_accuracy: 0.7120 - val_loss: 1.1454\n",
            "Epoch 187/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7816 - loss: 0.8792 - val_accuracy: 0.7130 - val_loss: 1.1421\n",
            "Epoch 188/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7850 - loss: 0.8638 - val_accuracy: 0.7147 - val_loss: 1.1359\n",
            "Epoch 189/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7848 - loss: 0.8599 - val_accuracy: 0.7143 - val_loss: 1.1471\n",
            "Epoch 190/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7834 - loss: 0.8694 - val_accuracy: 0.7109 - val_loss: 1.1497\n",
            "Epoch 191/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7861 - loss: 0.8513 - val_accuracy: 0.7180 - val_loss: 1.1309\n",
            "Epoch 192/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7866 - loss: 0.8569 - val_accuracy: 0.7117 - val_loss: 1.1311\n",
            "Epoch 193/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7862 - loss: 0.8480 - val_accuracy: 0.7188 - val_loss: 1.1236\n",
            "Epoch 194/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7891 - loss: 0.8493 - val_accuracy: 0.7150 - val_loss: 1.1243\n",
            "Epoch 195/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7864 - loss: 0.8526 - val_accuracy: 0.7173 - val_loss: 1.1367\n",
            "Epoch 196/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7880 - loss: 0.8457 - val_accuracy: 0.7163 - val_loss: 1.1219\n",
            "Epoch 197/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7902 - loss: 0.8331 - val_accuracy: 0.7193 - val_loss: 1.1214\n",
            "Epoch 198/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7862 - loss: 0.8480 - val_accuracy: 0.7183 - val_loss: 1.1180\n",
            "Epoch 199/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7898 - loss: 0.8359 - val_accuracy: 0.7204 - val_loss: 1.1096\n",
            "Epoch 200/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7888 - loss: 0.8380 - val_accuracy: 0.7201 - val_loss: 1.1110\n",
            "Epoch 201/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7896 - loss: 0.8359 - val_accuracy: 0.7176 - val_loss: 1.1085\n",
            "Epoch 202/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7875 - loss: 0.8376 - val_accuracy: 0.7206 - val_loss: 1.1074\n",
            "Epoch 203/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7885 - loss: 0.8336 - val_accuracy: 0.7178 - val_loss: 1.1093\n",
            "Epoch 204/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7897 - loss: 0.8265 - val_accuracy: 0.7211 - val_loss: 1.1059\n",
            "Epoch 205/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7897 - loss: 0.8296 - val_accuracy: 0.7206 - val_loss: 1.0987\n",
            "Epoch 206/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7903 - loss: 0.8282 - val_accuracy: 0.7196 - val_loss: 1.1080\n",
            "Epoch 207/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7879 - loss: 0.8314 - val_accuracy: 0.7230 - val_loss: 1.0939\n",
            "Epoch 208/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7898 - loss: 0.8240 - val_accuracy: 0.7175 - val_loss: 1.0996\n",
            "Epoch 209/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7884 - loss: 0.8250 - val_accuracy: 0.7241 - val_loss: 1.0909\n",
            "Epoch 210/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7902 - loss: 0.8219 - val_accuracy: 0.7189 - val_loss: 1.0980\n",
            "Epoch 211/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7933 - loss: 0.8126 - val_accuracy: 0.7243 - val_loss: 1.0843\n",
            "Epoch 212/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7942 - loss: 0.8088 - val_accuracy: 0.7211 - val_loss: 1.0849\n",
            "Epoch 213/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7923 - loss: 0.8115 - val_accuracy: 0.7218 - val_loss: 1.0968\n",
            "Epoch 214/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7916 - loss: 0.8169 - val_accuracy: 0.7251 - val_loss: 1.0780\n",
            "Epoch 215/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7933 - loss: 0.8123 - val_accuracy: 0.7226 - val_loss: 1.0858\n",
            "Epoch 216/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7945 - loss: 0.8006 - val_accuracy: 0.7260 - val_loss: 1.0745\n",
            "Epoch 217/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7947 - loss: 0.8008 - val_accuracy: 0.7208 - val_loss: 1.0895\n",
            "Epoch 218/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7942 - loss: 0.7982 - val_accuracy: 0.7255 - val_loss: 1.0758\n",
            "Epoch 219/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7965 - loss: 0.7935 - val_accuracy: 0.7234 - val_loss: 1.0728\n",
            "Epoch 220/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7948 - loss: 0.7959 - val_accuracy: 0.7234 - val_loss: 1.0739\n",
            "Epoch 221/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7924 - loss: 0.8087 - val_accuracy: 0.7259 - val_loss: 1.0777\n",
            "Epoch 222/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7958 - loss: 0.7949 - val_accuracy: 0.7241 - val_loss: 1.0669\n",
            "Epoch 223/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7963 - loss: 0.7938 - val_accuracy: 0.7270 - val_loss: 1.0673\n",
            "Epoch 224/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7958 - loss: 0.7916 - val_accuracy: 0.7271 - val_loss: 1.0620\n",
            "Epoch 225/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7961 - loss: 0.7924 - val_accuracy: 0.7269 - val_loss: 1.0706\n",
            "Epoch 226/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7955 - loss: 0.7927 - val_accuracy: 0.7256 - val_loss: 1.0655\n",
            "Epoch 227/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7956 - loss: 0.7893 - val_accuracy: 0.7236 - val_loss: 1.0701\n",
            "Epoch 228/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7955 - loss: 0.7985 - val_accuracy: 0.7280 - val_loss: 1.0579\n",
            "Epoch 229/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7953 - loss: 0.7904 - val_accuracy: 0.7285 - val_loss: 1.0546\n",
            "Epoch 230/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7955 - loss: 0.7883 - val_accuracy: 0.7246 - val_loss: 1.0615\n",
            "Epoch 231/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7971 - loss: 0.7785 - val_accuracy: 0.7268 - val_loss: 1.0564\n",
            "Epoch 232/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7969 - loss: 0.7835 - val_accuracy: 0.7281 - val_loss: 1.0539\n",
            "Epoch 233/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7953 - loss: 0.7866 - val_accuracy: 0.7286 - val_loss: 1.0476\n",
            "Epoch 234/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7993 - loss: 0.7738 - val_accuracy: 0.7285 - val_loss: 1.0588\n",
            "Epoch 235/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7975 - loss: 0.7784 - val_accuracy: 0.7278 - val_loss: 1.0502\n",
            "Epoch 236/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7972 - loss: 0.7814 - val_accuracy: 0.7266 - val_loss: 1.0489\n",
            "Epoch 237/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7974 - loss: 0.7777 - val_accuracy: 0.7288 - val_loss: 1.0513\n",
            "Epoch 238/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7998 - loss: 0.7679 - val_accuracy: 0.7291 - val_loss: 1.0430\n",
            "Epoch 239/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7968 - loss: 0.7772 - val_accuracy: 0.7296 - val_loss: 1.0420\n",
            "Epoch 240/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7982 - loss: 0.7720 - val_accuracy: 0.7281 - val_loss: 1.0514\n",
            "Epoch 241/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7992 - loss: 0.7739 - val_accuracy: 0.7326 - val_loss: 1.0359\n",
            "Epoch 242/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8003 - loss: 0.7661 - val_accuracy: 0.7283 - val_loss: 1.0451\n",
            "Epoch 243/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8015 - loss: 0.7634 - val_accuracy: 0.7283 - val_loss: 1.0384\n",
            "Epoch 244/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8003 - loss: 0.7637 - val_accuracy: 0.7310 - val_loss: 1.0400\n",
            "Epoch 245/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8006 - loss: 0.7611 - val_accuracy: 0.7308 - val_loss: 1.0407\n",
            "Epoch 246/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7999 - loss: 0.7646 - val_accuracy: 0.7342 - val_loss: 1.0301\n",
            "Epoch 247/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8028 - loss: 0.7577 - val_accuracy: 0.7329 - val_loss: 1.0335\n",
            "Epoch 248/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8006 - loss: 0.7617 - val_accuracy: 0.7324 - val_loss: 1.0353\n",
            "Epoch 249/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7997 - loss: 0.7648 - val_accuracy: 0.7337 - val_loss: 1.0302\n",
            "Epoch 250/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8025 - loss: 0.7505 - val_accuracy: 0.7306 - val_loss: 1.0312\n",
            "Epoch 251/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8028 - loss: 0.7536 - val_accuracy: 0.7346 - val_loss: 1.0253\n",
            "Epoch 252/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8008 - loss: 0.7613 - val_accuracy: 0.7331 - val_loss: 1.0299\n",
            "Epoch 253/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8025 - loss: 0.7578 - val_accuracy: 0.7330 - val_loss: 1.0293\n",
            "Epoch 254/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8030 - loss: 0.7510 - val_accuracy: 0.7348 - val_loss: 1.0199\n",
            "Epoch 255/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8031 - loss: 0.7579 - val_accuracy: 0.7329 - val_loss: 1.0326\n",
            "Epoch 256/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8016 - loss: 0.7559 - val_accuracy: 0.7371 - val_loss: 1.0180\n",
            "Epoch 257/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8049 - loss: 0.7469 - val_accuracy: 0.7371 - val_loss: 1.0203\n",
            "Epoch 258/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8048 - loss: 0.7463 - val_accuracy: 0.7357 - val_loss: 1.0178\n",
            "Epoch 259/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8048 - loss: 0.7493 - val_accuracy: 0.7350 - val_loss: 1.0296\n",
            "Epoch 260/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8023 - loss: 0.7550 - val_accuracy: 0.7353 - val_loss: 1.0203\n",
            "Epoch 261/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8049 - loss: 0.7471 - val_accuracy: 0.7373 - val_loss: 1.0132\n",
            "Epoch 262/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8046 - loss: 0.7473 - val_accuracy: 0.7339 - val_loss: 1.0238\n",
            "Epoch 263/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8062 - loss: 0.7413 - val_accuracy: 0.7373 - val_loss: 1.0116\n",
            "Epoch 264/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8045 - loss: 0.7455 - val_accuracy: 0.7358 - val_loss: 1.0153\n",
            "Epoch 265/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8038 - loss: 0.7449 - val_accuracy: 0.7372 - val_loss: 1.0143\n",
            "Epoch 266/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8061 - loss: 0.7408 - val_accuracy: 0.7386 - val_loss: 1.0096\n",
            "Epoch 267/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8058 - loss: 0.7394 - val_accuracy: 0.7363 - val_loss: 1.0221\n",
            "Epoch 268/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8067 - loss: 0.7386 - val_accuracy: 0.7394 - val_loss: 1.0084\n",
            "Epoch 269/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8050 - loss: 0.7434 - val_accuracy: 0.7384 - val_loss: 1.0106\n",
            "Epoch 270/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8054 - loss: 0.7384 - val_accuracy: 0.7398 - val_loss: 1.0093\n",
            "Epoch 271/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8076 - loss: 0.7360 - val_accuracy: 0.7401 - val_loss: 1.0053\n",
            "Epoch 272/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8069 - loss: 0.7383 - val_accuracy: 0.7382 - val_loss: 1.0116\n",
            "Epoch 273/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8067 - loss: 0.7349 - val_accuracy: 0.7413 - val_loss: 1.0019\n",
            "Epoch 274/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8095 - loss: 0.7268 - val_accuracy: 0.7390 - val_loss: 1.0106\n",
            "Epoch 275/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8075 - loss: 0.7322 - val_accuracy: 0.7424 - val_loss: 0.9985\n",
            "Epoch 276/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8082 - loss: 0.7320 - val_accuracy: 0.7419 - val_loss: 1.0070\n",
            "Epoch 277/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8072 - loss: 0.7336 - val_accuracy: 0.7367 - val_loss: 1.0166\n",
            "Epoch 278/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8054 - loss: 0.7404 - val_accuracy: 0.7422 - val_loss: 0.9970\n",
            "Epoch 279/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8085 - loss: 0.7301 - val_accuracy: 0.7406 - val_loss: 1.0014\n",
            "Epoch 280/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8103 - loss: 0.7208 - val_accuracy: 0.7449 - val_loss: 0.9934\n",
            "Epoch 281/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8103 - loss: 0.7231 - val_accuracy: 0.7406 - val_loss: 1.0100\n",
            "Epoch 282/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8085 - loss: 0.7302 - val_accuracy: 0.7416 - val_loss: 0.9970\n",
            "Epoch 283/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8097 - loss: 0.7250 - val_accuracy: 0.7404 - val_loss: 0.9995\n",
            "Epoch 284/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8074 - loss: 0.7274 - val_accuracy: 0.7413 - val_loss: 0.9979\n",
            "Epoch 285/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8109 - loss: 0.7241 - val_accuracy: 0.7430 - val_loss: 0.9901\n",
            "Epoch 286/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8119 - loss: 0.7142 - val_accuracy: 0.7420 - val_loss: 0.9930\n",
            "Epoch 287/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8113 - loss: 0.7175 - val_accuracy: 0.7451 - val_loss: 0.9879\n",
            "Epoch 288/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8122 - loss: 0.7176 - val_accuracy: 0.7428 - val_loss: 0.9988\n",
            "Epoch 289/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8091 - loss: 0.7240 - val_accuracy: 0.7400 - val_loss: 1.0049\n",
            "Epoch 290/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8084 - loss: 0.7265 - val_accuracy: 0.7444 - val_loss: 0.9871\n",
            "Epoch 291/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8118 - loss: 0.7170 - val_accuracy: 0.7437 - val_loss: 0.9878\n",
            "Epoch 292/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8118 - loss: 0.7122 - val_accuracy: 0.7447 - val_loss: 0.9849\n",
            "Epoch 293/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8120 - loss: 0.7133 - val_accuracy: 0.7420 - val_loss: 0.9931\n",
            "Epoch 294/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8088 - loss: 0.7261 - val_accuracy: 0.7456 - val_loss: 0.9864\n",
            "Epoch 295/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8143 - loss: 0.7072 - val_accuracy: 0.7452 - val_loss: 0.9897\n",
            "Epoch 296/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8098 - loss: 0.7200 - val_accuracy: 0.7438 - val_loss: 0.9855\n",
            "Epoch 297/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8108 - loss: 0.7176 - val_accuracy: 0.7457 - val_loss: 0.9816\n",
            "Epoch 298/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8117 - loss: 0.7166 - val_accuracy: 0.7450 - val_loss: 0.9860\n",
            "Epoch 299/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8130 - loss: 0.7069 - val_accuracy: 0.7464 - val_loss: 0.9842\n",
            "Epoch 300/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8122 - loss: 0.7119 - val_accuracy: 0.7419 - val_loss: 0.9907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAK9CAYAAAAT0TyCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACnBklEQVR4nOzdd5hU5dnH8e9sX8ouvVcB6U0EBey9oVixJPbeY0wxMYnljRi7xqixa+y9YMGKBVFBQBEpgvRed9kFtszM+8fZKrB05ix8P9c11845c+bMM4jJ/ryf534i8Xg8jiRJkiRpg5ISPQBJkiRJCjuDkyRJkiRthMFJkiRJkjbC4CRJkiRJG2FwkiRJkqSNMDhJkiRJ0kYYnCRJkiRpIwxOkiRJkrQRBidJkiRJ2giDkySpzJNPPkkkEmHmzJmJHopKzJw5k0gkwh133JHooUjSLs3gJEmSJEkbYXCSJEmSpI0wOEmSJEnSRhicJEkb9cADD9C1a1fS09Np1qwZl112GStXrqx0zc8//8yJJ55IkyZNyMjIoEWLFpx66qnk5OSUXfPhhx+yzz77UKdOHWrVqkXHjh35y1/+UuVnd+vWjQMPPHCd87FYjObNm3PSSSeVnXvhhRfo06cPtWvXJisri+7du3Pvvfdu9PvFYjHuueceunbtSkZGBo0bN+aiiy5ixYoVla5r06YNxxxzDB988AG9evUiIyODLl268Nprr61zz19++YWTTz6ZevXqUaNGDfbee2/eeeedda5bu3YtN9xwA7vvvjsZGRk0bdqUE044genTp69z7cMPP0y7du1IT0+nb9++jB49utLrCxcu5JxzzqFFixakp6fTtGlTjjvuONesSdI2kJLoAUiSwu2GG27gxhtv5JBDDuGSSy5hypQpPPjgg4wePZqRI0eSmppKYWEhhx9+OAUFBVxxxRU0adKEefPmMWzYMFauXEl2djYTJ07kmGOOoUePHtx0002kp6czbdo0Ro4cWeXnDxkyhBtuuIGFCxfSpEmTsvNffvkl8+fP59RTTwWCUHbaaadx8MEH869//QuASZMmMXLkSK666qoqP+Oiiy7iySef5JxzzuHKK69kxowZ3H///YwbN67sO5b6+eefGTJkCBdffDFnnXUWTzzxBCeffDLvv/8+hx56KACLFi1iwIABrF69miuvvJL69evz1FNPceyxx/LKK69w/PHHAxCNRjnmmGP4+OOPOfXUU7nqqqtYtWoVH374IT/++CPt2rUr+9znnnuOVatWcdFFFxGJRLjttts44YQT+OWXX8rGd+KJJzJx4kSuuOIK2rRpw+LFi/nwww+ZPXs2bdq02cR/4pKk9YpLklTiiSeeiAPxGTNmxOPxeHzx4sXxtLS0+GGHHRaPRqNl191///1xIP7444/H4/F4fNy4cXEg/vLLL2/w3nfffXcciC9ZsmSzxjRlypQ4EP/3v/9d6fyll14ar1WrVnz16tXxeDwev+qqq+JZWVnx4uLizbr/F198EQfizz77bKXz77///jrnW7duHQfir776atm5nJyceNOmTeO9e/cuO3f11VfHgfgXX3xRdm7VqlXxtm3bxtu0aVP2Z/n444/Hgfhdd921zrhisVg8Ho/HZ8yYEQfi9evXjy9fvrzs9TfffDMOxN9+++14PB6Pr1ixIg7Eb7/99s36/pKkTeNUPUnSBn300UcUFhZy9dVXk5RU/n8ZF1xwAVlZWWVTz7KzswEYPnw4q1evXu+96tSpA8Cbb75JLBbb5DHsvvvu9OrVixdffLHsXDQa5ZVXXmHQoEFkZmaW3T8/P58PP/xws77jyy+/THZ2NoceeihLly4te/Tp04datWrx6aefVrq+WbNmZRUjgKysLM4880zGjRvHwoULAXj33Xfp168f++yzT9l1tWrV4sILL2TmzJn89NNPALz66qs0aNCAK664Yp1xRSKRSsdDhgyhbt26Zcf77rsvEEwJBMjMzCQtLY0RI0asM8VQkrT1DE6SpA2aNWsWAB07dqx0Pi0tjd12263s9bZt23LNNdfw6KOP0qBBAw4//HD+85//VFrfNGTIEAYOHMj5559P48aNOfXUU3nppZc2KUQNGTKEkSNHMm/ePABGjBjB4sWLGTJkSNk1l156KbvvvjtHHnkkLVq04Nxzz+X999/f6L1//vlncnJyaNSoEQ0bNqz0yMvLY/HixZWub9++/TqhZvfddwcoW0s0a9asdf7MADp37lz2OsD06dPp2LEjKSkbnznfqlWrSselIao0JKWnp/Ovf/2L9957j8aNG7Pffvtx2223lYU5SdLWMThJkraJO++8kx9++IG//OUvrFmzhiuvvJKuXbsyd+5cIKiIfP7553z00Uf89re/5YcffmDIkCEceuihRKPRKu89ZMgQ4vE4L7/8MgAvvfQS2dnZHHHEEWXXNGrUiPHjx/PWW29x7LHH8umnn3LkkUdy1llnVXnvWCxGo0aN+PDDD9f7uOmmm7byT2bbSE5OXu/5eDxe9vzqq69m6tSpDB06lIyMDP72t7/RuXNnxo0bt6OGKUk7LYOTJGmDWrduDcCUKVMqnS8sLGTGjBllr5fq3r07119/PZ9//jlffPEF8+bN46GHHip7PSkpiYMPPpi77rqLn376iX/+85988skn60yH+7W2bdvSr18/XnzxRYqLi3nttdcYPHgw6enpla5LS0tj0KBBPPDAA0yfPp2LLrqIp59+mmnTpm3w3u3atWPZsmUMHDiQQw45ZJ1Hz549K10/bdq0SmEFYOrUqQBlDRhat269zp8ZwOTJk8teL/3sKVOmUFRUVOX33xzt2rXj97//PR988AE//vgjhYWF3Hnnndvs/pK0qzI4SZI26JBDDiEtLY377ruvUlh47LHHyMnJ4eijjwYgNzeX4uLiSu/t3r07SUlJFBQUALB8+fJ17t+rVy+AsmuqMmTIEL7++msef/xxli5dWmmaHsCyZcsqHSclJdGjR4+N3v+UU04hGo1y8803r/NacXHxOm3X58+fz+uvv152nJuby9NPP02vXr3Kuv4dddRRfPvtt4waNarsuvz8fB5++GHatGlDly5dgKAL3tKlS7n//vvX+exfh7ONWb16NWvXrq10rl27dtSuXXuT/nwlSVWzHbkkaYMaNmzIddddx4033sgRRxzBsccey5QpU3jggQfo27cvv/nNbwD45JNPuPzyyzn55JPZfffdKS4u5n//+x/JycmceOKJANx00018/vnnHH300bRu3ZrFixfzwAMP0KJFi0pNFDbklFNO4dprr+Xaa6+lXr16HHLIIZVeP//881m+fDkHHXQQLVq0YNasWfz73/+mV69eZWuL1mf//ffnoosuYujQoYwfP57DDjuM1NRUfv75Z15++WXuvffeSntF7b777px33nmMHj2axo0b8/jjj7No0SKeeOKJsmv+/Oc/8/zzz3PkkUdy5ZVXUq9ePZ566ilmzJjBq6++WtZo48wzz+Tpp5/mmmuu4dtvv2XfffclPz+fjz76iEsvvZTjjjtuk/9ZTZ06lYMPPphTTjmFLl26kJKSwuuvv86iRYvKWrZLkrZCQnv6SZJC5dftyEvdf//98U6dOsVTU1PjjRs3jl9yySXxFStWlL3+yy+/xM8999x4u3bt4hkZGfF69erFDzzwwPhHH31Uds3HH38cP+644+LNmjWLp6WlxZs1axY/7bTT4lOnTt3k8Q0cODAOxM8///x1XnvllVfihx12WLxRo0bxtLS0eKtWreIXXXRRfMGCBZt074cffjjep0+feGZmZrx27drx7t27x//4xz/G58+fX3ZN69at40cffXR8+PDh8R49esTT09PjnTp1Wm8b9unTp8dPOumkeJ06deIZGRnxfv36xYcNG7bOdatXr47/9a9/jbdt2zaempoab9KkSfykk06KT58+PR6Pl7cjX1+bcSD+j3/8Ix6Px+NLly6NX3bZZfFOnTrFa9asGc/Ozo7vtdde8ZdeemmTvr8kqWqReHwz5wJIkrSLatOmDd26dWPYsGGJHookaQdzjZMkSZIkbYTBSZIkSZI2wuAkSZIkSRvhGidJkiRJ2ojQVJxuvfVWIpEIV1999QavefLJJ4lEIpUeGRkZO26QkiRJknZJodjHafTo0fz3v/8t26iwKllZWZV2Y49EIttzaJIkSZKU+OCUl5fHGWecwSOPPML//d//bfT6SCRStjP7lojFYsyfP5/atWsbuiRJkqRdWDweZ9WqVTRr1qxsc/INSXhwuuyyyzj66KM55JBDNik45eXl0bp1a2KxGHvssQe33HILXbt23eD1BQUFFBQUlB3PmzePLl26bJOxS5IkSar+5syZQ4sWLaq8JqHB6YUXXmDs2LGMHj16k67v2LEjjz/+OD169CAnJ4c77riDAQMGMHHixA1+0aFDh3LjjTeuc37OnDlkZWVt1fglSZIkVV+5ubm0bNmS2rVrb/TahHXVmzNnDnvuuScffvhh2dqmAw44gF69enHPPfds0j2Kioro3Lkzp512GjfffPN6r/l1xan0DycnJ8fgJEmSJO3CcnNzyc7O3qRskLCK03fffcfixYvZY489ys5Fo1E+//xz7r//fgoKCkhOTq7yHqmpqfTu3Ztp06Zt8Jr09HTS09O32bglSZIk7XoSFpwOPvhgJkyYUOncOeecQ6dOnfjTn/600dAEQdCaMGECRx111PYapiRJkiQlLjjVrl2bbt26VTpXs2ZN6tevX3b+zDPPpHnz5gwdOhSAm266ib333pv27duzcuVKbr/9dmbNmsX555+/w8cvSZIkadeR8K56VZk9e3altoArVqzgggsuYOHChdStW5c+ffrw1Vdf2SVPkiRpJxONRikqKkr0MLQTSE1N3aTZbBuTsOYQibI5C8AkSZK04+Xl5TF37lx2sV9TtZ1EIhFatGhBrVq11nmtWjSHkCRJkn4tGo0yd+5catSoQcOGDYlEIokekqqxeDzOkiVLmDt3Lh06dNiqypPBSZIkSaFRVFREPB6nYcOGZGZmJno42gk0bNiQmTNnUlRUtFXBKWnjl0iSJEk7lpUmbSvb6u+SwUmSJEmSNsLgJEmSJEkbYXCSJEmSQqZNmzbcc889m3z9iBEjiEQirFy5cruNCeDJJ5+kTp062/UzwsrmEJIkSdJWOuCAA+jVq9dmhZ2qjB49mpo1a27y9QMGDGDBggVkZ2dvk8/XugxOkiRJ0g4Qj8eJRqOkpGz8V/CGDRtu1r3T0tJo0qTJlg5Nm8CpepIkSQqteDzO6sLihDw2dQPes88+m88++4x7772XSCRCJBJh5syZZdPn3nvvPfr06UN6ejpffvkl06dP57jjjqNx48bUqlWLvn378tFHH1W656+n6kUiER599FGOP/54atSoQYcOHXjrrbfKXv/1VL3SKXXDhw+nc+fO1KpViyOOOIIFCxaUvae4uJgrr7ySOnXqUL9+ff70pz9x1llnMXjw4M36Z/Tggw/Srl070tLS6NixI//73/8q/fO74YYbaNWqFenp6TRr1owrr7yy7PUHHniADh06kJGRQePGjTnppJM267N3JCtOkiRJCq01RVG6/H14Qj77p5sOp0baxn9dvvfee5k6dSrdunXjpptuAsr3DgL485//zB133MFuu+1G3bp1mTNnDkcddRT//Oc/SU9P5+mnn2bQoEFMmTKFVq1abfBzbrzxRm677TZuv/12/v3vf3PGGWcwa9Ys6tWrt97rV69ezR133MH//vc/kpKS+M1vfsO1117Ls88+C8C//vUvnn32WZ544gk6d+7MvffeyxtvvMGBBx64yX9Gr7/+OldddRX33HMPhxxyCMOGDeOcc86hRYsWHHjggbz66qvcfffdvPDCC3Tt2pWFCxfy/fffAzBmzBiuvPJK/ve//zFgwACWL1/OF198scmfvaMZnCRJkqStkJ2dTVpaGjVq1FjvdLmbbrqJQw89tOy4Xr169OzZs+z45ptv5vXXX+ett97i8ssv3+DnnH322Zx22mkA3HLLLdx33318++23HHHEEeu9vqioiIceeoh27doBcPnll5cFO4B///vfXHfddRx//PEA3H///bz77rub8c3hjjvu4Oyzz+bSSy8F4JprruHrr7/mjjvu4MADD2T27Nk0adKEQw45hNTUVFq1akW/fv0AmD17NjVr1uSYY46hdu3atG7dmt69e2/W5+9IBidJkiSFVmZqMj/ddHjCPntb2HPPPSsd5+XlccMNN/DOO++wYMECiouLWbNmDbNnz67yPj169Ch7XrNmTbKysli8ePEGr69Ro0ZZaAJo2rRp2fU5OTksWrSoLMQAJCcn06dPH2Kx2CZ/t0mTJnHhhRdWOjdw4EDuvfdeAE4++WTuuecedtttN4444giOOuooBg0aREpKCoceeiitW7cue+2II44om4oYRq5xkiRJUmhFIhFqpKUk5BGJRLbJd/h1d7xrr72W119/nVtuuYUvvviC8ePH0717dwoLC6u8T2pq6jp/NlWFnPVdv6nrtraVli1bMmXKFB544AEyMzO59NJL2W+//SgqKqJ27dqMHTuW559/nqZNm/L3v/+dnj17bveW6lvK4CRJkiRtpbS0NKLR6CZdO3LkSM4++2yOP/54unfvTpMmTcrWQ+0o2dnZNG7cmNGjR5edi0ajjB07drPu07lzZ0aOHFnp3MiRI+nSpUvZcWZmJoMGDeK+++5jxIgRjBo1igkTJgCQkpLCIYccwm233cYPP/zAzJkz+eSTT7bim20/TtWTJEmStlKbNm345ptvmDlzJrVq1dpgwwaADh068NprrzFo0CAikQh/+9vfNmt63LZyxRVXMHToUNq3b0+nTp3497//zYoVKzar0vaHP/yBU045hd69e3PIIYfw9ttv89prr5V1CXzyySeJRqPstdde1KhRg2eeeYbMzExat27NsGHD+OWXX9hvv/2oW7cu7777LrFYjI4dO26vr7xVrDhJkiRJW+naa68lOTmZLl260LBhwyrXK911113UrVuXAQMGMGjQIA4//HD22GOPHTjawJ/+9CdOO+00zjzzTPr370+tWrU4/PDDycjI2OR7DB48mHvvvZc77riDrl278t///pcnnniCAw44AIA6derwyCOPMHDgQHr06MFHH33E22+/Tf369alTpw6vvfYaBx10EJ07d+ahhx7i+eefp2vXrtvpG2+dSHxHT3RMsNzcXLKzs8nJySErKyvRw5EkSVIFa9euZcaMGbRt23azfoHX1ovFYnTu3JlTTjmFm2++OdHD2Waq+ju1OdnAqXqSJEnSLmjWrFl88MEH7L///hQUFHD//fczY8YMTj/99EQPLZQMTgk0ddEqpi/Oo3X9mnRpZvVLkiRJO05SUhJPPvkk1157LfF4nG7duvHRRx/RuXPnRA8tlAxOCfTS6Dk8+uUMLtp/N4OTJEmSdqiWLVuu0xFPG2ZziASqkR7k1tUFm9a6UpIkSVJiGJwSqGZasBt1fkFxgkciSZIkqSoGpwSqWVJxyi80OEmSJElhZnBKoJrpQcVpdaFT9SRJkqQwMzglUI20koqTU/UkSZKkUDM4JVDNsuBkxUmSJEkKM4NTApVO1XONkyRJktq0acM999xTdhyJRHjjjTc2eP3MmTOJRCKMHz9+qz53W91nY84++2wGDx68XT9je3IfpwQqbQ7hGidJkiT92oIFC6hbt+42vefZZ5/NypUrKwWyli1bsmDBAho0aLBNP2tnY3BKoBq2I5ckSdIGNGnSZId8TnJy8g77rOrMqXoJVLrGqaA4RnE0luDRSJIkhVA8DoX5iXnE45s0xIcffphmzZoRi1X+fe64447j3HPPBWD69Okcd9xxNG7cmFq1atG3b18++uijKu/766l63377Lb179yYjI4M999yTcePGVbo+Go1y3nnn0bZtWzIzM+nYsSP33ntv2es33HADTz31FG+++SaRSIRIJMKIESPWO1Xvs88+o1+/fqSnp9O0aVP+/Oc/U1xc/h/7DzjgAK688kr++Mc/Uq9ePZo0acINN9ywSX9epQoKCrjyyitp1KgRGRkZ7LPPPowePbrs9RUrVnDGGWfQsGFDMjMz6dChA0888QQAhYWFXH755TRt2pSMjAxat27N0KFDN+vzN5cVpwQqnaoHkF8YJTvTHCtJklRJ0Wq4pVliPvsv8yGt5kYvO/nkk7niiiv49NNPOfjggwFYvnw577//Pu+++y4AeXl5HHXUUfzzn/8kPT2dp59+mkGDBjFlyhRatWq10c/Iy8vjmGOO4dBDD+WZZ55hxowZXHXVVZWuicVitGjRgpdffpn69evz1VdfceGFF9K0aVNOOeUUrr32WiZNmkRubm5ZAKlXrx7z58+vdJ958+Zx1FFHcfbZZ/P0008zefJkLrjgAjIyMiqFo6eeeoprrrmGb775hlGjRnH22WczcOBADj300I1+H4A//vGPvPrqqzz11FO0bt2a2267jcMPP5xp06ZRr149/va3v/HTTz/x3nvv0aBBA6ZNm8aaNWsAuO+++3jrrbd46aWXaNWqFXPmzGHOnDmb9LlbyuCUQGkpSaQmRyiKxlldWEx2ZmqihyRJkqTNVLduXY488kiee+65suD0yiuv0KBBAw488EAAevbsSc+ePcvec/PNN/P666/z1ltvcfnll2/0M5577jlisRiPPfYYGRkZdO3alblz53LJJZeUXZOamsqNN95Ydty2bVtGjRrFSy+9xCmnnEKtWrXIzMykoKCgyql5DzzwAC1btuT+++8nEonQqVMn5s+fz5/+9Cf+/ve/k5QU/Mf+Hj168I9//AOADh06cP/99/Pxxx9vUnDKz8/nwQcf5Mknn+TII48E4JFHHuHDDz/kscce4w9/+AOzZ8+md+/e7LnnnkDQPKPU7Nmz6dChA/vssw+RSITWrVtv9DO3lsEpwWqkpZCzpsiW5JIkSeuTWiOo/CTqszfRGWecwQUXXMADDzxAeno6zz77LKeeempZyMjLy+OGG27gnXfeYcGCBRQXF7NmzRpmz569SfefNGkSPXr0ICMjo+xc//7917nuP//5D48//jizZ89mzZo1FBYW0qtXr03+HqWf1b9/fyKRSNm5gQMHkpeXx9y5c8sqZD169Kj0vqZNm7J48eJN+ozp06dTVFTEwIEDy86lpqbSr18/Jk2aBMAll1zCiSeeyNixYznssMMYPHgwAwYMAIImF4ceeigdO3bkiCOO4JhjjuGwww7brO+5uZwblmA1bRAhSZK0YZFIMF0uEY8KwWFjBg0aRDwe55133mHOnDl88cUXnHHGGWWvX3vttbz++uvccsstfPHFF4wfP57u3btTWFi4zf6oXnjhBa699lrOO+88PvjgA8aPH88555yzTT+jotTUyrOlIpHIOuu8tsaRRx7JrFmz+N3vfsf8+fM5+OCDufbaawHYY489mDFjBjfffDNr1qzhlFNO4aSTTtpmn70+BqcEK13n5F5OkiRJ1VdGRgYnnHACzz77LM8//zwdO3Zkjz32KHt95MiRnH322Rx//PF0796dJk2aMHPmzE2+f+fOnfnhhx9Yu3Zt2bmvv/660jUjR45kwIABXHrppfTu3Zv27dszffr0StekpaURjVY906lz586MGjWKeIXmGCNHjqR27dq0aNFik8dclXbt2pGWlsbIkSPLzhUVFTF69Gi6dOlSdq5hw4acddZZPPPMM9xzzz08/PDDZa9lZWUxZMgQHnnkEV588UVeffVVli9fvk3Gtz4GpwSrUbqXk1P1JEmSqrUzzjiDd955h8cff7xStQmCNUCvvfYa48eP5/vvv+f000/frOrM6aefTiQS4YILLuCnn37i3Xff5Y477ljnM8aMGcPw4cOZOnUqf/vb3yp1qYNgndAPP/zAlClTWLp0KUVFRet81qWXXsqcOXO44oormDx5Mm+++Sb/+Mc/uOaaa8qmHm6tmjVrcskll/CHP/yB999/n59++okLLriA1atXc9555wHw97//nTfffJNp06YxceJEhg0bRufOnQG46667eP7555k8eTJTp07l5ZdfpkmTJtSpU2ebjG99DE4JVjZVz4qTJElStXbQQQdRr149pkyZwumnn17ptbvuuou6desyYMAABg0axOGHH16pIrUxtWrV4u2332bChAn07t2bv/71r/zrX/+qdM1FF13ECSecwJAhQ9hrr71YtmwZl156aaVrLrjgAjp27Miee+5Jw4YNK1V8SjVv3px3332Xb7/9lp49e3LxxRdz3nnncf3112/Gn8bG3XrrrZx44on89re/ZY899mDatGkMHz68bNPftLQ0rrvuOnr06MF+++1HcnIyL7zwAgC1a9fmtttuY88996Rv377MnDmTd999d5sFu/WJxOOb2KB+J5Gbm0t2djY5OTlkZWUlejic/9QYPpq0iFuO787pe228FaUkSdLObO3atcyYMYO2bdtWaoQgbamq/k5tTjaw4pRgtdKDitNqK06SJElSaBmcEqx0jZPtyCVJkqTwMjglUv5SWkdn05AVVpwkSZKkEHMD3ET68m4u+vF+4inHMKeg58avlyRJkpQQVpwSKTkNgHSKWF3oVD1JkqRSu1j/Mm1H2+rvksEpkVLSAUijmPwCp+pJkiQlJweNswoLCxM8Eu0sSv8ulf7d2lJO1UukkopTKsVWnCRJkoCUlBRq1KjBkiVLSE1N3a778mjnF4vFWLJkCTVq1CAlZeuij8EpkUorTpEi8qw4SZIkEYlEaNq0KTNmzGDWrFmJHo52AklJSbRq1YpIJLJV9zE4JVJJxSmNYrvqSZIklUhLS6NDhw5O19M2kZaWtk0qlwanRCpb41TkPk6SJEkVJCUlkZGRkehhSGWcNJpIyeXNIaw4SZIkSeFlcEqklJJ25BErTpIkSVKYGZwSqULFqTAao7A4luABSZIkSVofg1MipZQ2hygCYI0tySVJkqRQMjglUknFKT0SrG/Kd52TJEmSFEoGp0RKLl3jFAQmG0RIkiRJ4WRwSqTS5hAEgSnPBhGSJElSKBmcEqm0OUQkWOO0usCKkyRJkhRGBqdEqrABLkC+zSEkSZKkUDI4JVLJGqeUuGucJEmSpDAzOCVSpYpTnDyn6kmSJEmhZHBKpJKKE0AqUVbbHEKSJEkKJYNTIpVUnCCoOrmPkyRJkhROBqdESq4cnFbbHEKSJEkKJYNTIiUlQVIKAGkUu8ZJkiRJCimDU6JV2MvJfZwkSZKkcDI4JVpK0CAijWL3cZIkSZJCyuCUaCUVp3SK3MdJkiRJCqnQBKdbb72VSCTC1VdfXeV1L7/8Mp06dSIjI4Pu3bvz7rvv7pgBbi/J5RWnPNuRS5IkSaEUiuA0evRo/vvf/9KjR48qr/vqq6847bTTOO+88xg3bhyDBw9m8ODB/PjjjztopNtB2VQ91zhJkiRJYZXw4JSXl8cZZ5zBI488Qt26dau89t577+WII47gD3/4A507d+bmm29mjz324P77799Bo90OyppDFJNvcJIkSZJCKeHB6bLLLuPoo4/mkEMO2ei1o0aNWue6ww8/nFGjRm3wPQUFBeTm5lZ6hEpJxSmVYgqjsQQPRpIkSdL6pCTyw1944QXGjh3L6NGjN+n6hQsX0rhx40rnGjduzMKFCzf4nqFDh3LjjTdu1Ti3q9KKE0UUReMJHowkSZKk9UlYxWnOnDlcddVVPPvss2RkZGy3z7nuuuvIyckpe8yZM2e7fdYWKak4pVNMNGZwkiRJksIoYRWn7777jsWLF7PHHnuUnYtGo3z++efcf//9FBQUkJycXOk9TZo0YdGiRZXOLVq0iCZNmmzwc9LT00lPT9+2g9+WKmyAW+RUPUmSJCmUElZxOvjgg5kwYQLjx48ve+y5556cccYZjB8/fp3QBNC/f38+/vjjSuc+/PBD+vfvv6OGve2llE7Vs+IkSZIkhVXCKk61a9emW7dulc7VrFmT+vXrl50/88wzad68OUOHDgXgqquuYv/99+fOO+/k6KOP5oUXXmDMmDE8/PDDO3z820xyeTvy4liceDxOJBJJ8KAkSZIkVZTwrnpVmT17NgsWLCg7HjBgAM899xwPP/wwPXv25JVXXuGNN95YJ4BVKynlzSEAq06SJElSCCW0q96vjRgxospjgJNPPpmTTz55xwxoRyirOAV7OBXH4qSsO0tRkiRJUgKFuuK0S0gpbw4BQXCSJEmSFC4Gp0T7VcUp6l5OkiRJUugYnBItuXQfp6DiVBSzJbkkSZIUNganRCuZqpceKak4OVVPkiRJCh2DU6KVVpwiUQA3wZUkSZJCyOCUaGUVJ9uRS5IkSWFlcEq0sopTMFWvyOYQkiRJUugYnBKttOKEa5wkSZKksDI4JVpy5eYQrnGSJEmSwsfglGgppfs4ucZJkiRJCiuDU6KVVJzSSipOxQYnSZIkKXQMTon2q4pTsVP1JEmSpNAxOCVaacXJ5hCSJElSaBmcEi2lNDgFFacig5MkSZIUOganREtOBSC1rDmEU/UkSZKksDE4JVrJVL3UeEnFyQ1wJUmSpNAxOCVayVS9VNc4SZIkSaFlcEq05KCrXkpZxcmpepIkSVLYGJwSrVJziLgVJ0mSJCmEDE6JVlJxAkglSrFrnCRJkqTQMTglWknFCYKqU7EVJ0mSJCl0DE6Jlvzr4OQaJ0mSJClsDE6JlpQESSkApFHsVD1JkiQphAxOYVBSdUqLFNkcQpIkSQohg1MYpAQNItIopsipepIkSVLoGJzCoKTilE4RUafqSZIkSaFjcAqD5IoVJ4OTJEmSFDYGpzAom6pXRNSpepIkSVLoGJzCoKw5hF31JEmSpDAyOIVBScUplWI3wJUkSZJCyOAUBqUVJ4oojjpVT5IkSQobg1MYlFSc0q04SZIkSaFkcAqDChvgusZJkiRJCh+DUxiklE7Vs+IkSZIkhZHBKQySy9uRF9uOXJIkSQodg1MYpFRoDmHFSZIkSQodg1MYlFWciom6xkmSJEkKHYNTGKRUaA7hVD1JkiQpdAxOYVCh4uRUPUmSJCl8DE5hkFy6j5PtyCVJkqQwMjiFQaV25E7VkyRJksLG4BQGFduRW3GSJEmSQsfgFAYlFafUiGucJEmSpDAyOIVBpeYQTtWTJEmSwsbgFAYVN8B1qp4kSZIUOganMEiu2BzC4CRJkiSFjcEpDFJK2pFHioganCRJkqTQMTiFQYWKU1HUNU6SJElS2BicwiClvB25FSdJkiQpfAxOYeAaJ0mSJCnUDE5hUKmrnlP1JEmSpLAxOIVBcioAaW6AK0mSJIWSwSkMSjbATaHYfZwkSZKkEDI4hUFSUHFKIWZzCEmSJCmEDE5hkJQMQDJRimKucZIkSZLCxuAUBkkpQFBxischZtVJkiRJChWDUxiUBKdkogBWnSRJkqSQMTiFQVnFKQhOrnOSJEmSwsXgFAalFadInAgxiuysJ0mSJIWKwSkMSppDACTbWU+SJEkKHYNTGJRUnCAITsWucZIkSZJCxeAUBhWCU6qb4EqSJEmhY3AKg19VnJyqJ0mSJIWLwSkMKqxxSiFKUdSpepIkSVKYGJzCIBKpsJeTFSdJkiQpbAxOYVFhLyfbkUuSJEnhYnAKi7K9nKJWnCRJkqSQSWhwevDBB+nRowdZWVlkZWXRv39/3nvvvQ1e/+STTxKJRCo9MjIyduCIt6OSdU4pxCiyHbkkSZIUKikbv2T7adGiBbfeeisdOnQgHo/z1FNPcdxxxzFu3Di6du263vdkZWUxZcqUsuNIJLKjhrt9la1xsuIkSZIkhU1Cg9OgQYMqHf/zn//kwQcf5Ouvv95gcIpEIjRp0mRHDG/HKlvjFLOrniRJkhQyoVnjFI1GeeGFF8jPz6d///4bvC4vL4/WrVvTsmVLjjvuOCZOnFjlfQsKCsjNza30CCUrTpIkSVJoJTw4TZgwgVq1apGens7FF1/M66+/TpcuXdZ7bceOHXn88cd58803eeaZZ4jFYgwYMIC5c+du8P5Dhw4lOzu77NGyZcvt9VW2Tskap1SiFNtVT5IkSQqVSDweT+hv6YWFhcyePZucnBxeeeUVHn30UT777LMNhqeKioqK6Ny5M6eddho333zzeq8pKCigoKCg7Dg3N5eWLVuSk5NDVlbWNvseW+2+3rD8F04s+AcX//YMDu3SONEjkiRJknZqubm5ZGdnb1I2SOgaJ4C0tDTat28PQJ8+fRg9ejT33nsv//3vfzf63tTUVHr37s20adM2eE16ejrp6enbbLzbTYU1TlG76kmSJEmhkvCper8Wi8UqVYiqEo1GmTBhAk2bNt3Oo9oBklKBYB8nN8CVJEmSwiWhFafrrruOI488klatWrFq1Sqee+45RowYwfDhwwE488wzad68OUOHDgXgpptuYu+996Z9+/asXLmS22+/nVmzZnH++ecn8mtsG2X7ONkcQpIkSQqbhAanxYsXc+aZZ7JgwQKys7Pp0aMHw4cP59BDDwVg9uzZJCWVF8VWrFjBBRdcwMKFC6lbty59+vThq6++2qT1UKFX1lXPduSSJElS2CQ0OD322GNVvj5ixIhKx3fffTd33333dhxRApWtcbLiJEmSJIVN6NY47bIqVpwMTpIkSVKoGJzCouIaJ6fqSZIkSaFicAqLsopTlGIrTpIkSVKoGJzCosI+TgYnSZIkKVwMTmFRGpwiUYqdqidJkiSFisEpLCqscbLiJEmSJIWLwSksKq5xihqcJEmSpDAxOIVFcirgGidJkiQpjAxOYVGh4hSNucZJkiRJChODU1iUrXGKUeRUPUmSJClUDE5hUaniZHCSJEmSwsTgFBYV25E7VU+SJEkKFYNTWJRVnGJ21ZMkSZJCxuAUFqUVJ/dxkiRJkkLH4BQWboArSZIkhZbBKSwqVpyirnGSJEmSwsTgFBYV1zhZcZIkSZJCxeAUFkmpgBUnSZIkKYwMTmFRssbJipMkSZIUPgansKi4j5PtyCVJkqRQMTiFRdkapyhRK06SJElSqBicwqKsq16M4phrnCRJkqQwMTiFRdkaJ/dxkiRJksLG4BQWFStOrnGSJEmSQsXgFBYV1jg5VU+SJEkKF4NTWJRVnJyqJ0mSJIWNwSksStY4BRvgGpwkSZKkMDE4hUXpVL1IzHbkkiRJUsgYnMIiORUIKk5FUdc4SZIkSWFicAoLN8CVJEmSQsvgFBZla5xiVpwkSZKkkDE4hYUVJ0mSJCm0DE5hUWED3CKDkyRJkhQqBqewsOIkSZIkhZbBKSwqbIAbjcWJxw1PkiRJUlgYnMKipDlEciRoDFFs1UmSJEkKDYNTWJRUnFKJAjhdT5IkSQoRg1NYVFjjBNiSXJIkSQoRg1NYVFjjBFacJEmSpDAxOIVFWcUpqDQVRQ1OkiRJUlgYnMLCipMkSZIUWgansFin4uQaJ0mSJCksDE5hUdpVLxIF4lacJEmSpBAxOIVFyT5OAEnEKY5ZcZIkSZLCwuAUFiUVJwjWObkBriRJkhQeBqewqBCckolSbFc9SZIkKTQMTmFRITilWnGSJEmSQsXgFBa/qjhFXeMkSZIkhYbBKSySkoAIACnE3ABXkiRJChGDU5gkpwY/iNqOXJIkSQoRg1OYlEzXS4nE3ABXkiRJChGDU5iUBCcrTpIkSVK4GJzCpGQT3BSirnGSJEmSQsTgFCZlFaeYFSdJkiQpRAxOYVK6xokoxbYjlyRJkkLD4BQmFSpOxU7VkyRJkkLD4BQmFdY4WXGSJEmSwsPgFCaVpupZcZIkSZLCwuAUJmX7ONmOXJIkSQoTg1OYVFjjZDtySZIkKTwMTmFSYape1DVOkiRJUmgYnMKkrOLkBriSJElSmBicwqSs4uQGuJIkSVKYGJzCpELFqTjqVD1JkiQpLAxOYVK2j1PMduSSJElSiBicwqRixcngJEmSJIVGQoPTgw8+SI8ePcjKyiIrK4v+/fvz3nvvVfmel19+mU6dOpGRkUH37t159913d9Bod4AK+zgV2xxCkiRJCo2EBqcWLVpw66238t133zFmzBgOOuggjjvuOCZOnLje67/66itOO+00zjvvPMaNG8fgwYMZPHgwP/744w4e+XZSoR15se3IJUmSpNCIxOPxUJU26tWrx+2338555523zmtDhgwhPz+fYcOGlZ3be++96dWrFw899NAm3T83N5fs7GxycnLIysraZuPeJl78LUx6i+uLziG253nccnz3RI9IkiRJ2mltTjYIzRqnaDTKCy+8QH5+Pv3791/vNaNGjeKQQw6pdO7www9n1KhRG7xvQUEBubm5lR6hVbHiZFc9SZIkKTQSHpwmTJhArVq1SE9P5+KLL+b111+nS5cu67124cKFNG7cuNK5xo0bs3Dhwg3ef+jQoWRnZ5c9WrZsuU3Hv00lpwY/bA4hSZIkhUrCg1PHjh0ZP34833zzDZdccglnnXUWP/300za7/3XXXUdOTk7ZY86cOdvs3tucG+BKkiRJoZSS6AGkpaXRvn17APr06cPo0aO59957+e9//7vOtU2aNGHRokWVzi1atIgmTZps8P7p6emkp6dv20FvLyX7OAUb4BqcJEmSpLBIeMXp12KxGAUFBet9rX///nz88ceVzn344YcbXBNV7VSoONlVT5IkSQqPhFacrrvuOo488khatWrFqlWreO655xgxYgTDhw8H4Mwzz6R58+YMHToUgKuuuor999+fO++8k6OPPpoXXniBMWPG8PDDDyfya2w7pRvguo+TJEmSFCoJDU6LFy/mzDPPZMGCBWRnZ9OjRw+GDx/OoYceCsDs2bNJSiovig0YMIDnnnuO66+/nr/85S906NCBN954g27duiXqK2xblfZxMjhJkiRJYZHQ4PTYY49V+fqIESPWOXfyySdz8sknb6cRJVjZGien6kmSJElhEro1Tru0Svs4WXGSJEmSwsLgFCZO1ZMkSZJCyeAUJgYnSZIkKZQMTmFScY1T1DVOkiRJUlgYnMIkKRUIKk5RK06SJElSaBicwqRsH6cYRVacJEmSpNAwOIVJhTVOVpwkSZKk8DA4hUnZGiebQ0iSJElhYnAKk7KKU8x9nCRJkqQQMTiFSekaJytOkiRJUqgYnMKkYsUpZnMISZIkKSwMTmFSFpyKiTpVT5IkSQoNg1OYlDSHSInEKLLiJEmSJIWGwSlMKqxxsh25JEmSFB4GpzCpsMapKBonHjc8SZIkSWFgcAqT5NTgB1EALDpJkiRJ4WBwCpPSNU4E65uKoq5zkiRJksLA4BQmFdY4Aa5zkiRJkkLC4BQmZWucguBUbEtySZIkKRQMTmFSVnEKpui5Ca4kSZIUDganMCnbx8mpepIkSVKYGJzCpEI7coAig5MkSZIUCganMPnVGqeoa5wkSZKkUDA4hUlpcCqZqlfkGidJkiQpFAxOYfKr5hCucZIkSZLCweAUJr+aqucGuJIkSVI4GJzCxA1wJUmSpFAyOIXJr6bqFdkcQpIkSQoFg1OYVAhOEWJWnCRJkqSQMDiFSckGuBCEp2LXOEmSJEmhYHAKk5KKE5QEJytOkiRJUigYnMKkQnBKIepUPUmSJCkkDE5hUqniFLUduSRJkhQSBqcwqbDGKdWKkyRJkhQaBqcwiUQgEoSnZGIUGZwkSZKkUDA4hU3JdL1gjZNT9SRJkqQwMDiFTXJq8CMSdQNcSZIkKSQMTmFTss4pxQ1wJUmSpNAwOIVNyVS9ZKJugCtJkiSFhMEpbMrWOLkBriRJkhQWBqewqVRxMjhJkiRJYWBwCpuyNU5RK06SJElSSBicwqas4hRzjZMkSZIUEgansCkJTqlWnCRJkqTQMDiFTVKwj1NqpNh25JIkSVJIGJzCJjUDgHQKKYo5VU+SJEkKA4NT2KRkApBBEVG76kmSJEmhYHAKm5KKUwaFrnGSJEmSQsLgFDYpJcEpUkixU/UkSZKkUDA4hU1q6VS9QjfAlSRJkkLC4BQ2KeXNIZyqJ0mSJIWDwSlsSitOkUI3wJUkSZJCwuAUNqVrnCiy4iRJkiSFhMEpbFzjJEmSJIWOwSlsSipOmRRYcZIkSZJCwuAUNhXXONmOXJIkSQoFg1PYVFjjFLXiJEmSJIWCwSlsSipO6a5xkiRJkkLD4BQ2pRUnp+pJkiRJobFFwempp57inXfeKTv+4x//SJ06dRgwYACzZs3aZoPbJVXsqudUPUmSJCkUtig43XLLLWRmBr/gjxo1iv/85z/cdtttNGjQgN/97nfbdIC7nLI1Tk7VkyRJksIiZUveNGfOHNq3bw/AG2+8wYknnsiFF17IwIEDOeCAA7bl+HY9VpwkSZKk0NmiilOtWrVYtmwZAB988AGHHnooABkZGaxZs2bbjW5XVLbGqYjiqGucJEmSpDDYoorToYceyvnnn0/v3r2ZOnUqRx11FAATJ06kTZs223J8u54KFSfbkUuSJEnhsEUVp//85z/079+fJUuW8Oqrr1K/fn0AvvvuO0477bRtOsBdTknFKZ1CiuyqJ0mSJIXCFlWc6tSpw/3337/O+RtvvHGrB7TLK93HKVJMvLg4wYORJEmSBFtYcXr//ff58ssvy47/85//0KtXL04//XRWrFixzQa3SyqpOAFEYoUJHIgkSZKkUlsUnP7whz+Qm5sLwIQJE/j973/PUUcdxYwZM7jmmms2+T5Dhw6lb9++1K5dm0aNGjF48GCmTJlS5XuefPJJIpFIpUdGRkaV76lWSipOAKmxggQORJIkSVKpLZqqN2PGDLp06QLAq6++yjHHHMMtt9zC2LFjyxpFbIrPPvuMyy67jL59+1JcXMxf/vIXDjvsMH766Sdq1qy5wfdlZWVVCliRSGRLvkY4JSUTT0olEisiKbY20aORJEmSxBYGp7S0NFavXg3ARx99xJlnnglAvXr1yipRm+L999+vdPzkk0/SqFEjvvvuO/bbb78Nvi8SidCkSZMtGHn1EE/JIFJYZMVJkiRJCoktCk777LMP11xzDQMHDuTbb7/lxRdfBGDq1Km0aNFiiweTk5MDBAGsKnl5ebRu3ZpYLMYee+zBLbfcQteuXdd7bUFBAQUF5QFkc4JdosRTMqBwFamucZIkSZJCYYvWON1///2kpKTwyiuv8OCDD9K8eXMA3nvvPY444ogtGkgsFuPqq69m4MCBdOvWbYPXdezYkccff5w333yTZ555hlgsxoABA5g7d+56rx86dCjZ2dllj5YtW27R+HaokgYRKU7VkyRJkkIhEo/HQ7HL6iWXXMJ7773Hl19+uVlVq6KiIjp37sxpp53GzTffvM7r66s4tWzZkpycHLKysrbJ2Le14vv6krJ8KqcV/pVn/+8PJCXtRGu4JEmSpJDIzc0lOzt7k7LBFk3VA4hGo7zxxhtMmjQJgK5du3LssceSnJy82fe6/PLLGTZsGJ9//vlmT/VLTU2ld+/eTJs2bb2vp6enk56evtljSqRIavkmuMWxOGkGJ0mSJCmhtig4TZs2jaOOOop58+bRsWNHIJgS17JlS9555x3atWu3SfeJx+NcccUVvP7664wYMYK2bdtu9lii0SgTJkzYrG5+oVfSkjyDIqKxUBQEJUmSpF3aFq1xuvLKK2nXrh1z5sxh7NixjB07ltmzZ9O2bVuuvPLKTb7PZZddxjPPPMNzzz1H7dq1WbhwIQsXLmTNmjVl15x55plcd911Zcc33XQTH3zwAb/88gtjx47lN7/5DbNmzeL888/fkq8STiUVpwwKKYrFEjwYSZIkSVtUcfrss8/4+uuvK3W/q1+/PrfeeisDBw7c5Ps8+OCDABxwwAGVzj/xxBOcffbZAMyePZukpPJ8t2LFCi644AIWLlxI3bp16dOnD1999VXZvlI7g6TSilOkkGjUipMkSZKUaFsUnNLT01m1atU65/Py8khLS9vk+2xKX4oRI0ZUOr777ru5++67N/kzqqWyqXpWnCRJkqQw2KKpescccwwXXngh33zzDfF4nHg8ztdff83FF1/Mscceu63HuMuJpJQHJ9c4SZIkSYm3RcHpvvvuo127dvTv35+MjAwyMjIYMGAA7du355577tnGQ9wFla5xihRS7FQ9SZIkKeG2aKpenTp1ePPNN5k2bVpZO/LOnTvTvn37bTq4XVZKeVe9YitOkiRJUsJtcnC65pprqnz9008/LXt+1113bfmIVLbGKZ1CiqOucZIkSZISbZOD07hx4zbpukjEzVq3WoV25FacJEmSpMTb5OBUsaKk7SylQjtyg5MkSZKUcFvUHELbWcUNcJ2qJ0mSJCWcwSmMbEcuSZIkhYrBKYzKKk5FFNmOXJIkSUo4g1MYucZJkiRJChWDUxhVXOMUc42TJEmSlGgGpzBKKd/HKepUPUmSJCnhDE5hVFpxihRSbMVJkiRJSjiDUxhV6KrnBriSJElS4hmcwqhCV71ip+pJkiRJCWdwCqOKFSc3wJUkSZISzuAURiUVp6RInHhxQYIHI0mSJMngFEYlFSeAWNGaBA5EkiRJEhicwik5lVjJP5pI8doED0aSJEmSwSmMIhGKImkAxK04SZIkSQlncAqpoqR0wIqTJEmSFAYGp5AqDU4YnCRJkqSEMziFVHFpxanI4CRJkiQlmsEppMqCU9Q1TpIkSVKiGZxCqtg1TpIkSVJoGJxCKppUsgmuwUmSJElKOINTSEWTg4pTUtTgJEmSJCWawSmkyipO0YIEj0SSJEmSwSmkrDhJkiRJ4WFwCqlYSmnFyeAkSZIkJZrBKaxKg1OxU/UkSZKkRDM4hVVqJgCRYvdxkiRJkhLN4BRSSSXByeYQkiRJUuIZnEIqkl4LgPRoXoJHIkmSJMngFFKxmo0AqF28PMEjkSRJkmRwCqlI7SYA1ImtSPBIJEmSJBmcQiq5dmMA6hqcJEmSpIQzOIVUSnYQnLLJA1uSS5IkSQllcAqptFr1KYwnBwf5SxI7GEmSJGkXZ3AKqcy0FJZQB4BY7qLEDkaSJEnaxRmcQiozLZkl8WwAinIXJHg0kiRJ0q7N4BRSGSnJLInXAaAoZ2FiByNJkiTt4gxOIZWUFGF5pA4A0VyDkyRJkpRIBqcQy0mqC0A8b3GCRyJJkiTt2gxOIZabUg+AiMFJkiRJSiiDU4itKglOSfkGJ0mSJCmRDE4hlp9aH4CUNQYnSZIkKZEMTiG2Oi0ITqlrlkI8nuDRSJIkSbsug1OIFaQ3ACAlugYK8xI8GkmSJGnXZXAKsUh6LfLiGcGBDSIkSZKkhDE4hVhmWjJL4tnBQd6ixA5GkiRJ2oUZnEIsMzWJJdQJDgxOkiRJUsIYnEIsM7VixcmpepIkSVKiGJxCLCMtmSXxOsGBFSdJkiQpYQxOIRZUnOoEBwYnSZIkKWEMTiGWmZrMEpyqJ0mSJCWawSnEMitN1TM4SZIkSYlicAqxDJtDSJIkSaFgcAqxzNRkFsXrBQd5C6EwP7EDkiRJknZRBqcQC9Y41WFpUgOIx2De2EQPSZIkSdolGZxCLDMtGYCfkjsGJ+Z+m8DRSJIkSbsug1OIZaQGwel7SoLTnNEJHI0kSZK06zI4hVhmSXAaG+sQnJj7LcTjCRyRJEmStGsyOIVY6VS974tbQXI6rF4Gy39J8KgkSZKkXY/BKcRKK065RUnQrFdwco7rnCRJkqQdzeAUYqUVp+JYnGjzvsFJG0RIkiRJO1xCg9PQoUPp27cvtWvXplGjRgwePJgpU6Zs9H0vv/wynTp1IiMjg+7du/Puu+/ugNHueKUVJ4C1TfoET2wQIUmSJO1wCQ1On332GZdddhlff/01H374IUVFRRx22GHk5294o9evvvqK0047jfPOO49x48YxePBgBg8ezI8//rgDR75jpCZHSE6KALC60R7BycUToWBVAkclSZIk7Xoi8Xh42rQtWbKERo0a8dlnn7Hffvut95ohQ4aQn5/PsGHDys7tvffe9OrVi4ceemijn5Gbm0t2djY5OTlkZWVts7FvL93+MZy8gmJGXHsAbf63N+TMht+8Bu0PTvTQJEmSpGptc7JBqNY45eTkAFCvXr0NXjNq1CgOOeSQSucOP/xwRo0atd7rCwoKyM3NrfSoTkr3clpTFIXdSsLkpLcTOCJJkiRp1xOa4BSLxbj66qsZOHAg3bp12+B1CxcupHHjxpXONW7cmIULF673+qFDh5KdnV32aNmy5TYd9/aWmRb8I1pTFIVuJwYnf3oTokUJHJUkSZK0awlNcLrsssv48ccfeeGFF7bpfa+77jpycnLKHnPmzNmm99/eShtErC2MQpv9oGZDWLMcfhmR2IFJkiRJu5BQBKfLL7+cYcOG8emnn9KiRYsqr23SpAmLFi2qdG7RokU0adJkvdenp6eTlZVV6VGdZFacqpecAl0GBy/8+GriBiVJkiTtYhIanOLxOJdffjmvv/46n3zyCW3btt3oe/r378/HH39c6dyHH35I//79t9cwE6rSGieA7icFPycNg6I1CRqVJEmStGtJaHC67LLLeOaZZ3juueeoXbs2CxcuZOHChaxZUx4IzjzzTK677rqy46uuuor333+fO++8k8mTJ3PDDTcwZswYLr/88kR8he2udBPcNYUlwalFP8hqAYWr4OcPEzgySZIkadeR0OD04IMPkpOTwwEHHEDTpk3LHi+++GLZNbNnz2bBggVlxwMGDOC5557j4YcfpmfPnrzyyiu88cYbVTaUqM7K1jiVVpySkqDb8cHzH17cwLskSZIkbUspifzwTdlCasSIEeucO/nkkzn55JO3w4jCJ/PXU/UAep0BX/0bprwHOfMgu3mCRidJkiTtGkLRHEIbllE2VS9WfrJRZ2i9D8Sj8N0TG37z6uWQO387j1CSJEna+RmcQm69FSeAfucHP797CooL131jPA6PHAj394O11WvTX0mSJClsDE4ht84ap1KdjoFaTSB/MUx6a9035s6HFTODJhJLf97+A5UkSZJ2YgankFunq16p5FToc3bwfPSj675xyeTy5ytnbpexSZIkSbsKg1PIrbOPU0V9zoZIMsweBQt/rPxapeA0e/sNUJIkSdoFGJxCboNrnACymkLnY4Lnv646VQxOK2Ztp9FJkiRJuwaDU8hlpgX/iNZZ41Sq7wXBzx9egrU55eeXTCl/vtLgJEmSJG0Ng1PIlVWcfr3GqVSbfaBhZyjKh+9fCM7F47DYipMkSZK0rRicQq7KNU4AkQj0PS94PvrRIDStWggFFapPOXMgFlv/+yVJkiRtlMEp5Kpc41SqxxBIqwVLp8KMz8vXN9VtGzSPiBbCqgU7YLSSJEnSzsngFHKl7cjXbmiqHkBGVhCeAL57sjw4Ne4K2S2C565zkiRJkraYwSnkNqniBNDnrODn5GEwa2TwvGEnqNs6eO46J0mSJGmLGZxCrnSNU35VFSeApj2haa9gWt6kt4NzjTpDnZLg5F5OkiRJ0hYzOIVcvZppABQWx8grKK764tKqU6mGHcsrTk7VkyRJkraYwSnkaqanUDs9BYBFuWurvrjbSZBaI3geSYL6HaBOm+DYqXqSJEnSFjM4VQONstKBTQhOGVnQ9YTged22kJoBdVoFx1acJEmSpC1mcKoGGtXOAGDJqoKNXzzgcsisB91ODI5Lp+rlzoNo0XYaoSRJkrRzS0n0ALRxjTe14gRBQ4g//hJsjAtQqzGkZEDx2mAj3Hq7rfue4kJISduGI5YkSZJ2LlacqoHGWUHFaVHuJlScoDw0lT4vna7363VO8Th8egvc0hQmvLINRipJkiTtnAxO1UDD2ptRcVqf0pbkK2ZUPv/57fDZvyBWDD++thUjlCRJknZuBqdqoLTitHhT1jitT7Newc+xTwdVJoCv/g2f/rP8mjnflL8mSZIkqRKDUzVQFpy2tOK018WQVgvmjws2x53xBXzwt+C1/f8Myemweiksm76NRixJkiTtXAxO1UB5c4gC4ltSFarZAPa+NHj+8U3w2gVAHHr9Bg68DprvEbw2e9S2GXDRGvjoBpg7ZtvcT5IkSUowg1M1UNqOfE1RlLyC4i27yYDLIbMuLPsZVi0INsc96rbgtVZ7Bz/nfF35PQWrgnVQufM377MmvwNf3h2EJ0mSJGknYHCqBjLTkqmdEXSO3+TOer+WkQ37/C54npwGJz0OaTWD45YlwWn2N5Xf89lt8Mn/wcc3b95nLS9pQrFy9paNVZIkSQoZ93GqJhpnZbBqbR6Lc9fSvlGtLbvJXhfDmpXQci9o2qP8fMt+wc9lP0P+MqhZPzie8m7wc+63m/c5OSWBadWCoOFExfbokiRJUjVkxamaKFvntGoLG0QApKTDIf+AjkdUPl+jHjToGDyfU1J1WjIVlk0Lni+bBmtWbPrnrJwT/IwWwuplWz5eSZIkKSQMTtVE6TqnxVs6VW9jWu0V/Cxd51RabSo1b+ym3ytnTvnz3HlbNy5JkiQpBAxO1USjCp31tovSdU4zvgim1015LzhOyQx+bmpwischZ275ce6CbTdGSZIkKUEMTtVE45KK01ZN1avKbvtDUgrMHwuf3Fw+Za/f+cHPeZvYWjx/CRRXGKMVJ0mSJO0EDE7VxFZvgrsx2S3g8FuC51/cCcShaU/ofGxwbt53QTVpY1bOqXy8yoqTJEmSqj+DUzVROlVv8artNFUPoN+F0P2U8uOOR0GT7kElKn9J5bVLG5Lzqxbkm7sHlCRJkhRCBqdqomyqXu5a4ptS+dkSkQgMuhea9gr2eup6AqRmQuNuwetzN2G6XmnFKamk073BSZIkSTsBg1M1UVpxWlsUI3dt8fb7oLQacN4H8LuJ0HD34FzzPsHPed9t/P2lVakmJftEVRWcvn0E3r4aYrEtHq4kSZK0IxicqomM1GSyMoIqznZb51QqJR1qNSo/brFn8HP6J/Dzh5BTRcOH0opTq5IufRta4xSLwYd/h++egAXjtn7MkiRJ0nZkcKpGyhpEbM91TuvTom/wc/FP8OxJcHdX+OgGiBate21pxallv+BnQS4UrFr3uty5ULQ6eL58xjYfsiRJkrQtGZyqkRZ1gz2Vpi3O27Ef3KADHHUHdDoGGnYG4vDl3fD44bDyV80gSitODTtDenbwfH17OS2dWv58hcFJkiRJ4WZwqkZ6tawLwLjZK3b8h/e7AE59Fi77Gk5+CjKygzVPz58OxYXBNWtzoCAneF6nJWQ1DZ6vby+npT+XP18xc7sOXZIkSdpaBqdqpHerOgCMm7MyoeOg62C4+EuoUR8WTYAv7gjOl1abMutBWk3IahYcr69BRMWK0/KZ23O0kiRJ0lYzOFUjPVvWAWDWstUsy9vB65x+rU4rOPrO4Pnnd8D88eXrm+q0DH7WLglOq9YXnCpWnJyqJ0mSpHAzOFUj2ZmptG9UC4Dxia46AXQ9PnjEo/DqeTDji+B8dklw2tSKU+58KNrOnQIlSZKkrWBwqmZ6l1Sdxs1emdBxlDnqTqjdFJZNg6//E5xbJzj9qjnEmpWQtyh4npIBxNdtMiFJkiSFiMGpmundqqRBxJwENIhYn5r14fyPoeVe5efq/Do4/ao5xLJpwc/aTaF+h+C50/UkSZIUYganaqa0QcT3c3KIxuKJHUyp7OZw9juwz++gcTfY/YjgfGlw+vUmuKXT9Bp0gHptgufu5SRJkqQQMzhVM7s3rk2NtGTyCop3/H5OVUlOhUNugEtGQv12wbnS5hD5S6BoTfm1pcGpfgeo2zZ4bktySZIkhZjBqZpJTorQs0UdIEH7OW2OGvWgZsPg+bt/gHhJhay0o16D3aFum+C5U/UkSZIUYganaqh0ut6YWSEPTpEIHHs/RJJg3P9g5D3B+UpT9UoqThuaqldcCD+8FGyuK0mSJCWIwaka6t+uPgCfTF5McTSW4NFsRMcj4Ih/Bc8/ugGG/xWW/xIcN9i98lS92Hq+y2e3wmsXwMc374jRSpIkSetlcKqG+u9Wn3o101ieX8hX05clejgbt9eF0P/y4Pmo+yFWDKk1IKs5ZLeASDJECyBvYeX3RYth3DPB82kf7dgxS5IkSRUYnKqhlOQkjureBIC3v1/P5rJhdNj/wRmvQIOOwXGTHpCUFDSVKG1fPvkdeO1C+PaR4Hj6x+X7Pa2Y4V5PkiRJShiDUzV1TI+gY937ExdSUBxN8Gg2QSQCHQ6FS76CIc/CiY+Uv1Y6Xe/da+GHF4OfM7+E8c9WvseML3bceCVJkqQKDE7VVN829Wiclc6qtcV8MXVpooez6ZJToPMxUKdV+bnS9uUAdVoHP9+4BKa8FzzvcHjwc8bnwc+cufD9izD7G1gT8gYZkiRJ2ikYnKqp5KQIR3cPqk5v/1BNputtyF6XwB5nwVlvw8VfQnbLYFpetDCY0tf/0uC6GZ8HXfb+dzy8fiE8fhj8qy18fFNixy9JkqSdnsGpGjumZ1MAPvxpEXkFxQkezVZo0B6OvQ/a7gcZWcHzUr1/Ay33guQ0WDUfhl8XtDNPqxU0lyAOX9wJX92fsOFLkiRp52dwqsZ6t6zDbg1qsrowyutj5yZ6ONtOu4Pg4L9Dh8Og52mQmhmEJ4DRjwY/D/8nXPMTHFpSbfrgrzDhlcSMV5IkSTs9g1M1FolEOLN/sCboya9mEo/HEzyibWjf38MZLwcVKIA2+5a/1rg79P5t8HzAlbDXxcHzNy+HvMXB81gUxj8HK2btuDFLkiRpp2VwquZO7NOCWukpTF+Sz5fTqlGTiM3Vdr/y50cMhaTk4HkkAoffAs32gOI18M1DwfmR9wQNJp44sjxMxeNQsGqHDluSJEk7B4NTNVc7I5WT+rQA4KmvZiZ2MNtTy72g34XBFL62+1Z+LSk5qFABfPsoLJkKn98ZHOfOgxd/C0umwBNHwa2tyrv1SZIkSZsoEt+p5ndtXG5uLtnZ2eTk5JCVlZXo4WwTvyzJ46A7PyMSgRHXHkDr+jUTPaQdLxaDB/aGpVOgZkPIXwKNu8HKOVCQU/naFn3h/I+C52tzoGgN1G6y48csSZKkhNqcbGDFaSewW8Na7L97Q+JxeGLkzEQPJzGSkmCfq4Pn+UuCn8feByc9BkSC49YDISkV5o6GBT9AYT48fADctwcsmx5cE4/D9y/AvLE7+AtswKRh8Mn/BcFQkiRJCWNw2kmcv29bAF4aM4eVqwsTPJoE6X5ysAcUQM/ToXkf6HAo/PY1OOkJOGtYsPkuwHdPwOe3w/JfoCgfPrstOD/+WXj9InjmRChcnZjvUSoeh7evDMY584vEjiUs5o+Hp44NT7CVJEm7DIPTTmKf9g3o1KQ2qwujPPvN7EQPJzGSU+H4/0Kfc4J25aXaHQTdTgiqUnueG5z7/gX46t/l10x4CeZ8Cx/+PTheszwIUaUK86v+7OW/wAtnwLBrgsCzLeTMhdXLgueLftw296zuxj8LMz6DsU8leiSSJGkXY3DaSUQiES7cbzcgaE1eUBxN8IgSpM1AGHQP1Ki3gdf3hfrtoWg1xIph9yOh0zEQj8HTxwVBJTk9uHbU/UFb86/+Dbc0h1H/Wf89v38BHtoXJg+DMY/BgvHb5rtUvM+iidvmntVdzrzg5/IZiR2HJEna5RicdiKDejajSVYGS1YV8NrYeYkeTjhFIuVVp5RMOPJWOODPwXFRydS8Ic9AjfqwYmawN9QH1wNx+PQWyFtS+X7jngmm9hXmlQeu71/cNmNd8H35cytOgdySjZ4NTpIkaQczOO1EUpOTOHefNgD8/c0fefjz6cRiceavXMOEuTk71wa5W6PPObDneXDCw1C3DTTpDl0GB691Owl2Pwz6XhAcf/9c8DMlMwhHn99efp81K+HDfwTP+18OJz8ZPP/xFYgWb/04548vf7548ra5Z3WXOz/4mTMHigsSOxZJkrRLMTjtZM7s34YjuzWhKBrnlncn0+PGDxhw6ycMuv9LXv5ubqKHFw5pNeCYu6DLseXnjr0PBt0b/ATodwGkZATPdz8STisJUGMeD9YzQRCiVi+FBrvDITcEjShqNAi6+k3/ZOvGGI9XnqoXLYDl07funtVdcUF5x0TisHIXXcsnSZISwuC0k8lITeaBM/Zg6AndyUhNIq+gvErxzg8L1rl+Qc4abnhrIoty1+7IYYZPRjb0ORvSSvbAqtkAjr0/2HT3xEeDBhPtDoZYEbx2EYx+FL55KLj28KFBY4rkVOh+UnDuhxc2/pnRog2/tmpBEBIiScF+VOB0vdJqU6nSACtJkrQDJDQ4ff755wwaNIhmzZoRiUR44403qrx+xIgRRCKRdR4LFy7cMQOuJiKRCKf1a8WXfzqINy8byFuXDwTg61+WsbaoctOI+z6expNfzeS+j39OxFDDrcfJcNTtkF4rOD7khpJ9oL6Fd34fNJfocBh0OKTCe4YEPye/A6sWVb5fLAbTPoa3roAH+sPNDeH1S9b/2aXrmxp2ghZ7Bs939QYRub9at2dwkiRJO1BKIj88Pz+fnj17cu6553LCCSds8vumTJlSaWffRo0abY/hVXsNaqXToFY68XicZtkZzM9Zy9e/LOOAjuV/XmNnrQBgzMwViRpm9dG0B1zwMUx4JZiKV5gHR9xa+ZpmvaFBR1g6Be7uGkzfq9MqCFnTP1n3l/3vn4Nep0PbfSufLw1OTXtWqDjt4sEp59fByQYRkiRpx0locDryyCM58sgjN/t9jRo1ok6dOpt0bUFBAQUF5YvIc3NzN/vzqrtIJML+HRvy/LdzGDFlSVlwWrW2iKmLVwEwdfEqclYXkV0jNZFDDb+mPYMHN6//9UgEBj8Iw66GhT/AlHcrv56eFVSl2h0YvDbuGXj/OrjoM0hKLr+utDFE057QuGvwfFcPTqUVp6SUIIhacZIkSTtQQoPTlurVqxcFBQV069aNG264gYEDB27w2qFDh3LjjTfuwNGF0/67N+L5b+fw2dTydtrfz8kp26s1Hoexs1dwYCerd1utRR+4+AtYPCmYsle0OlirVKc1dD2+fOpfy73hp7dh0QT4/I6gAcSC74Ppf/PHBdc07QWNOgfPc+YEnfwy6yTgS4VAaXBq3gfmfAMrrDhJkqQdp1oFp6ZNm/LQQw+x5557UlBQwKOPPsoBBxzAN998wx577LHe91x33XVcc801Zce5ubm0bNlyRw05NAa2r09KUoQZS/OZtSyf1vVrMm525el5Y2YtNzhtS406l4ee9alZHw74Ewz/C4y4pfz8tI9KnkSgSTdIrw3ZLYPgtPgnaD2g8n1i0aBClZQEmXUhq3nQqGJnUzpVr80+JcFpVtCiPbla/c+YJEmqpqrVbxwdO3akY8eOZccDBgxg+vTp3H333fzvf/9b73vS09NJT0/fUUMMrdoZqfRpXZdvZizns6lLOLN/TcbNWQlA56ZZTFqQy2jXOe14fS+A718IAlH7Q4JGEOOeDaopzfsEoQmC6Xo5c+DdPwRt0mvUh5b9SkqFTwWvlcqsB3uW7FWV3bzqzy9aCynpwRTDsCutOLXoG2w2HC0INsSt2yahw5IkSbuGahWc1qdfv358+eWXiR5GtXBAx0Z8M2M5H/60iN/u3bqs4nTBvm255qXv+X7OSgqLY6Sl2KV+h0lJg/M/ClqTl07h2+camDu6ciBo3gemvl+5JfnPw8ufp2cH+1OtXg5rlsMXd8KXd0Pb/aDzscEeSIsnQu2mMOCKYK3V6Efhg+uDBhYnP1V5jVUYlQan7JbBn83SKUGDCIOTJEnaAap9cBo/fjxNmzZN9DCqhcO6Nub24ZP54uelvDB6DitWF5GWksTRPZpy87CfWLG6iB/n57BHq7qJHuquJSU9eJRKSoZWe1e+Zu9LgipTUkrwM2dOMF2tYBV0Owm6DobUzGDq2pR3gz2mZo2EX0YEj4rG/g9a9oVJbwfHk96GEbfCQX9dd2zxeNANcM0K6HZieWVq7ndQqxHU+dW011gMxjwWBLOeQ7biD+VXitbA6mXB86xmUK9tSXD6JWi0IUmStJ0lNDjl5eUxbdq0suMZM2Ywfvx46tWrR6tWrbjuuuuYN28eTz/9NAD33HMPbdu2pWvXrqxdu5ZHH32UTz75hA8++CBRX6FaadewFqfv1Ypnvp7N398MKhfdm2eTnpJMn9b1+GjSIr6bucLgFEbptaHveZXP7b2ePaCSU6DLscFj+S8w8fVg76jMutCwI0x8A5ZPD8JSJCloVvHjq/D5bZCcFjSqmPsdNOgQtF+f+gEsmRTce863cOS/4Mu74OObIKMOXPJV+XTAWAyGXQVjg39fWTIZDv77tpkGWLr5bWqN4LvU2y04trOeJEnaQRIanMaMGcOBB5b/1+LSJg5nnXUWTz75JAsWLGD27NllrxcWFvL73/+eefPmUaNGDXr06MFHH31U6R6q2u8P7ciwHxawcnURAHu0qgNA3zZ1+WjSIkbPXM4F++1W6T1ri6Kc+fi3tKiTyV1Deu3gEWuL1dsN9v198Ci13x+DKXzTPoID/wLtDw4qWN8+DJ/+X/l1uXPhl0+D52m1gj2rvv0vzPsO5o0Jzq9dCW9eBr95DYjD21fBuP8BkeD4y7uCjoJH3Lr14al0ml5W8+BepcFpxcytu68kSdImSmhwOuCAA4iX9sNejyeffLLS8R//+Ef++Mc/budR7dzq1kzj94d15G9vBBWn3iXVpb5t6wHw1fRl6+zn9PnUJXw7YznfAn89ujP1a9lso9pKzYADrwsepQ77J+TMDdqndz4G2h0cVKUWfA/1O8AeZ8Kkt+CtK8pD016XwHdPBuHq3Wth9tfBGqpIEhz/MBTkwDu/D6YM1m4K+1wdvC9vcTD9r3bj4HjNiqAVe6v+wWdvSGlHvaxmwc+6bYOfiybaWU+SJO0Q/raxCzq9Xyve+WE+0xbn0X+3+gD0alGHTk1qM3nhKh4bOYNrDt297PqPJi0qe/793JUc1Cn4pXfO8tU0zsqwmUR1l5IGpz1f+dyv1w3tcWYQij77Fwy4EvpdAPXbBaFpzGPBNRnZMOjeYPofBAHp3WuDaX2t+gdNK14+J3jt1Geh9UB4/jSYPQpG3R/c95Ab1t+koqwxRIvgZ9OeQXfBFTPg9QvhhEfC39xCkiRVa/7GuwtKTorw7Pl7881fDqFuzTQAkpIiXHlwBwCeGDmDnDXBVL5YLM4nkxeXvXf8nBwAPp60iH1v+5Q7Ppiyg0evhOn9G7h6QhCaAPqeH3TsS8kIOvVdOb48NJW+3u0kiEfh+VPhhdOheE3weP5UePq4IDSlZATXf3UfPHsy5JVs0hwtCtZfLfqp8lQ9gFoNSzoBpgTXvH4x5C/dIX8MkiRp12TFaReVnLTumpMjujahY+PaTFm0ise/nMHvDt2d8XNXsjSvsOya8SV7P70+LvhF9oOJC/nLUVVs8qqdVyQCpzwdbMC7vqlykQgMugfmjwum/kEQvgpWwU9vwpyvg4YUZ7wcTOF783KY/jE8OAD2vQbGPA5Lp0JSKtQIppJW2peq4xFw0hPw8tkw4aWgEUbHI4N1W837QMNOO+dGwJIkKSEMTiqTlBThioPbc/lz43h85Ax+2781H/0UTNPbrWFNflmSz/dzVlIcjfHFz8F/3Z+5bDXL8gpc97SrikSqXl+UXhuG/C9Y79TxyGA6XiwKGdcEQWfQPcFeUwCNOsMr5wVd/N7/c3AuJTOoUOWVTBfN+tWGvl2OhdNegBG3BAFt0lvBA4LAVa9t0E2wRd/gUbNhENbSawddAZMqFN1jUfjmv1CYHzTUSLIgL0mSykXiVXVn2Anl5uaSnZ1NTk4OWVlZiR5O6MRicY689wumLFpFt+ZZrC6I8svSfO44uSd/eX0ChcUx7jqlJ9e89H3Zex47a08O7tw4gaNWtRSLrrsuqWgNfPh3+P5F6H0G7P+noHX6e38KAtRVP6y7d1SphRPgx9eCBhbzx0NBbtWfn5QSBLE9zoQeQ2DY72Dah8FrR94Oe1241V9RkiSF2+ZkA4OT1jF9SR6nPDSKZfnBFL2UpAjfXX8o5zz5LWNnr6Rtg5rMWJpfdv1lB7bjD4d3KjuOxeK8MX4e/drWo0XdGjt8/NoJxOOVW5jnLgg2wG3SbdPeH4sF66KW/RwEqjnfBmGqcBUUFwYhbH0iSRCPBftFXfJVULH69Vg25bOtVkmSVC1sTjZwqp7W0a5hLZ46tx+nPfw1qwqK6de2Htk1UunVsi5jZ68sC019Wtflu1krGDtrZaX3v/3DfK556Xs6N83i3Sv3IbItNkDVruXXf2eymgaPTZWUFFSm6rSEdget+3pxIaxeCjM+D/a1WjIZsloE3f6G/xVmfQmvXQDZLWHysKAy1fe84F6584P9o1bMDMJZm31hz3ODMY9+FD6+GQ66vryJhiRJ2ikYnLRe3Zpn88Q5fbnjgylcfmB7AHq2zK50zdWHdOC3j33L93ODdU8pycF/Zf94UtCFb9KCXL74eSn77d5wxw5e2piUtGBPqJ6nQvdTgul9DTsGLdWPuz9oUDF3dPCAoO35B9ev/14TX4f5Y6Fpr6D9OgThq91BQcv2WDTYr6pmg00b29qcoMqVWWdrv6UkSdqGnE+iDdqzTT1euLA/A9oHv/D1blm37LUuTbMY2K4BtdNTWF0YZcqiVUAwTe/LaeVtoR/54pcdO2hpcyUlQct+QWiCYHreoHuDTXb3PA/O/xgG3RfsHZVWGxp1hY5Hw96XBW3YI0kw7pny0FSjAUQL4J1rYMUseHh/uL09fDo0mMZXUe58mDQsCFcQhKaH9oE7Owb3lCRJoWHFSZusZb1M6tVMY3l+Ift3bEhSUoRererwxc9LGTt7JV2bZTNxfi7L8wvJTE2moDjKFz8v5af5uXRp5noyVSM9TgkepVrsCX3OWv+1rfeBV86BotWw1yXBFL0HB8AvI+CBvYPzAJ/dGlSmjrod6raBye/AG5cEYan/5XD4P+Gz22Dl7OD6Ny8LKl5H3h5UyCRJUkJZcdImi0QiDOrRlIzUJAb3CtpC924VVKHGzV4BwOc/B5uX7tOhAUd1D9akWHXSTq3jEXDxl3Dai3DE0GB63n4l1aei1cEUviP+FWz0+/MHcG9PuKdHsCHw2mBDaUbdD18/BN88FBx3OwmIwHdPlrdmlyRJCWVw0mb5x6CufP+Pw+jYpDYAe7SqA8DYWSuIx+N8NjUITvvt3pCL9msHwNvfz2fxqrXr3CsWi1NQHN0xA5e2p/rtggBV2tRiwFWwx1lBJenc92Hvi+G8D4NGEpFkWDkruK7/5UFjCYD3/wSxYuhwOJz0GAwpmao35rFgOt/aXHj7anj+NFizsvyz16yAaNH6x1VcANHi7fGNJUna5ThVT5slKSlCeoW9d3q3rEtqcoSZy1Zz94dTGTsrqDzt36EhrerXoGfLOnw/ZyXvTVjIWQPaVLrXbx//hikL83jr8oE0q5O5I7+GtH2lpMGx91U+17QHnD0sqDLNHBl0CWzWG4rWwuxvYPHEYNPeI4YG13c+JlhD9dW/4a3Lgw17V8wIXnvtgmDj38nvwKvnQ/32cO57wTqt4kL44UX46U2Y8VmwsfC5wyHVf8ckSdoaVpy0VbJrpHLdkZ0BuO+TaRTH4rSuX4NW9YP9m47t2QwIqk4V/bIkj5HTlrE0r4B/f/Lzjh20lEgZ2dDpqCA0AaRmwMlPBM0nDrs5qF6VOujvwVS/NSuC0JTdsnzK3/OnwctnB40oFk8MAlT+Mvjf4CBoTfsQooWw4Hv4+KYNj2fME0FDiqX+eyhJUlUMTtpq5+7TlvP3aVt2vF+H8vbjx/RoSiQCY2atYN7K8k1HP/hpUdnzl8bMZWaFDXWlXU7DjnDR57D3JZXPp6TBSY9D425B2/SLv4Bj/x289vNwiEdh9yPLw9R9vWDWSEjPggOvD7oDAnz9QLBn1a+tmBWsoVo4AT7423b9ipIkVXcGJ20TfzmqMyf0bk5yUoTBvZuXnW+clcFebesBMKxC1Wn4xIUA1EpPIRqLc/dHU3fsgKXqon47uGQknPgIZNYNuv0NvDp4re/5cOpzcNx/guOC3GAj33OHw/5/gD5nBw+ANy6FWaOCPaJKfXA9FJesP5z6Hsz9Lni+ejn8/FFQjfr6QShcvQO+qCRJ4RaJxyv+v+jOLzc3l+zsbHJycsjKskX2tra2KEpGanKlc89+M4u/vv4j3ZpnMeyKfVmcu5Z+t3wMwBNn9+WcJ0cTicC7V+5L56b+M5E2yerlUKNe+fGYx2H213DIjcH6qVIFefDQQFgxMzhu2hN6/xZq1A/aqEeSoNUAmPUltDsY9r4UXjkXCnLK79Hn7PLqlSRJO5HNyQZWnLRN/To0ARzZrSkpSRF+nJfL9CV5ZdP0erWsw4GdGnF096bE4/DgiOk7erhS9VUxNEHQne+EhyuHJoD0WnDWMNjjzGBK34Lvg816Xzmn5H3nwXH3Q1IKTP8Ynj0pCE11WgVBCuC7p2DumO3/nSRJCjGDk7a7ejXT2KdDAwDOf2oML4wONvg8vGsTAC45IFgM/86EBcyvsA5K0jZSp2WwNuqaSXD4LdB8z+B8rcZw4F+gXlvo/ZuSi+NByLp8DPz2Neh5WnBu2O+CqtXwvwZt0QtdlyhJ2rU4VU87xLTFqzjr8dGVGkR88vv92a1hLQBOe/hrRv2yjIv2243rjupcds1P83O5ffhkLj+oPX1a11vnvpK2UO4CSEkvr1zlLw3WPLUeGISo0j2p8hbD/XuWb9Zbqu1+cPpLULAKRj8KTXoELdRLrVkRNKlIWrcKLUlSWGxONjA4aYdZllfAlS+MY+S0ZXRsXJvhv9uv7LWPJy3ivKfGUDsjhVHXHUyt9BRy1xZx9H1fMGf5Gro2y2LYFfsQKf1lTtKOM/pReOf3wfPW+8CC8VCYF4Sl5b8EzyFYX9XnbBh2NUx8Pdh7qt2BwTTCtvut/96SJCWQwakKBqfEKo7GeGfCAro3zy6rNgHEYnEOueszflmaz1+O6sQF++7GVS+M560KnfieO38vBrRvkIhhS7u2eBwmvQ1ZzaFFH5j1FTxzIhSVdNur0wpWBlNwychetzqVlAJnvAztDoJ538GntwSb9nY4DNrsE1S+JElKAINTFQxO4fXM17O4/o0fAWhZL5M5y9eQnBShX5t6jPplGQd0bMiT5/RL8CglATBzJIz6D3Q7AbqeAF//J5jqB1C3DRz/cPD8q/tg8jBIqw37/R5G3FreAh2C0HXq89Ck2w7/CpIkGZyqYHAKr7VFUa57bQLDfphPUTT4a/mHwztyTI+mHHjHCGJxGH71fnRsUrvS+2Yty+fLaUtpU78mA61ISYkz5T1Y8AP0vxTSS/49LS6A/50QtDsv1e5gyG4eXJ+/BFJrBh0BK66RkiRpBzA4VcHgFH45a4r4ZPIi1hTGGNK3JclJES599jvenbCQ43o1454hvYhEInw1fSnXv/EjvywJunslJ0UYce0BtKxXI8HfQFIla1bAY4fD0imw92Vw2M1B04jVy+Hls2HGZ8F1LfpCjyHBRr+rl0FqDWjZD+p3gCSbwEqStj2DUxUMTtXTuNkrOP6BrwA4rEtj+rWtx63vTaY4FiclKULtjBRWrC7irP6tufE4p/xIoVO4OlgH1ahT5fPRIvjgb/DtfyEeW/97M+tBl+Og1xnQYs/yjn+SJG0lg1MVDE7V15MjZ/DPdyeVTeMDOK5XM/5vcDcmzM3h9Ee/ISM1iZF/Ooj6tVxsLlUrqxbChFdgyrtABGrWh/xlQTOJ4gr7u9VuBrsdAB0OhU7HQEpaokYsSdoJGJyqYHCq3n6cl8OVL4xjxtJ8rj2sI5ce0I5IJEI8Hue4/4zkh7k5XHlQe645rGOl98XjcSYvXMXURas4qntTUpOd9iNVC9EimPklfP88/PRW5RBVqzF0OxFy58Pin6DlXnDE0GB91U9vBW3U+18Oux+WuPFLkkLN4FQFg1P1VxSNsSK/kEZZGZXOvzthAZc+O5bszFTeu2pfmtXJZHl+IS+OnsNrY+fy8+Jgr5lzBrbhH4O6JmLokrZG4WqY8zVM/xR+eAnyFq57Tf0OQYAa/0xwnJQKpzwNnY6CnLmQtwia99mx45YkhZbBqQoGp51XtGQvqBlL84lEoGeLOkxakEtBcbBuIi05icJojKQIvHHZQHq0qJPYAUvactEimPRWEKLqt4OsFvDRPyB3Xvk1TbrDwglBeGqxJ8weFZzf53dw8D+Cfai++S/UbAB7nFn+vtXLgwYVrqWSpJ2ewakKBqed24/zcrjp7Z/4dubysnPdmmdx5t5tOKJ7E/72xo+8OX4+XZtl8eZlA0lxyp6088hfCm9eDksmw9F3Qtv94bXzYeLr617beRDM/x5ySjbuPfbfQXj65r/w/p+DjXmHPBNs6FtR0RpITrfLnyTtJAxOVTA47RrmLF/N5z8vYffGtdmzdV0iJf/leGleAQff+Rk5a4o4oGND2jWsRat6NTioU6MNtjEvisaYMC+Hni3qkJzkf4GWqpVoMYy8G5JSoNtJ8MsIePvK8g5+6VlQkBtUpfY8N+juV6pJdzjjVajdODie8Tk8NwQ6HgUnPbbDv4okadszOFXB4KSXRs/hj6/+sM753RrUJDMtmWgsTt829fjdobtTHItx6TNjGTNrBYN7NeOeU3snYMSStqnJ7wbT+jocBgf8Gd68DH56s/z13r+BqcODzXnrtIbTX4KMLHhoX1i9NLjm1OeDdVOSpGrN4FQFg5MAvvx5KT/Oz2FFfiHfz13J6JkriMYq/6uQnZlKekoSi1cVlJ176Dd9OKJbk3XuV1gc4/LnxpK7tohT9mzJUd2bkpGavN2/h6RtoDAfHj88WA/V/3I47P9g+S/wzAmwYiak1YY6rWDxREjJgOK1kN0SLvsGitbC3G+hUReo2zrR30SStJkMTlUwOGl9Vq4uZPyclQCsKYxy78c/M3nhKgDaN6pF75Z1ePm7uTSolcYHv9ufejUr7x3zn0+ncfvwKWXHDWql8/wFe9Ghce0d9h0kbYWiNbB0KjTpUd4UIn8pvHQmzBoZHKdnw7nvwXOnBmujWvSFRRODJhMA9XaDvS+FfhcEx/F4ELzqtrHRhCSFlMGpCgYnbYriaIyXxsxl9vLVXHZgO9JSkjjmvi/5eXEe++3ekDtO6lHWDn3O8tUcctdnFBTHGNyrGd/MWM6CnLXst3tDnj63X4K/iaStUlwYNIuY9BYc90CwJ9Tkd+GF08qvyW4Z7CUVjwbHB/wF+p4Pr18I0z6CrsfDCY8E66x+eBEWfB9MEfx144n1KciDaCHUqLd9vp8k7eIMTlUwOGlLfT9nJSc++BXFsTg10pI5d2Bb+rerz2NfzuCTyYvZe7d6PH/B3sxZvoaD7xpBUTTOc+fvxYD2Dbb6s/MKihn+40IO7dqYrIzUbfBtJG2WeLxy1ejjm2DxZOh3Pux2IBSsgq8fhBG3BK9nZMPanPLrOw+ClEyY8FJw3Ko//OY1SFt/UxogqHj9d7+gxXqjLsGarP3/CGk1t/33k6RdlMGpCgYnbY1xs1dw07CfGDd7ZaXzqckR3rtqX9o3Cqbm/ePNH3lq1Cx6tMjmzcsGlnX1KzVy2lL+751J9Gldh78e1YXMtA2vh8ovKOY3j33DuNkrOalPC+44uec2/17V0fCJC2mWnUn3FpvwX+2lHeWrf8MH1wfP67WDvS4KjqOFwblIMqRmQmEetD8EhjwLqRlB8Pr2EVj0Ixz892B638vnwMTXKt+/7/lBq3VJ0jZhcKqCwUlbKx6PM+yHBbzzwwImL8xlzoo1XHPo7lx2YPuya5bmFbD/bZ+SXxjlioPac2S3pjSvk0leYTEvjp7Dvz/5mdJ/8zo2rs0Dv9mDdg1rrfNZa4uinPPEaEb9sgwINvH98s8H0qh2xg75rmE1ZeEqDr/nc5pmZ/DVnw9aJ5hKCfXjq8Hap4FXB934fv4QXvxtUIU66XFISob/HR+sjUqtAS37wYIfYE3J/nO1GgfrpD75vyBo/eYVWD4D3rkmOL7kK2jUKaFfUZJ2FganKhictK3F4/H1/uJ+z0dTueejnzf4vmN6NOXrX5azNK+AzNRkrjl0d84Z2KZsU955K9dwzYvj+WbGcmqlp9Codjq/LM3nqoM78LtDd99u36c6eOHb2fz5tQkAfPuXg8vWm0mhtXp5EJJSS/6uTv8UXr8Y8haWX1OvHSSnBhv4ltr390EFCuCFM2DysKBS9ZtXd9zYJWkntjnZIGUHjUnaaW2o2nHZge3JSE3mi5+XMH72SvILo6QlJ9EoK51rD+vI4N7NWbxqLVe/MJ6vpi/jn+9O4tWxc9lv94ZkpCbzxJczWFVQTGZqMo+dtSeLVxVwxfPjeObrWVxyQLtdut35j/PL145MWrjK4KTw+3Vzh3YHwjWTYMkkmPUV1GwAnQYFU/heOD3o5NewE+z/p/L3HHpTsL/UtI9g1H+Crn7129s4QpJ2ECtO0g4Qi8UpisVIT1k37MRicV7+bg63vDuZnDVFlV7r3aoOd57ck90a1qI4GmO/2z5lfs5abjupB6fs2XK9n5WzpogZS/MpjsbYo1VdkpJ2vmlsxz8wsmyd2Z+P7MTF+7dL7ICkbalobVBZars/1GpY+bXhf4VR95cfR5Kg9UBodxCsXgY5c6BpT+h3YTCt7/Pb4YeXYN9roO95O/Z7SFI14FS9KhicFFZL8wp4+/v5zFm+hkWr1rJn67qc2b8NyRWCz0OfTefW9yaTlpxEp6a16dSkNi3q1qBuzTR+mLOSr6YvY97KNWXX92ldl5uO60rXZjtPA4XiaIxuNwxnbVEMgMG9mnHPqb0TPCppB1mbC8P/Euw5lTs/CErrU6N+0H1v5ezycwf/IwhQBatgzQqo3TSYGljR/HFBBaznaVayJO0SDE5VMDipOstZXcSx//mSWctWV3ldo9rprFpbzJqiKEkRqFMjjaLiGNk1UunVsg57tKrLIZ0b06p+Fa2QQ2rqolUcdvfnZccdG9dm+O/2S+CIpARaMRN+egvmjYHazaBWIxj/LCybFrye1Txolz7+mfLj3HnB80hScNx1MOx9WdDU4qN/QKwYMuvBQddDr9ODLoCStJMyOFXB4KTqLhaLM2v5an6an8vPi1cxf+UalqwqYPcmtRnYrgG9W9WhdkYqC3LW8H/vTOKdHxZs8F5dmmZRIy2Z+SvXkJmWzNE9mrH/7g34cV4uY2atoE39GpyxV2uaZFdeQ7Shhhg7wuvj5vK7F7+nRd1M5q5YQ0pShIk3Hb7eaZDSLilaDBNehlULgu586bVh5L3w4d/Lr0lKhVjFqcERoOTXgRoNYPXSktNJULcttN0P9vsDZDeHGV8Ea6xa7RUErpS0HfXNJGmbMzhVweCkXc2c5atZUxQlJSnCgpy1jJ+zki9/Xso3M5YR24R/+1OSIhzQsSFt6tekZnoK4+asZOysFbRvVIv/G9yNbs3XnQYYj8d55utZfDNjOX8+shMt6m67ytbNw37isS9ncPaANrw2di65a4t558p9dqrpiNJ2MedbKFoDjbtBZl3IXwLzvgtC1ZyvITkNDr8F+pwNYx6HL+6q3PUvJROa94FZX5afa9ARDv8n7HbAutP+KorHg0rXkinQsCNkt9he31KSNovBqQoGJymwLK+AL35eSmpyEk3rZDBn+WreGDePsbNX0rVZFnu2qcfXvyzj2xnLN3iPlKQI5+3TloM6NaJb82zSUpJYmlfAda9NYMSUJQC0rl+Dly/qv80635368Ci+/mU5t5/Ug1e+m8s3M5Zz58k9ObGPv4hJW2z+OEjPgvoVGq3E40G4mj8evrwLZo8KzkeSoNuJQUv10spUWu2gKtVqr6DbX/M+kJIe3OPrB4ImFWtWBNfWbAgXjjA8SQoFg1MVDE7S5vlxXg7fzljOwty1LM8vpGuzLHq0qMPjX87gnQkbngaYnpJEnRqpLMotoEOjWvzz+O40rJ1O0+yMLW6lHovF6XnjB6wqKOa9q/blxdFzePKrmZy/T1uuP6bLln5FSRsTj8Pkd2DG57DnOdCocxCEPh0KP74SdPSrqEYD6P0bWDwJfh4enEtKCfayKsiFpr3g3PerXj8Vi8H8sdCoC6RVv/WYkqoHg1MVDE7StjN84kJe/W4uP8zNYWHu2rLzXZtlcdcpvaiRlszJD42q9FpmajIHdmpI/93qszB3LbOWrSY5KUJWRipNsjPo0jSLLs2yaFQ7fZ11VLOW5bP/7SNIS0li4o2H89rYufzp1Qns074Bz5y/1w773pIqiMVgwfggVM0bA7O/DipVpZLTg+l8e5wJqxbCwwfAmuXQ8aig5XpSMux+ONRpVf6eglXw2kUw5Z1gauGZbwZ7XUnSNmZwqoLBSdo+clYHC83TUpLISE0qCz3Tl+Rx49s/MXNpPkvzClhdGN2k+zWolUaXZtns16EBJ/dpSXaNVF4bO5drXvqeHi2yeevyffh+zkqO+89IGtRKY8z1h2637yZpM0SLgyrTmCeC6tLRd0KT7uWvz/gcnh4M8Qr/W5CUErRA3/0IKMyHL+8ONgcu1bBTEJ5qN9lhX0PSrsHgVAWDk5Q48XicCfNyeO/Hhfw0P5fmdTPZrUFNINi4d3ZJt8DpS/IqNa7ISE2ieZ1Mpi/JB+C0fq0YekJ31hRG6fqP94nF4elz+9G/XX1Sk5MS8dUkbY6pH8D3zwfPVy0oXz9VUa0mQaXqg7/BqvnBuaQUyMiGZr2hRT/oflLldVmStJkMTlUwOEnht6YwypRFqxg7awUvjZnD5IWrAEhOirBn67r83+BudGhcG4DD7v6MqYvygGAaYIfGtWhTvyZtGtSkbYMatK5fkxZ1MmlQK52kpMS0UJe0EbO/ga/ug7xFwca92S3hwL9CVlNYPgOeGwJLp6z7vqQU2PPcYD3VmpXBFL96baF++6A5Ral4HIoLIHXbNKmRtPMwOFXB4CRVL/F4nHFzVrI4t4C9d6tHnRqV94z5btYKHh85g1HTl7E8v3CD90lLCapWZY+6lX82zc4gxWqVFE6xGKxdGbRTz1sEc8fA1Pdg+ifrvz6SHKyJyqwHxGHlHCjKh7ptgq5/nY6GzscG1373BIx7Bva6GHqeuoO+kKSwMDhVweAk7ZxisTjTl+Txy9J8Zi7NZ+ayfGYszWf2stUszF270T2rkiLQJCuDmukprFpbTGE0xu6Na9GzRR36tqnHXrvVo3ZGFfvUSNrxfvkMPrkZlv4MtRoH3feW/QIFORt/b73dghbsC8aXnzvsn0EFa/I7kL8Yegwpb0qxeFKw19X6pgbGohAtsqIlVUMGpyoYnKRdT1E0xsKctcxbuYa5K9Ywb8Ua5q1czbyVwfP5K9dSGI1VeY/kpAhdmmbRpkFNWtXLpE5mGjXSk1mwci0/Lcglv6CY/u3qs9/uDenSNGuLW65L2krxeFCVylsEq5dDPAZ1WkNmHVjwPcz8Ar57snxfqfSsYA+qycOC49SaQXWq9LW9Lg42CJ7xedAh8MRHoMtx5Z83+xt45dyg2cU57wVTBSVVGwanKhicJP1aLBZnSV4Bc1esoaAoSu2MVCIRmDg/h/FzVjJq+jJmLlu9yfeLRKBl3Rq0rJdJw1rpNK+byYEdG7FHq7qus5LCoDAfxv4PVs6GgVcG1aov74KPbwper9MqCE2LflzPmyNw6E1Bg4p5Y+CT/4NYcfBSo65w3gfB2qvJw6BpT2jQIXht1H9g5L2wzzWw98U75GtK2jiDUxUMTpK2xNwVq/lxXi6zl+czd8UaVq0tZtXaYhrUSqNrsyxSkpP44uclfDV9GStLWrP/WoNaaTTNziQ1OUKtjFTq10yjaXYGx/duXtbsotTCnLV8N2sFvVvVoVmdKjYJlbTtzPgi+C8frQYEx98/D6MfgVb9g8rTl3cHa6J+rfMgmPNtUOVq1T8IZLnzICUDjrgVVi8NAlapgVfBwTdA0nrWVeYtCapjyU4NlnYEg1MVDE6Stqd4PM7SvEKmL8ljYc5alqwqYOL8HD6evJhVa4s3+L59OzTgsK5N6NykNp//vJSHP5/O2qJg+mC/NvX4bf/WHNOj6TqbAkvageLxoPvfd08FVaW0mtDrdOh7PswdDU8eDdGSJjWpNaDoV5Xq9ofCtA+D5017Qsu9g+rW2pWQuwBmjYQVM6BmIxj8IHQ4ZMNjicXWH7wkbRaDUxUMTpISobA4xg9zV7KqoJjC4hir1hazPL+AMTNX8NGkRettXtGibiZzV6wpO+7Vsg6/P2x3+rap5xoqKYx+fA1G3Q/dT4E+Z8G3DwfT/2LFcMiNsM/VMO5ZePvK8ul9VelxKtRuHDSfaLV3ELwWTYQP/hpUuFoPCDoELpsGU4cHQe6kJ6Bxl+3+VaWdhcGpCgYnSWEzZ/lqXv5uLj/MXcmkBbnUyUzj6kM6cES3JizIWcuLo+fwyBe/sLowCkBachLdW2TTp3Vd+rSuS/fm2TTNzqhUjVqYs5ZvZy6nVnoyA9o1MGhJibJ4MqxeBm0Glp9bOSfY9Hf++GB6X2ZdqFEPmvcJ1k59fgd8+99175VWCwrzqv681Jpw/IPlDSzyl8HYJ4NGGbsfDq0HQtJ6/vcgFoMlk6DB7k4T1C7F4FQFg5Ok6mjxqrXc9/HPvP/jQpbmrbtfVc20ZJrWySQCrC6MMm9leaUqMzWZgzo14vpjOtM02/VSUrXwywiY8n4QcorXwpT3gnVTREqmB54HM7+E6Z8G+1O1PySocM34LHh/7abQsFMQ0IrXlt+3RgNo1it4re3+0P5gyF8Kr10QvLfB7nDY/0GHw4L1XrDxDYSL1kCq/9ui6sngVAWDk6TqLB6PM3v5asbMXMGYWSsYO2sF05fkUfyruX5JEejaLJtleQXMzwl+aapfM41/n9abAe0bVLo2Fovb7U8Ku1gs2HMqI3v9e0kBRIvh4xvg6wcrTwVs2jPo+Dfl3WA9VUV1WgXBJ39J5fPZLYNug0nJsHRq0L69zb5BR8HmewTXrM2BT/4ZNNDofCyc+GhQrYrHg8/JrLttvru0HRmcqmBwkrSzKYrGmLUsn8W5BRCBlKQkOjWtTVZGKvF4nB/m5nDdaxP4aUEuSRHo2bIOzetkkldQzI/zcsldU8TBnRtxSt+W7Nu+ASnJSRRFYzzz9Sw+mbyY43s359iezUhJdiG6VC0U5gd7Vi2aCI06B9PzIpFgk95538GSycHrP75WHqQad4NB98JPb8I3D5U3uVif5n2CytWC7yFvYfn5zsfCvtfAe38O9r5quz/sfQlktwiaX6xZHkw1jCRD1+OD7oFSghmcqmBwkrQrWlsU5fo3fuSV7+ZWeV12ZioHdGzIxPm5TFtcvpZitwY1+eMRnTiiW5PtPVRJO0rhavjpjWCqXr8Ly6fi5S+D5dMhb3EQoOq3D6bifX47/PBi5XvU2w32OAs+/WfVYevXsprD8Q8FnQUXToDFP0HO3GA9WKu9oeORQbOLzVWQF2x6nOHveNo0BqcqGJwk7cqmLFzFL0vymLdyDekpSXRplk1achKvjZvLm+Pnszy//BefejXTGNSjKW99P58VJXtTHd+7OTcc25XsTBePS7ukpT/D4knBNL3ktKAJRWpGsAbrxd9CrCioJvW/PAhl458P3pfVNKhSpdcKgtKKmQQl8vTKa7BKpWRC7SZBRSwlI7hn1xOCBhZThwfNLlIzg/sOvDrYaHj6p/Dy2cH7z3gZWvZb/3eY9hGMfw72OBN2O2Ab/wGpujE4VcHgJEnrVxyNMXb2Sj6dspgaqcmc2b8N2TVSySso5oFPp/HQZ9OJxYNGFO0b16Zt/RpkZaaSmZpMu0a12LdDA5tPSLuyRRODENS8T9XXFeQFLdW/ezI4zqwLTXtB3dZBYJr6Xkmw2kSlAe7H1yAedB8ltSac/kJQEVsxK+haWLdtsInxZ/8CSn797XYSHHYzZDUL1mZNeBnGPg39LijvTFiVuWOCJh19z4P02hu/XqFTbYLT559/zu233853333HggULeP311xk8eHCV7xkxYgTXXHMNEydOpGXLllx//fWcffbZm/yZBidJ2jLfzVrBtS9/z4yl+Ru8pn2jWuzTvgE9W2YzZuYKvpy2lJZ1a3D9MZ3p1MT/zZVUwbLpwR5VDTqUd/CDIMAsmggFq4J1UCtmwfhnYNon0LBjMI2vQYegqcXE1+HnD8rf2/2UoNHFL5+u5wMjlAWm1gODjoPxWBC8ep4afN7E18sv3+d3wTTE2V/DytnB9L/MetBqr6CT4ehH4b0/BY04mvWG0/+/vTuPjqrK9wX+rXlITanMISNTGBMZBCOtNhIFHu3FRq8TvkZp9ap4W2m1FV0q6loPu++yV7fdXr33ehe09/m0xRZtBW0RDLYYaIiEIUAgEyHzWPNctd8fR0oCoSqIpJLw/axVy+ScU1X7ZHuKfLP3+e2NgCHth/v52FukoJdVLI2O0UUxYoLTJ598gp07d2LWrFlYtmxZ3ODU0NCAadOm4f7778c999yDbdu24ZFHHsHmzZuxcOHCQb0ngxMR0fcXCkdQ3+1GXacLJ3o98PhDcPpD2Ndkw4Fm24AL+QKAUi7DnVfkY3ZBMgpSklCUaYSKxSaI6EIJARz5K/D1H4HJNwBX/qtUOv39e4AjHwFypVQh0NMD+B3SiNYNv5OCUus+4NM1UoA6RaaQSrSfHsYGYskHbCekr+UqaYqidSwwbgHQWy/d76VPkUay8kqlaYN124G966VjF/1aCmDNe6VwNGaWNOVQLpfC5J43gG0vAgGn9B63vgVM/snAbTn2GVC7FbjqUWl6I52XEROcTieTyeIGpyeeeAKbN2/GoUOHottuu+022Gw2fPrpp4N6HwYnIqKLw+4J4uu6bvy9thvVLXZMHWPG1RNSsWlfC/5W3dHv2CS1AleMTUG6SYsOhw/hiMA/z87B4mlZULA0OhH9ENw9Uvl2hVIKWM42QGOS7rM63YkK4OtXpJGqxb+WQszB94CPHpamHmbPkNa9CriltbSa90gjVZABC56VAtv/XSaNSg2aTCqCcXpom3A9MOsuqcR7Z7W0zZAhLZKsMQH3lUv3dbUfAnJmS9MPj/0NePt2aYqiKUeanpg5HQgFpDaea+2tM4WDwNHN0jTFcAC4ef0PO3o2jI3a4HT11Vdj5syZ+N3vfhfdtn79ejzyyCOw2+0DPsfv98Pv90e/dzgcyM3NZXAiIhpC24924OP9bTjR60Fdlwu2b4tNnKkwNQl3zyvAjTPGwKRVocPhQ1OvB5MyjTBqWZCCiIZQOCg91Pr+2z29QO02wDwGyL9S2uZsl9bPkskA6zgp4Li7peqE9eXSWljmPGD2XUBPvTT18JSiJUDdtv5FMrRm4NpnpCl6by6VApbaIJVzB6QgNeNOaQQr5AVUeiDoke7tMmVLo14iLE0ttI6VqiZOv1lalyvy7X1gcoX03+Nbgb/+AnC2fvf+OZcDKz66uAsbC9F/imaCjNrgNHHiRNx9991Ys2ZNdNuWLVuwZMkSeDwe6HRnd+7atWvx/PPPn7WdwYmIKDEiEYHDbQ58XdcNtz+MTLMWbXYf/vR1I+xeKVDpVAqkGTVo6vUAkBb0nTbGjJ8UZ+GOufkwaJSJPAUiovPjs0vB51RYqd8hrZk1Y7k0wtVaJVUldLYCl98LXPMraUQJkELZ61cB7k4Asm9HoU5bP2vCQmDpq8B7dwONfz93G1InSoGs/ZA0hbFosRSMvvmTtN+QARTfAnzzP1I1wyk3Svd5Bb2AIV0qrmFrlEbEjn4MZM+U1ulKzpemHHp6pemHuXOlaonn0lMnTUVs3Qfc/UnCwxOD02k44kRENDK4/SFs3HsSb+1uwvFv15CSyYA0gwadzu8+x01aJa6dlA5PIByd4rdwaiZkw+Avl0RE31vIL00HPBWYTtfXKC04nD9PGkWqfl+6N8qcI02rU+ul6Xn1XwAKlTS1UKmVpice+xTY+cp3ix0PZO4DQNlaaWpfw9+B//mpdC/W6VRJQNgvFcOIRakD8kulBZDDAel+sc6jgDFDCm4t3yBapOPuT6VjE+h8gtOI+pNdZmYmOjr6z5Pv6OiAyWQaMDQBgEajgUYTI/USEdGwkKRR4q55hVhxZQGqTtrg9IVwWZ4FJq0KbXYvvjjahTe+qkd9lxsfVH03pWTb0U7Mzk/GbXPyUJCih0WvhjcQRiAcxthUA5KT1Ak8KyKiQVJqzj1Sk1wgPU6ZfrP06Pd8NTDxjGJpeiuQMRWY/XNpXS21AcgqAbx9UgXBtgPSqNKEsu+eU3gVsOw/gc/XSlMVlRopgAW/rag6vkwqwtHwJVD5J+mYMTOl92r8Sronq2679Dhdj/O7rydcD8z9F2l0agQZUSNOTzzxBLZs2YKDBw9Gt91xxx3o7e1lcQgioktAOCKw7UgHjne6YNap0GLzYv3OBviCkXM+pyBFjx9NSMUts3MxfYyZI1NEROcrHJLu1xICSJ/03fZTMeLU56oQQNdR6b6uhi+lqYnjr5PumfJ0A84OKWSljBvyUziXETNVz+Vyoba2FgAwY8YM/Pa3v8X8+fNhtVqRl5eHNWvWoKWlBW+++SaA78qRr1q1CitXrsT27dvxi1/8guXIiYguYR0OH/7ry3ocbnOgqdcDuzcIg0YJuUyGFpu337ET0g2YkWfBtDFmXDUhDYWpSQlqNRERDQcjJjiVl5dj/vz5Z21fsWIFNmzYgLvuuguNjY0oLy/v95zVq1fj8OHDyMnJwTPPPMMFcImIaEA2TwD7mmz4oKoFnxxqRyDUf2RqYoYB107KwJzCZEzJMiMiBAKhCFKNGhagICK6BIyY4JQIDE5ERJcmmyeAXfU9qG514JumPuyu70XoXCv2Akg1aDAjz4J7flSIOYVWTvEjIhqFGJxiYHAiIiJAWrB329EO7Krvwd7GPtR3u6FWyKGQy+ANhvsdW5xjxmW5FuSnJKEow4ip2SYWnSAiGgUYnGJgcCIiooEIIaKjSnZvEA3dbmzcexIbK5vPmuIHABkmDfKtSShI1eO6KZm4ZmIa1Er5UDebiIguAINTDAxORER0PrqcfnxxtBONPW40dLtxpM2Bxh7PWcdZ9CrMG5eKSZlGTBtjxuyCZBi1KgBAIBSBUi6DXM7pfkREwwmDUwwMTkREdKEcviDqu9w40ePGgWY7/rq/FV2nLdILAAq5DEUZRti9QbTavTBqlJg7NgVzCqwoSE1Cfooe49MMgwpTv/v8GNbvbMQdc/Owav54Fq4gIvqBMDjFwOBEREQ/tFA4gn809uJQix1H25z4pqlvwFGpM41LS8I9V43FT2eMgValGPCYv1Q249GN+6Pfpxo0+PVN07FgcsYP1n4ioksVg1MMDE5ERDQUmvs8ONTiQJpRgzyrHi02LyrqenCoxY6TfR4c73BFi1Do1QpcOS4FJTkWuPwh2DxB5Fp1yDBp8fQHhxAIRXDjZdnY32xHQ7cbOpUCH/3rPIxPNyb4LImIRjYGpxgYnIiIaDhw+oL4856TWL+z8ayFes9UNjkD//m/ZyEUEVi5YQ++qu3GpEwjPlg175wjVUREFB+DUwwMTkRENJxEIgJH2h348lg3ajtdSNarYNAqUdvpwv5mG7LNOryxYna00ESnw4fFv/87etwBLL0sG8vn5qMowwizXpXgMyEiGnkYnGJgcCIiopGuvKYTd63f029bhkmDiRlGjEszYFxaEtKMGniDYQRDAtkWHcamJSHLrOVCvkREp2FwioHBiYiIRoO/7m/F+98043iHK+5Uv1PSjBqUTU7HFWNToFcroVHKMSnTiHST9iK3lohoeGJwioHBiYiIRhuHL4jjHS4c73CirsuF+i43bN4g9GoF5DIZmvs8aOr1IBge+J/8nGQdpmSZUJCahDEWHSx6FTRKOapbHag80YcMkxaPLyxCtkU3xGdGRHRxMTjFwOBERESXIn8ojN31vdh6uAM17U4EwhG4/CHUdbkwmN8EDBolnlhUhDmFKUgzaqBUyCAigE6tgFopv/gnQER0ETA4xcDgRERE9B2nL4j9J+2o7XTiRK8HbTYfnP4gXP4wxqUmYUaeBe/va8G+JtuAz9epFLhqQipmFySjpt2F6lY7ZuRZ8KuFk5CcpB7akyEiOk8MTjEwOBEREZ2fcERgw9eN2Lj3JDocPvR5gnGfY01S459n56Cu04W6LjdMWiXSjFpMyTbh2knpKB5jhlzOQhVElFgMTjEwOBEREV2YYDiCiBCQQYZjHU5sPdyBw20OFGUYMT7dgNfK61DT4Yz5Gsl6FWbmJWNmfjJm5FpQnGuBQaMcojMgIpIwOMXA4ERERHRxBUIRvFnRiKPtTkzOMmFSphFufwjtDh921ffgy2PdcPlD/Z4jlwETM4woybHAalDjHw29ONRix+QsE268LBv/a3oW0k1aCCHw5fFuvLXrBK4pSsMdc/JYYp2IvjcGpxgYnIiIiBIrEIrgUKsd+5ps+KapD1VNtkGVVJ+UaYRWpUDVSVt020+Ks/DSTcUcrSKi74XBKQYGJyIiouGnw+HD/pM27G+2occVwMy8ZEwbY8au+h58uL8V+08LS2qlHNdNzsDfqtsRighY9CpMyTJhbFoSrEkaWHQq5KfoUZRpxBiLjiNSRHRODE4xMDgRERGNPD0uP76u60GHw4efFGcj06xF5Yle/Ov/24dWu++cz9Oq5MgwaZFq0EApl0EmA1KSNMhL0cOsU6HH5YfTF8LEDCPmFFoxOcsEBYtWEF0yGJxiYHAiIiIaPXzBMI62O3G8w4kTPR7YvAH0uYOo63KhttOFUOT8fs1JM2rw0xlj8OOJabB5g+h2+ZFr1eOyHAvLqxONQgxOMTA4ERERXRoCoQja7F50OPzocfkRFgLhiEC3K4CmHjecvhCsSWro1QocaLFjb2PfWUUrTleQokdJrgWz8pNx3ZQMZJl16Hb5sembFrj8IVw9MQ2X5Vo4YkU0gjA4xcDgRERERAMJhCL4oqYTf6lsRk2HE2kGDSx6Neq6XGjodp91/JQsE453OhEMf/erlFGjhEGrhFIhw8y8ZNx5RT5m5ydH77Oye4KoqO9GYaoBRZnGs16zutUOk1aFXKv+4p0oEUUxOMXA4ERERETny+YJYH+zHftP2vD3413Y09gX3VeSa0Fusg47jnXB6Tt7xCrbrEVOsh4KuQx7GnsRigjIZcCKKwvw2PVFSNIo0dznwf/ZcgRbDrZDrZDj4bIJ+Jerx0KpkA/laRJdchicYmBwIiIiogvVZvfi69oeTMgwoDjHAkBaGLi+y41gOAKHL4i/VrXig6oW+IKRfs/Ntepwslcqv65RyqFRyuEJhM+6H2t8ugHFY8zItugwp9CKK8amQK1kkCL6ITE4xcDgREREREPF6Quipt2JdocPDm8Ic8daMS7NgB3HuvD0poNo7vtu/aq5hVas/aepONzqwPMfVcNxxuiVUaPExEwj5DIgEBbocvjQ7QogJ1mHGXnJGGPRwuUPAwCWFGdiZp40RbDXHUAgFEGmWTuk5040EjA4xcDgRERERMNBMBzByV4PAGltqtPXnOpx+fFVbTdabF40dLnxRU0Xul3+83r9yVkmhCMRHOtwAQDyrFJxi163Hy19XkzIMGLlvEJcMdbKta7oksXgFAODExEREY00kYjA/mYbOhw+CAEo5DKkm7Swflu8Yl9TH/o8QRi0SnQ6/Pj4QCv8oe+mCCrkMoTPUZo9zaiBEIA/FIbs22MzTFoU55gxJcuEnGQ9rAY1atqdqGqyQa9RYPG0LMzOT0afJ4BWmw9ZFmmtLKKRhsEpBgYnIiIiGu363AF8drgdZp0KlxdYoVEpsKexF0faHEg3apFh0uCz6g5srDx51j1Yg6VSyPpVFMw2a1GcY8H0HDOmZpuQkqSBWadChlkDjVIBAGixeXGi240p2SZY9FwXixKPwSkGBiciIiIiid0TRH23CxqlAhqVVHgiFBZo7HHjYLMdxzqcaLP70OX0ozA1CTPyLGh3+LD1cAecvhBkMiAlSYMetx/n+o1SLgOyLTqEwgLtDh8AQCYDpmWbMSs/GdPHmJFu0qDV5kWX04+cZD2KMo0Yl2aIWQxDfLsuFysP0oVgcIqBwYmIiIjowvhDYbTZfMg0a6FVKeDyh3CoxY4DzTYcaLbjeIcLdm8QNm+g34iWQi5DpkmLFps3xqtLlHIZxqYlYVyaAWlGDVKSNEg1qmHVq7G/2Y6P9rei3eHD0suy8dD88RibZgAA+IJhVNT3oLnXg4XTMpFuZFEMOjcGpxgYnIiIiIiGhhAC3a4AGrrdEEJgeo4ZerUSnQ4fvq7rwf5mGw612NHnCWKMRYcUgxpNPR7UtDvh9J+9Jta5yGRApkkLs06Fk70euANSdUGtSo4VpQW4oSQbY9OSUN/lxlu7T6DyRB9m5VvxTyXZyE/Rwx+KIEmtQLqJIetSw+AUA4MTERER0fAmhECb3Yeadicae9zocQXQ4/aj2xVAt8uPTJMWN5RkI8OkwWvldfj8SGe/52eYpBGqw22O83rfXKsOs/OtMGiUkMkAGQCZTAa1Ug6LXoWUJDWmZpsxOcsEuQxotfvQ6wqgIFUPo1aFcESg1eaFQaNEchLv4RoJGJxiYHAiIiIiGl06HD50OHywe4NI1qsxNVv6Ha+8pgtvfFWPw60O9HmCUClkWDQtC2WT07Gztht/q+6AJxCCVqmAJxg+Z+XBMxk0SsiAfqNiaUYN7J4gAuEIFHIZfjwxDWVTMtDrDqC5z4Mssw6z8pMxLdsMs1416HMLhCLYWHkSJ3o8ePDH41hU4wfG4BQDgxMRERHRpafPHYBSIYNRO3BocflD2NvYi0MtdgTCAhACAoiWau/zBNFu92H/SVs0MCnlMlj0KnS7AtHXObPa4ECMWiUyTFoEwxF4A2EYNNL3mWYtMkxapBs1UCnl8AfDeLPiBJq+Xe9rjEWHP94xAzPykgd83UAoclZBjUhEQC7nOl3nwuAUA4MTEREREX1f4YjA8U4nAGBsqlT5z+4JorHHDWuSGtkWHRq63Xivshn7T9qQZdFijEWHEz0eVJ7oG1RhjDOlGjTQqeU42euFUi7D5CwT0owaRIRArzuAHlcAve4AvMEwzDoVClL0AIDGHg88gRCumpCGfyrJxqz8ZGSZtQNWIgyFI+h0+tFq86LF5oXbH8Z1UzKQZjz3+ly+YBgKuQyqEVzZkMEpBgYnIiIiIkoUTyCElj6p9LpGJYdWpYDDG0KHw4d2hw/tdh+6XX6EIwIRIXBZbjJWXJmPUERgzV8OYvPBtgt6/1OVDXOSpWIcXU4/Wm3Se585VTFJrcD914zDLZfnwpqkhkImQ58ngOOdLry79yQ2H2hDSpIazy+dhuumZFxQuxKFwSkGBiciIiIiGomEEKjpcEaDl1wmgzVJDatBjZQkNUxaFTqcPjR2S1P7ClOTICCw5UAb/lbdgYYeNwKhcy94rJTLkGnWItuig9MXwpEzimso5LJz3gc2M88CXzCCFpsXgVAEYSFg0iqRZ9UjPyUJ+Sl65CTr4fAG0dTrQavNi9funAVFgqcRMjjFwOBERERERJeiSESg2+XHyT4Pmvu86HYFkG7UINuiwxiLDmlGTTTIRCICHx9sw+8/P4aGbjdOz0spSWpcOykdN8/KQfmxLvzXl/UIDbKwxum+fvJaZFt0P9TpfS8MTjEwOBERERERDV44IuDwShUDrUnqs+5pqu104h8Nfcg0a5CTrIdOpYBMBtg8QZzo8eBErxsnuj1osXlh1qmQY9UhN1mPG4qzz6vC4MVwPtlAOURtIiIiIiKiEUghl8Vcl2p8uhHj041nbc9JBqaNMV/Mpg2pkVsCg4iIiIiIaIgwOBEREREREcXB4ERERERERBQHgxMREREREVEcDE5ERERERERxMDgRERERERHFweBEREREREQUB4MTERERERFRHAxOREREREREcTA4ERERERERxcHgREREREREFAeDExERERERURwMTkRERERERHEwOBEREREREcXB4ERERERERBQHgxMREREREVEcDE5ERERERERxMDgRERERERHFweBEREREREQUB4MTERERERFRHAxOREREREREcTA4ERERERERxcHgREREREREFAeDExERERERURwMTkRERERERHEoE92AoSaEAAA4HI4Et4SIiIiIiBLpVCY4lRFiueSCk9PpBADk5uYmuCVERERERDQcOJ1OmM3mmMfIxGDi1SgSiUTQ2toKo9EImUyW6ObA4XAgNzcXJ0+ehMlkSnRz6AfAPh2d2K+jE/t1dGK/jk7s19FnOPSpEAJOpxPZ2dmQy2PfxXTJjTjJ5XLk5OQkuhlnMZlM/BAYZdinoxP7dXRiv45O7NfRif06+iS6T+ONNJ3C4hBERERERERxMDgRERERERHFweCUYBqNBs899xw0Gk2im0I/EPbp6MR+HZ3Yr6MT+3V0Yr+OPiOtTy+54hBERERERETniyNOREREREREcTA4ERERERERxcHgREREREREFAeDExERERERURwMTgn06quvoqCgAFqtFnPnzsU//vGPRDeJzsPatWshk8n6PSZNmhTd7/P5sGrVKqSkpMBgMOCmm25CR0dHAltMA/nyyy9xww03IDs7GzKZDB988EG//UIIPPvss8jKyoJOp0NZWRmOHz/e75je3l4sX74cJpMJFosFP//5z+FyuYbwLOh08fr0rrvuOuvaXbRoUb9j2KfDz7p163D55ZfDaDQiPT0dN954I2pqavodM5jP3aamJixZsgR6vR7p6el4/PHHEQqFhvJU6FuD6dMf//jHZ12v999/f79j2KfDy2uvvYbi4uLooralpaX45JNPovtH8nXK4JQgf/7zn/HLX/4Szz33HL755huUlJRg4cKF6OzsTHTT6DxMnToVbW1t0cdXX30V3bd69Wp89NFH2LhxI3bs2IHW1lYsW7Ysga2lgbjdbpSUlODVV18dcP9vfvMbvPLKK3j99dexe/duJCUlYeHChfD5fNFjli9fjurqamzduhUff/wxvvzyS9x3331DdQp0hnh9CgCLFi3qd+2+/fbb/fazT4efHTt2YNWqVdi1axe2bt2KYDCI66+/Hm63O3pMvM/dcDiMJUuWIBAI4Ouvv8af/vQnbNiwAc8++2wiTumSN5g+BYB777233/X6m9/8JrqPfTr85OTk4KWXXkJlZSX27t2La6+9FkuXLkV1dTWAEX6dCkqIOXPmiFWrVkW/D4fDIjs7W6xbty6BraLz8dxzz4mSkpIB99lsNqFSqcTGjRuj244cOSIAiIqKiiFqIZ0vAGLTpk3R7yORiMjMzBT/9m//Ft1ms9mERqMRb7/9thBCiMOHDwsAYs+ePdFjPvnkEyGTyURLS8uQtZ0GdmafCiHEihUrxNKlS8/5HPbpyNDZ2SkAiB07dgghBve5u2XLFiGXy0V7e3v0mNdee02YTCbh9/uH9gToLGf2qRBCXHPNNeLhhx8+53PYpyNDcnKyeOONN0b8dcoRpwQIBAKorKxEWVlZdJtcLkdZWRkqKioS2DI6X8ePH0d2djbGjh2L5cuXo6mpCQBQWVmJYDDYr48nTZqEvLw89vEI0tDQgPb29n79aDabMXfu3Gg/VlRUwGKxYPbs2dFjysrKIJfLsXv37iFvMw1OeXk50tPTUVRUhAceeAA9PT3RfezTkcFutwMArFYrgMF97lZUVGD69OnIyMiIHrNw4UI4HI7oX8Mpcc7s01PeeustpKamYtq0aVizZg08Hk90H/t0eAuHw3jnnXfgdrtRWlo64q9TZULf/RLV3d2NcDjc738IAMjIyMDRo0cT1Co6X3PnzsWGDRtQVFSEtrY2PP/887jqqqtw6NAhtLe3Q61Ww2Kx9HtORkYG2tvbE9NgOm+n+mqga/XUvvb2dqSnp/fbr1QqYbVa2dfD1KJFi7Bs2TIUFhairq4OTz31FBYvXoyKigooFAr26QgQiUTwyCOPYN68eZg2bRoADOpzt729fcDr+dQ+SpyB+hQA7rjjDuTn5yM7OxsHDhzAE088gZqaGrz//vsA2KfD1cGDB1FaWgqfzweDwYBNmzZhypQpqKqqGtHXKYMT0fe0ePHi6NfFxcWYO3cu8vPz8e6770Kn0yWwZUQUy2233Rb9evr06SguLsa4ceNQXl6OBQsWJLBlNFirVq3CoUOH+t1XSiPbufr09HsLp0+fjqysLCxYsAB1dXUYN27cUDeTBqmoqAhVVVWw2+147733sGLFCuzYsSPRzbpgnKqXAKmpqVAoFGdVEOno6EBmZmaCWkUXymKxYOLEiaitrUVmZiYCgQBsNlu/Y9jHI8upvop1rWZmZp5V1CUUCqG3t5d9PUKMHTsWqampqK2tBcA+He4eeughfPzxx/jiiy+Qk5MT3T6Yz93MzMwBr+dT+ygxztWnA5k7dy4A9Lte2afDj1qtxvjx4zFr1iysW7cOJSUl+P3vfz/ir1MGpwRQq9WYNWsWtm3bFt0WiUSwbds2lJaWJrBldCFcLhfq6uqQlZWFWbNmQaVS9evjmpoaNDU1sY9HkMLCQmRmZvbrR4fDgd27d0f7sbS0FDabDZWVldFjtm/fjkgkEv0Hnoa35uZm9PT0ICsrCwD7dLgSQuChhx7Cpk2bsH37dhQWFvbbP5jP3dLSUhw8eLBfMN66dStMJhOmTJkyNCdCUfH6dCBVVVUA0O96ZZ8Of5FIBH6/f+RfpwktTXEJe+edd4RGoxEbNmwQhw8fFvfdd5+wWCz9KojQ8Pboo4+K8vJy0dDQIHbu3CnKyspEamqq6OzsFEIIcf/994u8vDyxfft2sXfvXlFaWipKS0sT3Go6k9PpFPv27RP79u0TAMRvf/tbsW/fPnHixAkhhBAvvfSSsFgs4sMPPxQHDhwQS5cuFYWFhcLr9UZfY9GiRWLGjBli9+7d4quvvhITJkwQt99+e6JO6ZIXq0+dTqd47LHHREVFhWhoaBCff/65mDlzppgwYYLw+XzR12CfDj8PPPCAMJvNory8XLS1tUUfHo8neky8z91QKCSmTZsmrr/+elFVVSU+/fRTkZaWJtasWZOIU7rkxevT2tpa8cILL4i9e/eKhoYG8eGHH4qxY8eKq6++Ovoa7NPh58knnxQ7duwQDQ0N4sCBA+LJJ58UMplMfPbZZ0KIkX2dMjgl0B/+8AeRl5cn1Gq1mDNnjti1a1eim0Tn4dZbbxVZWVlCrVaLMWPGiFtvvVXU1tZG93u9XvHggw+K5ORkodfrxU9/+lPR1taWwBbTQL744gsB4KzHihUrhBBSSfJnnnlGZGRkCI1GIxYsWCBqamr6vUZPT4+4/fbbhcFgECaTSdx9993C6XQm4GxIiNh96vF4xPXXXy/S0tKESqUS+fn54t577z3rj1bs0+FnoD4FINavXx89ZjCfu42NjWLx4sVCp9OJ1NRU8eijj4pgMDjEZ0NCxO/TpqYmcfXVVwur1So0Go0YP368ePzxx4Xdbu/3OuzT4WXlypUiPz9fqNVqkZaWJhYsWBANTUKM7OtUJoQQQze+RURERERENPLwHiciIiIiIqI4GJyIiIiIiIjiYHAiIiIiIiKKg8GJiIiIiIgoDgYnIiIiIiKiOBiciIiIiIiI4mBwIiIiIiIiioPBiYiIiIiIKA4GJyIiohjKy8shk8lgs9kS3RQiIkogBiciIiIiIqI4GJyIiIiIiIjiYHAiIqJhLRKJYN26dSgsLIROp0NJSQnee+89AN9No9u8eTOKi4uh1WpxxRVX4NChQ/1e4y9/+QumTp0KjUaDgoICvPzyy/32+/1+PPHEE8jNzYVGo8H48ePx3//93/2OqaysxOzZs6HX63HllVeipqYmum///v2YP38+jEYjTCYTZs2ahb17916knwgRESUCgxMREQ1r69atw5tvvonXX38d1dXVWL16Ne68807s2LEjeszjjz+Ol19+GXv27EFaWhpuuOEGBINBAFLgueWWW3Dbbbfh4MGDWLt2LZ555hls2LAh+vyf/exnePvtt/HKK6/gyJEj+I//+A8YDIZ+7Xj66afx8ssvY+/evVAqlVi5cmV03/Lly5GTk4M9e/agsrISTz75JFQq1cX9wRAR0ZCSCSFEohtBREQ0EL/fD6vVis8//xylpaXR7ffccw88Hg/uu+8+zJ8/H++88w5uvfVWAEBvby9ycnKwYcMG3HLLLVi+fDm6urrw2WefRZ//q1/9Cps3b0Z1dTWOHTuGoqIibN26FWVlZWe1oby8HPPnz8fnn3+OBQsWAAC2bNmCJUuWwOv1QqvVwmQy4Q9/+ANWrFhxkX8iRESUKBxxIiKiYau2thYejwfXXXcdDAZD9PHmm2+irq4uetzpocpqtaKoqAhHjhwBABw5cgTz5s3r97rz5s3D8ePHEQ6HUVVVBYVCgWuuuSZmW4qLi6NfZ2VlAQA6OzsBAL/85S9xzz33oKysDC+99FK/thER0ejA4ERERMOWy+UCAGzevBlVVVXRx+HDh6P3OV0onU43qONOn3onk8kASPdfAcDatWtRXV2NJUuWYPv27ZgyZQo2bdr0g7SPiIiGBwYnIiIatqZMmQKNRoOmpiaMHz++3yM3Nzd63K5du6Jf9/X14dixY5g8eTIAYPLkydi5c2e/1925cycmTpwIhUKB6dOnIxKJ9Ltn6vuYOHEiVq9ejc8++wzLli3D+vXrL+j1iIhoeFEmugFERETnYjQa8dhjj2H16tWIRCL40Y9+BLvdjp07d8JkMiE/Px8A8MILLyAlJQUZGRl4+umnkZqaihtvvBEA8Oijj+Lyyy/Hiy++iFtvvRUVFRX44x//iH//938HABQUFGDFihVYuXIlXnnlFZSUlODEiRPo7OzELbfcEreNXq8Xjz/+OG6++WYUFhaiubkZe/bswU033XTRfi5ERDT0GJyIiGhYe/HFF5GWloZ169ahvr4eFosFM2fOxFNPPRWdKvfSSy/h4YcfxvHjx3HZZZfho48+glqtBgDMnDkT7777Lp599lm8+OKLyMrKwgsvvIC77ror+h6vvfYannrqKTz44IPo6elBXl4ennrqqUG1T6FQoKenBz/72c/Q0dGB1NRULFu2DM8///wP/rMgIqLEYVU9IiIasU5VvOvr64PFYkl0c4iIaBTjPU5ERERERERxMDgRERERERHFwal6REREREREcXDEiYiIiIiIKA4GJyIiIiIiojgYnIiIiIiIiOJgcCIiIiIiIoqDwYmIiIiIiCgOBiciIiIiIqI4GJyIiIiIiIjiYHAiIiIiIiKK4/8DEPqmahz5JFUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part of the code defines and trains the **seq2seq model** for your machine translation task. Let's break down each step and explain the components in detail:\n",
        "\n",
        "### 1. Defining the Model:\n",
        "```python\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "```\n",
        "- **`Model` Class**:\n",
        "  - This line creates a Keras model instance that takes two inputs (`encoder_inputs` and `decoder_inputs`) and outputs `decoder_outputs`.\n",
        "  - **Inputs**:\n",
        "    - `encoder_inputs`: Represents the input data to the encoder (e.g., one-hot encoded characters of the source language).\n",
        "    - `decoder_inputs`: Represents the input data to the decoder (e.g., one-hot encoded characters of the target language shifted by one time step).\n",
        "  - **Output**:\n",
        "    - `decoder_outputs`: The output from the decoder's LSTM layer after being passed through the `Dense` layer with `softmax` activation. This output is a sequence of probability distributions over the target language vocabulary.\n",
        "\n",
        "### 2. Compiling the Model:\n",
        "```python\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "```\n",
        "- **`compile` Method**:\n",
        "  - **`optimizer='rmsprop'`**:\n",
        "    - The model uses the **RMSprop** optimizer, which is well-suited for RNNs/LSTMs as it helps maintain a good learning rate throughout training by adapting the learning rate for each parameter.\n",
        "  - **`loss='categorical_crossentropy'`**:\n",
        "    - The loss function used is **categorical crossentropy**, which is appropriate for multi-class classification tasks where each output time step needs to predict a single token from a set of possible tokens (i.e., a probability distribution over the target vocabulary).\n",
        "  - **`metrics=['accuracy']`**:\n",
        "    - The model will also compute and report **accuracy** during training. Note that this metric checks how many predicted tokens match the actual tokens at each time step, but for sequence generation, more sophisticated evaluation metrics might be needed (e.g., BLEU score).\n",
        "\n",
        "### 3. Training the Model:\n",
        "```python\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "```\n",
        "- **`fit` Method**:\n",
        "  - **Training Data**:\n",
        "    - `[encoder_input_data, decoder_input_data]`: The model is trained using two input datasets:\n",
        "      - `encoder_input_data`: The one-hot encoded input sequences for the encoder.\n",
        "      - `decoder_input_data`: The one-hot encoded input sequences for the decoder (shifted target sequences).\n",
        "    - `decoder_target_data`: The expected output data, which the model aims to predict. This data is shifted by one time step relative to `decoder_input_data` for teacher forcing.\n",
        "  - **`batch_size=batch_size`**:\n",
        "    - Specifies the number of samples per gradient update. A smaller batch size can lead to more granular updates, while a larger batch size can speed up training.\n",
        "  - **`epochs=epochs`**:\n",
        "    - Number of complete passes through the training dataset.\n",
        "  - **`validation_split=0.2`**:\n",
        "    - A portion (20%) of the training data is set aside for validation. The model's performance on this validation set is evaluated at the end of each epoch to monitor for potential overfitting.\n",
        "\n",
        "### Detailed Process:\n",
        "- **Training**:\n",
        "  - The `fit` method runs the training loop, where the model's weights are updated using the training data.\n",
        "  - **Forward Pass**: The model computes the output probabilities for the target sequence given the input sequences.\n",
        "  - **Loss Calculation**: The categorical crossentropy loss is computed between `decoder_target_data` and the model's predictions (`decoder_outputs`).\n",
        "  - **Backward Pass**: The optimizer (RMSprop) updates the model weights to minimize the loss.\n",
        "- **Validation**:\n",
        "  - After each epoch, the model evaluates its performance on the 20% validation set.\n",
        "  - This helps monitor the model's generalization and detect overfitting.\n",
        "\n",
        "### Purpose of this Code:\n",
        "This code sets up the model's training process to learn a mapping from input sequences (e.g., Hindi sentences) to target sequences (e.g., English sentences). The encoder-decoder architecture, guided by the LSTM layers and one-hot encoded inputs, enables the model to handle variable-length sequences and learn contextual representations for translation tasks."
      ],
      "metadata": {
        "id": "ssJGEuYmo9H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model that will turn using adam optimizer & split 0.4\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model1 = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Run training\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model1.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.4)\n",
        "\n",
        "#save the model\n",
        "model1.save('s2s_adam.h5')\n",
        "\n",
        "#plot the model\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(history.history['loss'],label = 'training loss')\n",
        "plt.plot(history.history['val_loss'],label = 'validation loss')\n",
        "plt.title('loss vs epochs')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LsqFU_qBoVrJ",
        "outputId": "65ba8905-322f-4726-cf99-6ce6326ea715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - accuracy: 0.8277 - loss: 0.6577 - val_accuracy: 0.7569 - val_loss: 0.9360\n",
            "Epoch 2/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8261 - loss: 0.6568 - val_accuracy: 0.7563 - val_loss: 0.9278\n",
            "Epoch 3/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8294 - loss: 0.6495 - val_accuracy: 0.7572 - val_loss: 0.9258\n",
            "Epoch 4/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8275 - loss: 0.6528 - val_accuracy: 0.7592 - val_loss: 0.9241\n",
            "Epoch 5/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8294 - loss: 0.6444 - val_accuracy: 0.7581 - val_loss: 0.9253\n",
            "Epoch 6/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8289 - loss: 0.6450 - val_accuracy: 0.7562 - val_loss: 0.9249\n",
            "Epoch 7/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8276 - loss: 0.6487 - val_accuracy: 0.7575 - val_loss: 0.9242\n",
            "Epoch 8/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8295 - loss: 0.6439 - val_accuracy: 0.7582 - val_loss: 0.9225\n",
            "Epoch 9/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8307 - loss: 0.6376 - val_accuracy: 0.7604 - val_loss: 0.9194\n",
            "Epoch 10/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8313 - loss: 0.6383 - val_accuracy: 0.7594 - val_loss: 0.9193\n",
            "Epoch 11/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8308 - loss: 0.6393 - val_accuracy: 0.7590 - val_loss: 0.9197\n",
            "Epoch 12/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8307 - loss: 0.6387 - val_accuracy: 0.7595 - val_loss: 0.9231\n",
            "Epoch 13/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8302 - loss: 0.6402 - val_accuracy: 0.7593 - val_loss: 0.9222\n",
            "Epoch 14/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8298 - loss: 0.6385 - val_accuracy: 0.7592 - val_loss: 0.9175\n",
            "Epoch 15/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8304 - loss: 0.6372 - val_accuracy: 0.7602 - val_loss: 0.9165\n",
            "Epoch 16/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8329 - loss: 0.6295 - val_accuracy: 0.7599 - val_loss: 0.9213\n",
            "Epoch 17/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8312 - loss: 0.6333 - val_accuracy: 0.7600 - val_loss: 0.9206\n",
            "Epoch 18/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8329 - loss: 0.6293 - val_accuracy: 0.7606 - val_loss: 0.9201\n",
            "Epoch 19/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8314 - loss: 0.6365 - val_accuracy: 0.7603 - val_loss: 0.9204\n",
            "Epoch 20/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8325 - loss: 0.6303 - val_accuracy: 0.7593 - val_loss: 0.9179\n",
            "Epoch 21/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8334 - loss: 0.6263 - val_accuracy: 0.7603 - val_loss: 0.9186\n",
            "Epoch 22/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8332 - loss: 0.6255 - val_accuracy: 0.7614 - val_loss: 0.9172\n",
            "Epoch 23/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8345 - loss: 0.6260 - val_accuracy: 0.7618 - val_loss: 0.9142\n",
            "Epoch 24/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8347 - loss: 0.6249 - val_accuracy: 0.7608 - val_loss: 0.9137\n",
            "Epoch 25/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8357 - loss: 0.6168 - val_accuracy: 0.7587 - val_loss: 0.9133\n",
            "Epoch 26/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8333 - loss: 0.6232 - val_accuracy: 0.7594 - val_loss: 0.9105\n",
            "Epoch 27/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8334 - loss: 0.6195 - val_accuracy: 0.7611 - val_loss: 0.9095\n",
            "Epoch 28/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8347 - loss: 0.6210 - val_accuracy: 0.7607 - val_loss: 0.9100\n",
            "Epoch 29/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8348 - loss: 0.6214 - val_accuracy: 0.7616 - val_loss: 0.9118\n",
            "Epoch 30/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8362 - loss: 0.6150 - val_accuracy: 0.7613 - val_loss: 0.9121\n",
            "Epoch 31/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8363 - loss: 0.6174 - val_accuracy: 0.7616 - val_loss: 0.9095\n",
            "Epoch 32/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8356 - loss: 0.6172 - val_accuracy: 0.7600 - val_loss: 0.9069\n",
            "Epoch 33/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8356 - loss: 0.6130 - val_accuracy: 0.7613 - val_loss: 0.9065\n",
            "Epoch 34/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8362 - loss: 0.6129 - val_accuracy: 0.7629 - val_loss: 0.9076\n",
            "Epoch 35/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8352 - loss: 0.6196 - val_accuracy: 0.7624 - val_loss: 0.9048\n",
            "Epoch 36/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8381 - loss: 0.6089 - val_accuracy: 0.7623 - val_loss: 0.9053\n",
            "Epoch 37/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8376 - loss: 0.6090 - val_accuracy: 0.7614 - val_loss: 0.9040\n",
            "Epoch 38/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8367 - loss: 0.6134 - val_accuracy: 0.7621 - val_loss: 0.9042\n",
            "Epoch 39/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8382 - loss: 0.6080 - val_accuracy: 0.7619 - val_loss: 0.9074\n",
            "Epoch 40/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8363 - loss: 0.6131 - val_accuracy: 0.7614 - val_loss: 0.9043\n",
            "Epoch 41/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8372 - loss: 0.6089 - val_accuracy: 0.7625 - val_loss: 0.9049\n",
            "Epoch 42/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8377 - loss: 0.6075 - val_accuracy: 0.7626 - val_loss: 0.9019\n",
            "Epoch 43/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8388 - loss: 0.6058 - val_accuracy: 0.7637 - val_loss: 0.8997\n",
            "Epoch 44/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8402 - loss: 0.5990 - val_accuracy: 0.7593 - val_loss: 0.9296\n",
            "Epoch 45/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8355 - loss: 0.6159 - val_accuracy: 0.7590 - val_loss: 0.9144\n",
            "Epoch 46/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8351 - loss: 0.6159 - val_accuracy: 0.7604 - val_loss: 0.9151\n",
            "Epoch 47/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8376 - loss: 0.6093 - val_accuracy: 0.7619 - val_loss: 0.9149\n",
            "Epoch 48/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8368 - loss: 0.6113 - val_accuracy: 0.7643 - val_loss: 0.9069\n",
            "Epoch 49/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8388 - loss: 0.6010 - val_accuracy: 0.7647 - val_loss: 0.9005\n",
            "Epoch 50/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8374 - loss: 0.6095 - val_accuracy: 0.7659 - val_loss: 0.8997\n",
            "Epoch 51/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8388 - loss: 0.6049 - val_accuracy: 0.7650 - val_loss: 0.9010\n",
            "Epoch 52/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8391 - loss: 0.6032 - val_accuracy: 0.7651 - val_loss: 0.8994\n",
            "Epoch 53/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8395 - loss: 0.5997 - val_accuracy: 0.7649 - val_loss: 0.8979\n",
            "Epoch 54/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8419 - loss: 0.5967 - val_accuracy: 0.7649 - val_loss: 0.8979\n",
            "Epoch 55/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8394 - loss: 0.6008 - val_accuracy: 0.7640 - val_loss: 0.8998\n",
            "Epoch 56/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8405 - loss: 0.5917 - val_accuracy: 0.7651 - val_loss: 0.8990\n",
            "Epoch 57/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8408 - loss: 0.5923 - val_accuracy: 0.7650 - val_loss: 0.8993\n",
            "Epoch 58/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8402 - loss: 0.5968 - val_accuracy: 0.7656 - val_loss: 0.9014\n",
            "Epoch 59/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8398 - loss: 0.5963 - val_accuracy: 0.7648 - val_loss: 0.9011\n",
            "Epoch 60/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8407 - loss: 0.5938 - val_accuracy: 0.7651 - val_loss: 0.8972\n",
            "Epoch 61/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8424 - loss: 0.5879 - val_accuracy: 0.7662 - val_loss: 0.8964\n",
            "Epoch 62/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8418 - loss: 0.5900 - val_accuracy: 0.7666 - val_loss: 0.8982\n",
            "Epoch 63/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8427 - loss: 0.5868 - val_accuracy: 0.7659 - val_loss: 0.8995\n",
            "Epoch 64/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8411 - loss: 0.5899 - val_accuracy: 0.7658 - val_loss: 0.8975\n",
            "Epoch 65/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8423 - loss: 0.5853 - val_accuracy: 0.7649 - val_loss: 0.8972\n",
            "Epoch 66/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8421 - loss: 0.5851 - val_accuracy: 0.7648 - val_loss: 0.8965\n",
            "Epoch 67/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8412 - loss: 0.5857 - val_accuracy: 0.7656 - val_loss: 0.8951\n",
            "Epoch 68/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8430 - loss: 0.5833 - val_accuracy: 0.7661 - val_loss: 0.8967\n",
            "Epoch 69/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8437 - loss: 0.5804 - val_accuracy: 0.7657 - val_loss: 0.8976\n",
            "Epoch 70/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8417 - loss: 0.5846 - val_accuracy: 0.7660 - val_loss: 0.8953\n",
            "Epoch 71/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8443 - loss: 0.5795 - val_accuracy: 0.7674 - val_loss: 0.8940\n",
            "Epoch 72/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8443 - loss: 0.5805 - val_accuracy: 0.7679 - val_loss: 0.8936\n",
            "Epoch 73/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8447 - loss: 0.5787 - val_accuracy: 0.7670 - val_loss: 0.8939\n",
            "Epoch 74/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8437 - loss: 0.5814 - val_accuracy: 0.7665 - val_loss: 0.8944\n",
            "Epoch 75/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8452 - loss: 0.5792 - val_accuracy: 0.7670 - val_loss: 0.8933\n",
            "Epoch 76/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8452 - loss: 0.5763 - val_accuracy: 0.7669 - val_loss: 0.8922\n",
            "Epoch 77/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8449 - loss: 0.5764 - val_accuracy: 0.7678 - val_loss: 0.8915\n",
            "Epoch 78/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8459 - loss: 0.5749 - val_accuracy: 0.7673 - val_loss: 0.8914\n",
            "Epoch 79/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8458 - loss: 0.5736 - val_accuracy: 0.7674 - val_loss: 0.8915\n",
            "Epoch 80/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8449 - loss: 0.5761 - val_accuracy: 0.7675 - val_loss: 0.8920\n",
            "Epoch 81/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8469 - loss: 0.5691 - val_accuracy: 0.7680 - val_loss: 0.8918\n",
            "Epoch 82/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8466 - loss: 0.5727 - val_accuracy: 0.7673 - val_loss: 0.8928\n",
            "Epoch 83/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8469 - loss: 0.5701 - val_accuracy: 0.7673 - val_loss: 0.8955\n",
            "Epoch 84/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8450 - loss: 0.5751 - val_accuracy: 0.7679 - val_loss: 0.8908\n",
            "Epoch 85/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8463 - loss: 0.5731 - val_accuracy: 0.7683 - val_loss: 0.8908\n",
            "Epoch 86/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8479 - loss: 0.5638 - val_accuracy: 0.7674 - val_loss: 0.8962\n",
            "Epoch 87/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8466 - loss: 0.5680 - val_accuracy: 0.7681 - val_loss: 0.8939\n",
            "Epoch 88/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8484 - loss: 0.5661 - val_accuracy: 0.7681 - val_loss: 0.8915\n",
            "Epoch 89/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8472 - loss: 0.5679 - val_accuracy: 0.7666 - val_loss: 0.8952\n",
            "Epoch 90/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8478 - loss: 0.5659 - val_accuracy: 0.7662 - val_loss: 0.8955\n",
            "Epoch 91/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8464 - loss: 0.5666 - val_accuracy: 0.7677 - val_loss: 0.8904\n",
            "Epoch 92/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8484 - loss: 0.5657 - val_accuracy: 0.7681 - val_loss: 0.8900\n",
            "Epoch 93/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8486 - loss: 0.5621 - val_accuracy: 0.7686 - val_loss: 0.8886\n",
            "Epoch 94/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8478 - loss: 0.5640 - val_accuracy: 0.7686 - val_loss: 0.8874\n",
            "Epoch 95/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8479 - loss: 0.5598 - val_accuracy: 0.7688 - val_loss: 0.8885\n",
            "Epoch 96/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8499 - loss: 0.5602 - val_accuracy: 0.7675 - val_loss: 0.8911\n",
            "Epoch 97/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8496 - loss: 0.5607 - val_accuracy: 0.7677 - val_loss: 0.8889\n",
            "Epoch 98/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8496 - loss: 0.5576 - val_accuracy: 0.7679 - val_loss: 0.8867\n",
            "Epoch 99/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8488 - loss: 0.5580 - val_accuracy: 0.7681 - val_loss: 0.8873\n",
            "Epoch 100/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8496 - loss: 0.5589 - val_accuracy: 0.7685 - val_loss: 0.8888\n",
            "Epoch 101/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8502 - loss: 0.5565 - val_accuracy: 0.7684 - val_loss: 0.8901\n",
            "Epoch 102/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8511 - loss: 0.5522 - val_accuracy: 0.7677 - val_loss: 0.8905\n",
            "Epoch 103/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8506 - loss: 0.5569 - val_accuracy: 0.7690 - val_loss: 0.8878\n",
            "Epoch 104/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8492 - loss: 0.5552 - val_accuracy: 0.7683 - val_loss: 0.8905\n",
            "Epoch 105/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8513 - loss: 0.5546 - val_accuracy: 0.7672 - val_loss: 0.8927\n",
            "Epoch 106/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8516 - loss: 0.5559 - val_accuracy: 0.7677 - val_loss: 0.8900\n",
            "Epoch 107/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8503 - loss: 0.5517 - val_accuracy: 0.7681 - val_loss: 0.8868\n",
            "Epoch 108/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8510 - loss: 0.5483 - val_accuracy: 0.7679 - val_loss: 0.8875\n",
            "Epoch 109/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8518 - loss: 0.5533 - val_accuracy: 0.7687 - val_loss: 0.8884\n",
            "Epoch 110/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8516 - loss: 0.5502 - val_accuracy: 0.7691 - val_loss: 0.8880\n",
            "Epoch 111/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8546 - loss: 0.5459 - val_accuracy: 0.7686 - val_loss: 0.8880\n",
            "Epoch 112/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8528 - loss: 0.5494 - val_accuracy: 0.7681 - val_loss: 0.8881\n",
            "Epoch 113/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8519 - loss: 0.5504 - val_accuracy: 0.7683 - val_loss: 0.8882\n",
            "Epoch 114/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8542 - loss: 0.5452 - val_accuracy: 0.7681 - val_loss: 0.8851\n",
            "Epoch 115/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8528 - loss: 0.5469 - val_accuracy: 0.7689 - val_loss: 0.8851\n",
            "Epoch 116/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8530 - loss: 0.5461 - val_accuracy: 0.7685 - val_loss: 0.8869\n",
            "Epoch 117/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8542 - loss: 0.5424 - val_accuracy: 0.7683 - val_loss: 0.8868\n",
            "Epoch 118/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8535 - loss: 0.5451 - val_accuracy: 0.7692 - val_loss: 0.8829\n",
            "Epoch 119/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8541 - loss: 0.5403 - val_accuracy: 0.7692 - val_loss: 0.8860\n",
            "Epoch 120/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8553 - loss: 0.5397 - val_accuracy: 0.7688 - val_loss: 0.8883\n",
            "Epoch 121/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8554 - loss: 0.5376 - val_accuracy: 0.7687 - val_loss: 0.8837\n",
            "Epoch 122/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8541 - loss: 0.5407 - val_accuracy: 0.7698 - val_loss: 0.8846\n",
            "Epoch 123/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8547 - loss: 0.5406 - val_accuracy: 0.7684 - val_loss: 0.8899\n",
            "Epoch 124/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8545 - loss: 0.5370 - val_accuracy: 0.7688 - val_loss: 0.8861\n",
            "Epoch 125/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8557 - loss: 0.5383 - val_accuracy: 0.7671 - val_loss: 0.8900\n",
            "Epoch 126/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8562 - loss: 0.5390 - val_accuracy: 0.7702 - val_loss: 0.8853\n",
            "Epoch 127/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8555 - loss: 0.5343 - val_accuracy: 0.7685 - val_loss: 0.8858\n",
            "Epoch 128/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8586 - loss: 0.5348 - val_accuracy: 0.7685 - val_loss: 0.8874\n",
            "Epoch 129/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8567 - loss: 0.5318 - val_accuracy: 0.7695 - val_loss: 0.8870\n",
            "Epoch 130/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8559 - loss: 0.5323 - val_accuracy: 0.7678 - val_loss: 0.8880\n",
            "Epoch 131/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8566 - loss: 0.5349 - val_accuracy: 0.7700 - val_loss: 0.8892\n",
            "Epoch 132/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8560 - loss: 0.5328 - val_accuracy: 0.7694 - val_loss: 0.8861\n",
            "Epoch 133/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8579 - loss: 0.5307 - val_accuracy: 0.7701 - val_loss: 0.8874\n",
            "Epoch 134/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8570 - loss: 0.5304 - val_accuracy: 0.7712 - val_loss: 0.8861\n",
            "Epoch 135/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8568 - loss: 0.5337 - val_accuracy: 0.7699 - val_loss: 0.8844\n",
            "Epoch 136/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8568 - loss: 0.5307 - val_accuracy: 0.7704 - val_loss: 0.8864\n",
            "Epoch 137/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8579 - loss: 0.5262 - val_accuracy: 0.7690 - val_loss: 0.8905\n",
            "Epoch 138/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8590 - loss: 0.5273 - val_accuracy: 0.7693 - val_loss: 0.8854\n",
            "Epoch 139/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8580 - loss: 0.5289 - val_accuracy: 0.7689 - val_loss: 0.8847\n",
            "Epoch 140/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8577 - loss: 0.5298 - val_accuracy: 0.7691 - val_loss: 0.8827\n",
            "Epoch 141/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8569 - loss: 0.5292 - val_accuracy: 0.7707 - val_loss: 0.8853\n",
            "Epoch 142/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8571 - loss: 0.5264 - val_accuracy: 0.7690 - val_loss: 0.8829\n",
            "Epoch 143/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8592 - loss: 0.5233 - val_accuracy: 0.7684 - val_loss: 0.8844\n",
            "Epoch 144/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8599 - loss: 0.5208 - val_accuracy: 0.7685 - val_loss: 0.8877\n",
            "Epoch 145/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8597 - loss: 0.5200 - val_accuracy: 0.7700 - val_loss: 0.8862\n",
            "Epoch 146/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8604 - loss: 0.5207 - val_accuracy: 0.7689 - val_loss: 0.8822\n",
            "Epoch 147/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8597 - loss: 0.5203 - val_accuracy: 0.7691 - val_loss: 0.8868\n",
            "Epoch 148/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8597 - loss: 0.5225 - val_accuracy: 0.7681 - val_loss: 0.8905\n",
            "Epoch 149/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8602 - loss: 0.5213 - val_accuracy: 0.7680 - val_loss: 0.8902\n",
            "Epoch 150/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8605 - loss: 0.5159 - val_accuracy: 0.7687 - val_loss: 0.8850\n",
            "Epoch 151/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8601 - loss: 0.5204 - val_accuracy: 0.7698 - val_loss: 0.8882\n",
            "Epoch 152/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8594 - loss: 0.5206 - val_accuracy: 0.7697 - val_loss: 0.8855\n",
            "Epoch 153/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8621 - loss: 0.5144 - val_accuracy: 0.7703 - val_loss: 0.8847\n",
            "Epoch 154/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8613 - loss: 0.5155 - val_accuracy: 0.7700 - val_loss: 0.8847\n",
            "Epoch 155/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8602 - loss: 0.5167 - val_accuracy: 0.7713 - val_loss: 0.8832\n",
            "Epoch 156/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8621 - loss: 0.5130 - val_accuracy: 0.7713 - val_loss: 0.8822\n",
            "Epoch 157/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8611 - loss: 0.5148 - val_accuracy: 0.7695 - val_loss: 0.8848\n",
            "Epoch 158/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8611 - loss: 0.5128 - val_accuracy: 0.7703 - val_loss: 0.8852\n",
            "Epoch 159/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8627 - loss: 0.5068 - val_accuracy: 0.7691 - val_loss: 0.8853\n",
            "Epoch 160/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8612 - loss: 0.5130 - val_accuracy: 0.7694 - val_loss: 0.8887\n",
            "Epoch 161/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8631 - loss: 0.5096 - val_accuracy: 0.7708 - val_loss: 0.8846\n",
            "Epoch 162/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8632 - loss: 0.5071 - val_accuracy: 0.7697 - val_loss: 0.8889\n",
            "Epoch 163/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8616 - loss: 0.5082 - val_accuracy: 0.7694 - val_loss: 0.8879\n",
            "Epoch 164/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8641 - loss: 0.5087 - val_accuracy: 0.7695 - val_loss: 0.8869\n",
            "Epoch 165/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8637 - loss: 0.5049 - val_accuracy: 0.7691 - val_loss: 0.8895\n",
            "Epoch 166/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8622 - loss: 0.5112 - val_accuracy: 0.7700 - val_loss: 0.8887\n",
            "Epoch 167/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8639 - loss: 0.5056 - val_accuracy: 0.7692 - val_loss: 0.8851\n",
            "Epoch 168/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8624 - loss: 0.5069 - val_accuracy: 0.7681 - val_loss: 0.8888\n",
            "Epoch 169/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8647 - loss: 0.5025 - val_accuracy: 0.7685 - val_loss: 0.8953\n",
            "Epoch 170/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8638 - loss: 0.5047 - val_accuracy: 0.7679 - val_loss: 0.8970\n",
            "Epoch 171/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8647 - loss: 0.5037 - val_accuracy: 0.7684 - val_loss: 0.8906\n",
            "Epoch 172/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8640 - loss: 0.5028 - val_accuracy: 0.7703 - val_loss: 0.8835\n",
            "Epoch 173/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8652 - loss: 0.5027 - val_accuracy: 0.7705 - val_loss: 0.8888\n",
            "Epoch 174/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8654 - loss: 0.5004 - val_accuracy: 0.7704 - val_loss: 0.8861\n",
            "Epoch 175/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8637 - loss: 0.5029 - val_accuracy: 0.7710 - val_loss: 0.8883\n",
            "Epoch 176/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8655 - loss: 0.4959 - val_accuracy: 0.7706 - val_loss: 0.8849\n",
            "Epoch 177/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8658 - loss: 0.4960 - val_accuracy: 0.7698 - val_loss: 0.8898\n",
            "Epoch 178/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8666 - loss: 0.4962 - val_accuracy: 0.7706 - val_loss: 0.8886\n",
            "Epoch 179/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8660 - loss: 0.4956 - val_accuracy: 0.7697 - val_loss: 0.8903\n",
            "Epoch 180/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8669 - loss: 0.4948 - val_accuracy: 0.7709 - val_loss: 0.8899\n",
            "Epoch 181/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8659 - loss: 0.4954 - val_accuracy: 0.7702 - val_loss: 0.8908\n",
            "Epoch 182/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8671 - loss: 0.4943 - val_accuracy: 0.7682 - val_loss: 0.8914\n",
            "Epoch 183/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8663 - loss: 0.4937 - val_accuracy: 0.7699 - val_loss: 0.8941\n",
            "Epoch 184/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8672 - loss: 0.4909 - val_accuracy: 0.7676 - val_loss: 0.8978\n",
            "Epoch 185/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8657 - loss: 0.4948 - val_accuracy: 0.7692 - val_loss: 0.8925\n",
            "Epoch 186/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8665 - loss: 0.4886 - val_accuracy: 0.7671 - val_loss: 0.8910\n",
            "Epoch 187/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8673 - loss: 0.4927 - val_accuracy: 0.7705 - val_loss: 0.8895\n",
            "Epoch 188/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8683 - loss: 0.4896 - val_accuracy: 0.7688 - val_loss: 0.8925\n",
            "Epoch 189/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8686 - loss: 0.4858 - val_accuracy: 0.7700 - val_loss: 0.8866\n",
            "Epoch 190/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8680 - loss: 0.4893 - val_accuracy: 0.7690 - val_loss: 0.8911\n",
            "Epoch 191/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8692 - loss: 0.4862 - val_accuracy: 0.7697 - val_loss: 0.8902\n",
            "Epoch 192/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8678 - loss: 0.4878 - val_accuracy: 0.7687 - val_loss: 0.8933\n",
            "Epoch 193/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8690 - loss: 0.4839 - val_accuracy: 0.7690 - val_loss: 0.8932\n",
            "Epoch 194/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8692 - loss: 0.4844 - val_accuracy: 0.7690 - val_loss: 0.8960\n",
            "Epoch 195/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8685 - loss: 0.4835 - val_accuracy: 0.7692 - val_loss: 0.8927\n",
            "Epoch 196/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8687 - loss: 0.4835 - val_accuracy: 0.7695 - val_loss: 0.8916\n",
            "Epoch 197/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8670 - loss: 0.4891 - val_accuracy: 0.7679 - val_loss: 0.9000\n",
            "Epoch 198/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8690 - loss: 0.4812 - val_accuracy: 0.7700 - val_loss: 0.8906\n",
            "Epoch 199/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8685 - loss: 0.4844 - val_accuracy: 0.7668 - val_loss: 0.9014\n",
            "Epoch 200/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8688 - loss: 0.4841 - val_accuracy: 0.7685 - val_loss: 0.8954\n",
            "Epoch 201/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8690 - loss: 0.4823 - val_accuracy: 0.7681 - val_loss: 0.8994\n",
            "Epoch 202/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8699 - loss: 0.4785 - val_accuracy: 0.7686 - val_loss: 0.8972\n",
            "Epoch 203/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8707 - loss: 0.4774 - val_accuracy: 0.7679 - val_loss: 0.9010\n",
            "Epoch 204/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8677 - loss: 0.4878 - val_accuracy: 0.7718 - val_loss: 0.8902\n",
            "Epoch 205/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8703 - loss: 0.4776 - val_accuracy: 0.7686 - val_loss: 0.8971\n",
            "Epoch 206/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8700 - loss: 0.4792 - val_accuracy: 0.7701 - val_loss: 0.8927\n",
            "Epoch 207/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8713 - loss: 0.4731 - val_accuracy: 0.7673 - val_loss: 0.8981\n",
            "Epoch 208/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8712 - loss: 0.4802 - val_accuracy: 0.7684 - val_loss: 0.8967\n",
            "Epoch 209/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8702 - loss: 0.4771 - val_accuracy: 0.7692 - val_loss: 0.8974\n",
            "Epoch 210/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8710 - loss: 0.4752 - val_accuracy: 0.7681 - val_loss: 0.8963\n",
            "Epoch 211/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8710 - loss: 0.4736 - val_accuracy: 0.7704 - val_loss: 0.8947\n",
            "Epoch 212/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8704 - loss: 0.4759 - val_accuracy: 0.7691 - val_loss: 0.8994\n",
            "Epoch 213/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8718 - loss: 0.4724 - val_accuracy: 0.7690 - val_loss: 0.8984\n",
            "Epoch 214/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8724 - loss: 0.4696 - val_accuracy: 0.7684 - val_loss: 0.8995\n",
            "Epoch 215/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8719 - loss: 0.4710 - val_accuracy: 0.7688 - val_loss: 0.8969\n",
            "Epoch 216/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8712 - loss: 0.4721 - val_accuracy: 0.7692 - val_loss: 0.8990\n",
            "Epoch 217/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8714 - loss: 0.4710 - val_accuracy: 0.7681 - val_loss: 0.9008\n",
            "Epoch 218/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8729 - loss: 0.4691 - val_accuracy: 0.7697 - val_loss: 0.8992\n",
            "Epoch 219/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8729 - loss: 0.4655 - val_accuracy: 0.7682 - val_loss: 0.9055\n",
            "Epoch 220/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8738 - loss: 0.4668 - val_accuracy: 0.7704 - val_loss: 0.8980\n",
            "Epoch 221/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8720 - loss: 0.4637 - val_accuracy: 0.7669 - val_loss: 0.9047\n",
            "Epoch 222/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8735 - loss: 0.4658 - val_accuracy: 0.7683 - val_loss: 0.9019\n",
            "Epoch 223/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8736 - loss: 0.4643 - val_accuracy: 0.7670 - val_loss: 0.9107\n",
            "Epoch 224/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8747 - loss: 0.4644 - val_accuracy: 0.7681 - val_loss: 0.9026\n",
            "Epoch 225/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8726 - loss: 0.4658 - val_accuracy: 0.7666 - val_loss: 0.9081\n",
            "Epoch 226/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8734 - loss: 0.4623 - val_accuracy: 0.7681 - val_loss: 0.9049\n",
            "Epoch 227/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8743 - loss: 0.4597 - val_accuracy: 0.7683 - val_loss: 0.9029\n",
            "Epoch 228/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8753 - loss: 0.4561 - val_accuracy: 0.7671 - val_loss: 0.9044\n",
            "Epoch 229/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8747 - loss: 0.4587 - val_accuracy: 0.7681 - val_loss: 0.9038\n",
            "Epoch 230/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8766 - loss: 0.4511 - val_accuracy: 0.7681 - val_loss: 0.9016\n",
            "Epoch 231/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8753 - loss: 0.4576 - val_accuracy: 0.7674 - val_loss: 0.9036\n",
            "Epoch 232/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8742 - loss: 0.4596 - val_accuracy: 0.7688 - val_loss: 0.9067\n",
            "Epoch 233/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8743 - loss: 0.4590 - val_accuracy: 0.7658 - val_loss: 0.9064\n",
            "Epoch 234/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8757 - loss: 0.4560 - val_accuracy: 0.7676 - val_loss: 0.9076\n",
            "Epoch 235/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8750 - loss: 0.4535 - val_accuracy: 0.7652 - val_loss: 0.9176\n",
            "Epoch 236/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8766 - loss: 0.4523 - val_accuracy: 0.7685 - val_loss: 0.9041\n",
            "Epoch 237/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8744 - loss: 0.4570 - val_accuracy: 0.7674 - val_loss: 0.9090\n",
            "Epoch 238/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8749 - loss: 0.4549 - val_accuracy: 0.7653 - val_loss: 0.9210\n",
            "Epoch 239/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8752 - loss: 0.4565 - val_accuracy: 0.7664 - val_loss: 0.9095\n",
            "Epoch 240/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8772 - loss: 0.4528 - val_accuracy: 0.7647 - val_loss: 0.9144\n",
            "Epoch 241/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8760 - loss: 0.4512 - val_accuracy: 0.7669 - val_loss: 0.9127\n",
            "Epoch 242/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8769 - loss: 0.4523 - val_accuracy: 0.7665 - val_loss: 0.9130\n",
            "Epoch 243/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8771 - loss: 0.4511 - val_accuracy: 0.7672 - val_loss: 0.9123\n",
            "Epoch 244/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8767 - loss: 0.4489 - val_accuracy: 0.7671 - val_loss: 0.9143\n",
            "Epoch 245/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8780 - loss: 0.4460 - val_accuracy: 0.7663 - val_loss: 0.9173\n",
            "Epoch 246/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8781 - loss: 0.4465 - val_accuracy: 0.7689 - val_loss: 0.9122\n",
            "Epoch 247/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8760 - loss: 0.4520 - val_accuracy: 0.7634 - val_loss: 0.9280\n",
            "Epoch 248/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8782 - loss: 0.4476 - val_accuracy: 0.7670 - val_loss: 0.9209\n",
            "Epoch 249/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8767 - loss: 0.4490 - val_accuracy: 0.7644 - val_loss: 0.9270\n",
            "Epoch 250/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8768 - loss: 0.4473 - val_accuracy: 0.7662 - val_loss: 0.9227\n",
            "Epoch 251/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8776 - loss: 0.4465 - val_accuracy: 0.7672 - val_loss: 0.9177\n",
            "Epoch 252/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8775 - loss: 0.4433 - val_accuracy: 0.7671 - val_loss: 0.9169\n",
            "Epoch 253/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8774 - loss: 0.4443 - val_accuracy: 0.7668 - val_loss: 0.9255\n",
            "Epoch 254/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8781 - loss: 0.4423 - val_accuracy: 0.7640 - val_loss: 0.9318\n",
            "Epoch 255/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8794 - loss: 0.4403 - val_accuracy: 0.7673 - val_loss: 0.9169\n",
            "Epoch 256/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8784 - loss: 0.4432 - val_accuracy: 0.7626 - val_loss: 0.9327\n",
            "Epoch 257/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8783 - loss: 0.4441 - val_accuracy: 0.7666 - val_loss: 0.9211\n",
            "Epoch 258/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8765 - loss: 0.4444 - val_accuracy: 0.7611 - val_loss: 0.9355\n",
            "Epoch 259/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8778 - loss: 0.4438 - val_accuracy: 0.7669 - val_loss: 0.9241\n",
            "Epoch 260/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8793 - loss: 0.4381 - val_accuracy: 0.7628 - val_loss: 0.9370\n",
            "Epoch 261/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8788 - loss: 0.4425 - val_accuracy: 0.7692 - val_loss: 0.9133\n",
            "Epoch 262/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8789 - loss: 0.4392 - val_accuracy: 0.7651 - val_loss: 0.9337\n",
            "Epoch 263/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8796 - loss: 0.4398 - val_accuracy: 0.7663 - val_loss: 0.9308\n",
            "Epoch 264/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8794 - loss: 0.4387 - val_accuracy: 0.7646 - val_loss: 0.9275\n",
            "Epoch 265/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8801 - loss: 0.4386 - val_accuracy: 0.7654 - val_loss: 0.9244\n",
            "Epoch 266/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8790 - loss: 0.4364 - val_accuracy: 0.7648 - val_loss: 0.9314\n",
            "Epoch 267/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8811 - loss: 0.4351 - val_accuracy: 0.7651 - val_loss: 0.9278\n",
            "Epoch 268/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8800 - loss: 0.4350 - val_accuracy: 0.7646 - val_loss: 0.9335\n",
            "Epoch 269/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8811 - loss: 0.4328 - val_accuracy: 0.7656 - val_loss: 0.9338\n",
            "Epoch 270/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8807 - loss: 0.4322 - val_accuracy: 0.7636 - val_loss: 0.9357\n",
            "Epoch 271/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8815 - loss: 0.4355 - val_accuracy: 0.7636 - val_loss: 0.9370\n",
            "Epoch 272/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8812 - loss: 0.4331 - val_accuracy: 0.7640 - val_loss: 0.9373\n",
            "Epoch 273/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8805 - loss: 0.4328 - val_accuracy: 0.7630 - val_loss: 0.9414\n",
            "Epoch 274/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8815 - loss: 0.4300 - val_accuracy: 0.7651 - val_loss: 0.9339\n",
            "Epoch 275/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8814 - loss: 0.4297 - val_accuracy: 0.7645 - val_loss: 0.9309\n",
            "Epoch 276/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8810 - loss: 0.4299 - val_accuracy: 0.7631 - val_loss: 0.9420\n",
            "Epoch 277/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8819 - loss: 0.4306 - val_accuracy: 0.7641 - val_loss: 0.9383\n",
            "Epoch 278/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8821 - loss: 0.4301 - val_accuracy: 0.7648 - val_loss: 0.9321\n",
            "Epoch 279/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8833 - loss: 0.4281 - val_accuracy: 0.7644 - val_loss: 0.9360\n",
            "Epoch 280/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8820 - loss: 0.4267 - val_accuracy: 0.7635 - val_loss: 0.9352\n",
            "Epoch 281/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8834 - loss: 0.4253 - val_accuracy: 0.7626 - val_loss: 0.9445\n",
            "Epoch 282/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8832 - loss: 0.4259 - val_accuracy: 0.7664 - val_loss: 0.9328\n",
            "Epoch 283/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8828 - loss: 0.4243 - val_accuracy: 0.7655 - val_loss: 0.9355\n",
            "Epoch 284/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8825 - loss: 0.4238 - val_accuracy: 0.7656 - val_loss: 0.9334\n",
            "Epoch 285/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8838 - loss: 0.4214 - val_accuracy: 0.7650 - val_loss: 0.9371\n",
            "Epoch 286/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8839 - loss: 0.4202 - val_accuracy: 0.7641 - val_loss: 0.9435\n",
            "Epoch 287/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8823 - loss: 0.4262 - val_accuracy: 0.7642 - val_loss: 0.9354\n",
            "Epoch 288/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8840 - loss: 0.4212 - val_accuracy: 0.7623 - val_loss: 0.9519\n",
            "Epoch 289/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8857 - loss: 0.4179 - val_accuracy: 0.7643 - val_loss: 0.9435\n",
            "Epoch 290/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8843 - loss: 0.4185 - val_accuracy: 0.7621 - val_loss: 0.9479\n",
            "Epoch 291/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8851 - loss: 0.4174 - val_accuracy: 0.7631 - val_loss: 0.9470\n",
            "Epoch 292/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8858 - loss: 0.4183 - val_accuracy: 0.7639 - val_loss: 0.9501\n",
            "Epoch 293/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8855 - loss: 0.4174 - val_accuracy: 0.7630 - val_loss: 0.9471\n",
            "Epoch 294/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8875 - loss: 0.4123 - val_accuracy: 0.7642 - val_loss: 0.9389\n",
            "Epoch 295/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8847 - loss: 0.4166 - val_accuracy: 0.7641 - val_loss: 0.9461\n",
            "Epoch 296/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8852 - loss: 0.4155 - val_accuracy: 0.7638 - val_loss: 0.9479\n",
            "Epoch 297/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8842 - loss: 0.4162 - val_accuracy: 0.7631 - val_loss: 0.9488\n",
            "Epoch 298/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8863 - loss: 0.4109 - val_accuracy: 0.7628 - val_loss: 0.9465\n",
            "Epoch 299/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8873 - loss: 0.4083 - val_accuracy: 0.7602 - val_loss: 0.9631\n",
            "Epoch 300/300\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8852 - loss: 0.4171 - val_accuracy: 0.7646 - val_loss: 0.9518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#better accuracy obtained here"
      ],
      "metadata": {
        "id": "K8E0FoSxpE9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder setup"
      ],
      "metadata": {
        "id": "DAe7zNLJrghy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference Setup\n",
        "1) Encode the input sentence and retrieve the initial decoder state\n",
        "\n",
        "2) Run one step of the decoder with this initial state and a \"start of\n",
        "sequence\" token as target. The output will be the next target character.\n",
        "\n",
        "3) Append the target character predicted and repeat.\n"
      ],
      "metadata": {
        "id": "iPDWewnA8UsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)#this encoder model will take encoder inputs and output encoder states(from previous)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))#now make the states it will have latent dimension neurons\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)#setup decoder and input is same of decoder as previous initial state now is decoder ka\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)#normal dense is done as above\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,#now will take input of decoder input and decoder input states\n",
        "    [decoder_outputs] + decoder_states)#output will give decoder output and decoder states(this is then used to take context)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_dict.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_dict.items())\n"
      ],
      "metadata": {
        "id": "M3e5mqMCpYBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of the code is creating separate models for **inference** after training a sequence-to-sequence (seq2seq) model with LSTM layers. The training model is used to learn how to encode and decode sequences, but during inference (generating new sequences), a different approach is needed. Let's go through what each part of this code does:\n",
        "\n",
        "### 1. **Encoder Model for Inference**\n",
        "```python\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "```\n",
        "- **Purpose**: This line defines the encoder model for inference.\n",
        "- **Function**: During inference, we need to encode new input sequences into latent states (hidden and cell states of the LSTM). This standalone `encoder_model` accepts an input sequence and outputs the LSTM's hidden and cell states (`encoder_states`).\n",
        "- **Input**: `encoder_inputs` (the input sequence).\n",
        "- **Output**: `encoder_states` (the last hidden state `state_h` and cell state `state_c` of the encoder LSTM).\n",
        "\n",
        "### 2. **Decoder Model Inputs for Inference**\n",
        "```python\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "```\n",
        "- **Purpose**: These lines set up placeholders for the decoder's initial states during inference.\n",
        "- **Function**: During training, the decoder receives initial states from the encoder, but during inference, we need to provide these states explicitly to the decoder. `decoder_state_input_h` and `decoder_state_input_c` will hold the previous hidden and cell states.\n",
        "- **Input Shape**: The shape matches the latent dimension used in the LSTM (`latent_dim`).\n",
        "\n",
        "### 3. **Decoder Model for Inference**\n",
        "```python\n",
        "decoder_outputs, state_h, state_c = decoder(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "```\n",
        "- **Purpose**: These lines set up the LSTM decoder for inference.\n",
        "- **Function**: The `decoder` LSTM layer is reused from the training phase but is set to accept the initial state inputs (`decoder_states_inputs`) and produce:\n",
        "  - `decoder_outputs`: The output token probabilities for the current timestep.\n",
        "  - `state_h` and `state_c`: The updated hidden and cell states to be passed to the next timestep.\n",
        "- **Output**: The output of the decoder is passed through a dense layer (`decoder_dense`) with a softmax activation to generate a probability distribution over the target tokens.\n",
        "\n",
        "### 4. **Final Decoder Model Definition**\n",
        "```python\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "```\n",
        "- **Purpose**: This defines the complete decoder model for inference.\n",
        "- **Inputs**:\n",
        "  - `decoder_inputs`: The input token for the current timestep.\n",
        "  - `decoder_states_inputs`: The hidden and cell states from the previous timestep.\n",
        "- **Outputs**:\n",
        "  - `decoder_outputs`: The output token probabilities.\n",
        "  - `decoder_states`: The updated hidden and cell states to be fed back in for the next timestep.\n",
        "\n",
        "### 5. **Reverse-Lookup Dictionaries**\n",
        "```python\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_dict.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_dict.items())\n",
        "```\n",
        "- **Purpose**: These dictionaries are used to map integer indices back to their corresponding characters (or tokens).\n",
        "- **Function**:\n",
        "  - `reverse_input_char_index`: Maps from indices to characters for the input language.\n",
        "  - `reverse_target_char_index`: Maps from indices to characters for the target language.\n",
        "- **Use Case**: When decoding sequences, these reverse mappings help translate the model's predicted indices back into readable characters or tokens.\n",
        "\n",
        "### **Summary of Inference Workflow**\n",
        "1. **Encode** the input sequence using `encoder_model` to obtain initial state vectors (`state_h`, `state_c`).\n",
        "2. **Initialize** the decoder with the start token and use `decoder_model` to predict the next token.\n",
        "3. **Update** the input to the decoder with the output token and updated states.\n",
        "4. **Repeat** the process until an end token is generated or a maximum sequence length is reached.\n",
        "5. **Decode** the output using `reverse_target_char_index` to construct a human-readable sentence.\n",
        "\n",
        "This process allows for generating target sequences from unseen input sequences during inference."
      ],
      "metadata": {
        "id": "Dtct3y7O8w2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)#since now encoder is setup to proivde states as the output that is used here\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))#so create a start of sequence i.e \\t to act as first input in inference phase\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_dict['\\t']] = 1.#make the ohe of it as 1st seq 1st char with putting 1 in the num_decoder_tokens\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(#output is normal and will have num_of_target_tokens ka as in dense we added that many layers\n",
        "            [target_seq] + states_value)#so inital will take the input of encoder states and target seq(sos) then the context of decoder is added as state\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])#take the max probability of decoder outputs\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]#get the character of it\n",
        "        decoded_sentence += sampled_char#add to decoder sentence\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True#to stop if eos reached or greater than length\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))#now the new target seq is the one predicted by decoder in previous(since INFERENCE stage else decoder input in previous)\n",
        "        target_seq[0, 0, sampled_token_index] = 1.#so make ohe of that\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]#update the states to be of decoder now\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "q8mMJIO5ru5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function, `decode_sequence`, is designed for the **inference phase** of a sequence-to-sequence model using an LSTM encoder-decoder architecture. It generates an output sentence in the target language given an input sequence in the source language. Here's a detailed breakdown of how the function works:\n",
        "\n",
        "### Step-by-step Explanation:\n",
        "1. **Encoding the Input Sequence**:\n",
        "   - The function receives an input sequence (`input_seq`) in one-hot encoded form.\n",
        "   - It passes `input_seq` through the trained `encoder_model` using `encoder_model.predict(input_seq)`.\n",
        "   - This prediction returns the final hidden and cell states of the encoder, `states_value`, which represent the context of the input sequence and are used to initialize the decoder.\n",
        "\n",
        "2. **Initializing the Target Sequence**:\n",
        "   - An initial target sequence (`target_seq`) of length 1 is created, initialized as an array of zeros. This acts as the starting input for the decoder.\n",
        "   - The first element in `target_seq` is set to the one-hot representation of the \"start of sequence\" character (`\\t`), which signals the decoder to start generating an output sequence.\n",
        "\n",
        "3. **Decoding Loop**:\n",
        "   - A `while` loop runs until the `stop_condition` is met. This loop generates the output sequence token by token.\n",
        "   - The decoder model (`decoder_model`) predicts the next token using:\n",
        "     - The current `target_seq` (starting with the start token initially).\n",
        "     - The state values from either the encoder (for the first token) or the decoder (for subsequent tokens).\n",
        "   - The decoder outputs:\n",
        "     - `output_tokens`: The predicted probabilities of the next character.\n",
        "     - `h` and `c`: Updated hidden and cell states that will be fed back into the decoder for the next prediction.\n",
        "\n",
        "4. **Sampling a Token**:\n",
        "   - The `np.argmax(output_tokens[0, -1, :])` selects the index of the token with the highest probability from the decoder's output.\n",
        "   - This index is mapped to the actual character using `reverse_target_char_index` to find the `sampled_char`.\n",
        "   - The `sampled_char` is added to the `decoded_sentence`.\n",
        "\n",
        "5. **Stop Condition**:\n",
        "   - The loop stops when:\n",
        "     - The `sampled_char` is the end-of-sequence character (`\\n`).\n",
        "     - The `decoded_sentence` reaches a length greater than `max_decoder_seq_length` (to prevent infinite loops).\n",
        "\n",
        "6. **Preparing the Next Input**:\n",
        "   - A new `target_seq` is prepared with the one-hot encoding of `sampled_char` to be fed as input for the next iteration of the loop.\n",
        "   - The `states_value` is updated with the current `h` and `c` to maintain the decoder's context.\n",
        "\n",
        "7. **Return**:\n",
        "   - The function returns the `decoded_sentence`, which is the final generated sequence in the target language.\n",
        "\n",
        "### Summary:\n",
        "- The function starts by encoding the input sequence to get the initial context.\n",
        "- It uses a loop to generate each subsequent character, feeding the output state back into the decoder to continue generating until a stop condition is met.\n",
        "- The final output is a sentence decoded from the predicted character tokens."
      ],
      "metadata": {
        "id": "RDGXcvcJ9_Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in range(90):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-fEh8mcrxCP",
        "outputId": "1a9e7ff4-5cca-47fc-8671-011106e6c157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: बाहर करो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: बार्या ह!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: बार्या ह!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: बाहर करो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: सादर को!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: सादर को!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: सादर को!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: बाहर करो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: बाहर करो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: बाहर करो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: बाहर करो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Exhale.\n",
            "Decoded sentence: सासक करता है?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "-\n",
            "Input sentence: Exhale.\n",
            "Decoded sentence: सासक करता है?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: क्या क्या?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: I'm OK.\n",
            "Decoded sentence: मैं कैं करता है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "-\n",
            "Input sentence: Inhale.\n",
            "Decoded sentence: संद करो।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Inhale.\n",
            "Decoded sentence: संद करो।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "-\n",
            "Input sentence: Thanks!\n",
            "Decoded sentence: बाहर करो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "-\n",
            "Input sentence: We won.\n",
            "Decoded sentence: हम कर करते हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: Awesome!\n",
            "Decoded sentence: बहुत बहुत कर को!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: Come in.\n",
            "Decoded sentence: किलो में बारहा।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Get out!\n",
            "Decoded sentence: बार्या हो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: Go away!\n",
            "Decoded sentence: क्या तुम हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: Goodbye!\n",
            "Decoded sentence: किलो में बारहीं हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Perfect!\n",
            "Decoded sentence: बार्या हो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "-\n",
            "Input sentence: Perfect!\n",
            "Decoded sentence: बार्या हो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: We lost.\n",
            "Decoded sentence: हम कर करते हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Welcome.\n",
            "Decoded sentence: बारो म बाहो।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "-\n",
            "Input sentence: Welcome.\n",
            "Decoded sentence: बारो म बाहो।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "-\n",
            "Input sentence: Have fun.\n",
            "Decoded sentence: मुझे पता है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Have fun.\n",
            "Decoded sentence: मुझे पता है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: Have fun.\n",
            "Decoded sentence: मुझे पता है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: I forgot.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: I forgot.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "-\n",
            "Input sentence: I'll pay.\n",
            "Decoded sentence: मैं हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: I'm fine.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "-\n",
            "Input sentence: I'm full.\n",
            "Decoded sentence: मैं कही है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "-\n",
            "Input sentence: Let's go!\n",
            "Decoded sentence: पलगती बाता।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: Pick Tom.\n",
            "Decoded sentence: बार्या हो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "-\n",
            "Input sentence: Answer me.\n",
            "Decoded sentence: हम को मुझे हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "-\n",
            "Input sentence: Birds fly.\n",
            "Decoded sentence: किस्ते मुझे हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Excuse me.\n",
            "Decoded sentence: किसके पास करते हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: Fantastic!\n",
            "Decoded sentence: बहुत कर्हो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "-\n",
            "Input sentence: I fainted.\n",
            "Decoded sentence: मैं अंग्ते हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: I fear so.\n",
            "Decoded sentence: मेरे किया बहा है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "-\n",
            "Input sentence: I laughed.\n",
            "Decoded sentence: मैं अच्छा रहता हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: I'm alone.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "-\n",
            "Input sentence: I'm alone.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: I'm bored.\n",
            "Decoded sentence: मैं आपरी हूँ ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "-\n",
            "Input sentence: I'm broke.\n",
            "Decoded sentence: मैं अंदर कर हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "-\n",
            "Input sentence: I'm tired.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "-\n",
            "Input sentence: It's cold.\n",
            "Decoded sentence: वह किता है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: Well done!\n",
            "Decoded sentence: बार्या हो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "-\n",
            "Input sentence: Who knows?\n",
            "Decoded sentence: किसके पास करते हैं?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "-\n",
            "Input sentence: Who knows?\n",
            "Decoded sentence: किसके पास करते हैं?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: Who knows?\n",
            "Decoded sentence: किसके पास करते हैं?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: Who knows?\n",
            "Decoded sentence: किसके पास करते हैं?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "-\n",
            "Input sentence: Wonderful!\n",
            "Decoded sentence: बार्या हो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "-\n",
            "Input sentence: Birds sing.\n",
            "Decoded sentence: किस्ते मुझे हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "-\n",
            "Input sentence: Come on in.\n",
            "Decoded sentence: किलो में बार करते हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: Definitely!\n",
            "Decoded sentence: बार्या हो  ह   ह     ह   ह                                   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: Don't move.\n",
            "Decoded sentence: पलो गत बहो।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "-\n",
            "Input sentence: Fire burns.\n",
            "Decoded sentence: कोग तुम बार करो।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: Follow him.\n",
            "Decoded sentence: वह किता है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "-\n",
            "Input sentence: I can swim.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "-\n",
            "Input sentence: I can swim.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "-\n",
            "Input sentence: I love you.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "-\n",
            "Input sentence: I love you.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: I love you.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "-\n",
            "Input sentence: I love you.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "-\n",
            "Input sentence: I love you.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "-\n",
            "Input sentence: I'm coming.\n",
            "Decoded sentence: मैं बहुत हूँ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "-\n",
            "Input sentence: I'm hungry!\n",
            "Decoded sentence: मैं कही हो गया है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "-\n",
            "Input sentence: I'm hungry!\n",
            "Decoded sentence: मैं कही हो गया है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "-\n",
            "Input sentence: Let him in.\n",
            "Decoded sentence: मेरे पार करते हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "-\n",
            "Input sentence: Let him in.\n",
            "Decoded sentence: मेरे पार करते हैं।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: Let me out!\n",
            "Decoded sentence: कम्या तुम क्या?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "-\n",
            "Input sentence: Once again.\n",
            "Decoded sentence: पलो मुझे पढ़ाओ।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: Please sit.\n",
            "Decoded sentence: बहुत बारहो हो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "-\n",
            "Input sentence: That a boy!\n",
            "Decoded sentence: बार्या हो!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: Tom smiled.\n",
            "Decoded sentence: वह किया है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "-\n",
            "Input sentence: Tom yawned.\n",
            "Decoded sentence: को को तुम्हें करत है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "-\n",
            "Input sentence: What's new?\n",
            "Decoded sentence: क्या क्या?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "-\n",
            "Input sentence: What's new?\n",
            "Decoded sentence: क्या क्या?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: Who's that?\n",
            "Decoded sentence: किसके कोसा हैं?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "-\n",
            "Input sentence: Don't shout.\n",
            "Decoded sentence: बहुत बहुत क्या?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "-\n",
            "Input sentence: Don't shout.\n",
            "Decoded sentence: बहुत बहुत क्या?\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: He stood up.\n",
            "Decoded sentence: वह किया है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "-\n",
            "Input sentence: He's strong.\n",
            "Decoded sentence: वह किया है।\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loop is used to test the trained sequence-to-sequence model on a subset of the input data to see how well it translates input sentences into output sentences. Here's a detailed explanation of the code:\n",
        "\n",
        "### Step-by-Step Breakdown:\n",
        "1. **Looping Through a Subset of Data**:\n",
        "   - The `for` loop iterates over a range of 90 input sequences (`range(90)`). This means that the loop will run 90 times, each time translating a different input sentence.\n",
        "   - Each `seq_index` represents the index of the sentence being decoded from the training set.\n",
        "\n",
        "2. **Preparing the Input Sequence**:\n",
        "   - `input_seq = encoder_input_data[seq_index: seq_index + 1]` extracts a single input sequence from `encoder_input_data`. The `seq_index: seq_index + 1` ensures that `input_seq` has a shape suitable for the model's input, maintaining a batch dimension (e.g., shape `(1, seq_length, num_encoder_tokens)`).\n",
        "\n",
        "3. **Decoding the Sentence**:\n",
        "   - `decoded_sentence = decode_sequence(input_seq)` calls the `decode_sequence()` function defined earlier.\n",
        "   - This function encodes the input sequence, runs the decoder in inference mode to generate the output sequence step by step, and returns the decoded sentence (in the target language).\n",
        "\n",
        "4. **Printing Results**:\n",
        "   - `print('-')` outputs a separator line to distinguish results for different sentences.\n",
        "   - `print('Input sentence:', input_texts[seq_index])` prints the original input sentence from `input_texts` for the current `seq_index`.\n",
        "   - `print('Decoded sentence:', decoded_sentence)` prints the translated sentence generated by the model.\n",
        "\n",
        "### What This Does in Practice:\n",
        "- For each input sentence in the range of 90 sentences:\n",
        "  - The code retrieves the one-hot encoded input data.\n",
        "  - It calls the `decode_sequence()` function to translate this input into a sentence in the target language using the trained encoder-decoder models.\n",
        "  - The original input and the corresponding decoded output are printed for comparison.\n",
        "\n",
        "### Purpose:\n",
        "- This step is useful for **evaluating the model's performance** on the training data and observing how accurately it translates sentences. It helps verify that the model is generating reasonable output sentences before testing on unseen data."
      ],
      "metadata": {
        "id": "Zzaqyi8W-dtp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IF GRU"
      ],
      "metadata": {
        "id": "t5R6mfxSBdRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#It's actually a bit simpler, because GRU has only one state, whereas LSTM has two states. Here's how to adapt the training model to use a GRU layer:\n",
        "\n",
        "\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = GRU(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h = encoder(encoder_inputs)\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_gru = GRU(latent_dim, return_sequences=True)\n",
        "decoder_outputs = decoder_gru(decoder_inputs, initial_state=state_h)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "#the change everywher to have only one state so remove state_c from everywhere\n",
        "\n",
        "# refer ref notebook for complete"
      ],
      "metadata": {
        "id": "RXlouAN-BfRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IF Word level translation has to be done"
      ],
      "metadata": {
        "id": "1lC5i2rVB9A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "x = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)#vocab now is the unique ka len and provide dimensiom to of latent dim\n",
        "x, state_h, state_c = LSTM(latent_dim,\n",
        "                           return_state=True)(x)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "x = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n",
        "x = LSTM(latent_dim, return_sequences=True)(x, initial_state=encoder_states)\n",
        "decoder_outputs = Dense(num_decoder_tokens, activation='softmax')(x)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile & run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "# Note that `decoder_target_data` needs to be one-hot encoded,\n",
        "# rather than sequences of integers like `decoder_input_data`!\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "id": "0HnuibHBCFdo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}