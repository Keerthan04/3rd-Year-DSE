{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvcc --version","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ijg2RD5dDXeJ","outputId":"37b5e73e-fe50-43e8-e3be-60b2a203c746","execution":{"iopub.status.busy":"2024-10-20T09:52:36.217393Z","iopub.execute_input":"2024-10-20T09:52:36.217693Z","iopub.status.idle":"2024-10-20T09:52:37.217304Z","shell.execute_reply.started":"2024-10-20T09:52:36.217661Z","shell.execute_reply":"2024-10-20T09:52:37.216361Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Wed_Nov_22_10:17:15_PST_2023\nCuda compilation tools, release 12.3, V12.3.107\nBuild cuda_12.3.r12.3/compiler.33567101_0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install nvcc4jupyter","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6wpcuilPD-gB","outputId":"c49fac12-e837-42f4-cab8-8aaf25e1ac28","execution":{"iopub.status.busy":"2024-10-20T09:52:40.758559Z","iopub.execute_input":"2024-10-20T09:52:40.759349Z","iopub.status.idle":"2024-10-20T09:52:53.218363Z","shell.execute_reply.started":"2024-10-20T09:52:40.759304Z","shell.execute_reply":"2024-10-20T09:52:53.217160Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting nvcc4jupyter\n  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\nDownloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\nInstalling collected packages: nvcc4jupyter\nSuccessfully installed nvcc4jupyter-1.2.1\n","output_type":"stream"}]},{"cell_type":"code","source":"%load_ext nvcc4jupyter","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H7OPjo-NEBoi","outputId":"23ebe5a7-23fa-4d0b-8b62-c466ea3892d5","execution":{"iopub.status.busy":"2024-10-20T09:52:55.518419Z","iopub.execute_input":"2024-10-20T09:52:55.519144Z","iopub.status.idle":"2024-10-20T09:54:51.075283Z","shell.execute_reply.started":"2024-10-20T09:52:55.519099Z","shell.execute_reply":"2024-10-20T09:54:51.074261Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Detected platform \"Kaggle\". Running its setup...\nUpdating the package lists...\nInstalling nvidia-cuda-toolkit, this may take a few minutes...\nSource files will be saved in \"/tmp/tmp9ohynh5m\".\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Week7 Codes","metadata":{}},{"cell_type":"markdown","source":"### q1","metadata":{}},{"cell_type":"code","source":"%%writefile cuda_program.cu\n#include <stdio.h>\n#include <cuda.h>\n\n__global__ void block_size_add(float *a, float *b, float *c) {\n    int i = blockIdx.x;\n    c[i] = a[i] + b[i];\n}\n\n__global__ void thread_add(float *a, float *b, float *c) {\n    int i = threadIdx.x;\n    c[i] = a[i] + b[i];\n}\n\n__global__ void varying_block_add(float *a, float *b, float *c, int n) {\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    if (i < n) c[i] = a[i] + b[i];\n}\n\nint main() {\n    int n = 10;\n    // Allocating and initializing memory\n    float a[10] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n    float b[10] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n    float c[10];\n    float *da, *db, *dc;\n\n    // Allocating device memory and transferring data to the device\n    cudaMalloc((void**)&da, n * sizeof(float));\n    cudaMalloc((void**)&db, n * sizeof(float));\n    cudaMalloc((void**)&dc, n * sizeof(float));\n    cudaMemcpy(da, a, n * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(db, b, n * sizeof(float), cudaMemcpyHostToDevice);\n\n    // Launching the block_size_add kernel\n    block_size_add<<<n, 1>>>(da, db, dc);\n    cudaMemcpy(c, dc, n * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"Block add result:\\n\");\n    for (int i = 0; i < n; i++) {\n        printf(\"%f \\n\", c[i]);\n    }\n\n    // Launching the thread_add kernel\n    thread_add<<<1, n>>>(da, db, dc);\n    cudaMemcpy(c, dc, n * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"Thread add result:\\n\");\n    for (int i = 0; i < n; i++) {\n        printf(\"%f \\n\", c[i]);\n    }\n\n    // Launching the varying_block_add kernel\n    varying_block_add<<<(n + 255) / 256, 256>>>(da, db, dc, n);\n    cudaMemcpy(c, dc, n * sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"Varying block add result:\\n\");\n    for (int i = 0; i < n; i++) {\n        printf(\"%f \\n\", c[i]);\n    }\n\n    // Freeing device memory\n    cudaFree(da);\n    cudaFree(db);\n    cudaFree(dc);\n\n    return 0;\n}\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMqa3OslEGKR","outputId":"8fa31a66-e557-431e-b178-829fbb667bbf","execution":{"iopub.status.busy":"2024-10-20T04:30:53.709743Z","iopub.execute_input":"2024-10-20T04:30:53.710496Z","iopub.status.idle":"2024-10-20T04:30:53.718021Z","shell.execute_reply.started":"2024-10-20T04:30:53.710449Z","shell.execute_reply":"2024-10-20T04:30:53.717158Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Overwriting cuda_program.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc cuda_program.cu -o cuda_program","metadata":{"id":"vJb621IgERA7","execution":{"iopub.status.busy":"2024-10-20T04:30:57.607694Z","iopub.execute_input":"2024-10-20T04:30:57.608620Z","iopub.status.idle":"2024-10-20T04:30:59.852334Z","shell.execute_reply.started":"2024-10-20T04:30:57.608578Z","shell.execute_reply":"2024-10-20T04:30:59.851056Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"!./cuda_program","metadata":{"execution":{"iopub.status.busy":"2024-10-20T04:31:02.187802Z","iopub.execute_input":"2024-10-20T04:31:02.188646Z","iopub.status.idle":"2024-10-20T04:31:03.350253Z","shell.execute_reply.started":"2024-10-20T04:31:02.188605Z","shell.execute_reply":"2024-10-20T04:31:03.349247Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Block add result:\n2.000000 \n4.000000 \n6.000000 \n8.000000 \n10.000000 \n12.000000 \n14.000000 \n16.000000 \n18.000000 \n20.000000 \nThread add result:\n2.000000 \n4.000000 \n6.000000 \n8.000000 \n10.000000 \n12.000000 \n14.000000 \n16.000000 \n18.000000 \n20.000000 \nVarying block add result:\n2.000000 \n4.000000 \n6.000000 \n8.000000 \n10.000000 \n12.000000 \n14.000000 \n16.000000 \n18.000000 \n20.000000 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### q2 ->pending","metadata":{}},{"cell_type":"markdown","source":"### q3","metadata":{}},{"cell_type":"code","source":"%%writefile cuda_program.cu\n#include <stdio.h>\n#include <cuda.h>\n\n__global__ void linearalgebra(int *x, int *y, int *c, int n, int m) {\n    int i = threadIdx.x;\n    if (i < n) {  // Ensure that the thread index is within bounds\n        c[i] = (m * x[i]) + y[i];\n    }\n}\n\nint main() {\n    int n = 10;\n    int x[10] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n    int y[10] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n    int c[10];\n    int m = 2;\n    int *d_x, *d_y, *d_c;\n\n    // Allocate memory on the device\n    cudaMalloc((void**)&d_x, n * sizeof(int));\n    cudaMalloc((void**)&d_y, n * sizeof(int));\n    cudaMalloc((void**)&d_c, n * sizeof(int));\n\n    // Copy data from host to device\n    cudaMemcpy(d_x, x, n * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_y, y, n * sizeof(int), cudaMemcpyHostToDevice);\n\n    // Launch the kernel with one block and n threads\n    linearalgebra<<<1, n>>>(d_x, d_y, d_c, n, m);\n\n    // Copy the result back to host memory\n    cudaMemcpy(c, d_c, n * sizeof(int), cudaMemcpyDeviceToHost);\n\n    // Print the result\n    printf(\"Result:\\n\");\n    for (int i = 0; i < n; i++) {\n        printf(\"%d \", c[i]);\n    }\n    printf(\"\\n\");\n\n    // Free the device memory\n    cudaFree(d_x);\n    cudaFree(d_y);\n    cudaFree(d_c);\n\n    return 0;\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T04:43:47.873255Z","iopub.execute_input":"2024-10-20T04:43:47.874413Z","iopub.status.idle":"2024-10-20T04:43:47.881851Z","shell.execute_reply.started":"2024-10-20T04:43:47.874364Z","shell.execute_reply":"2024-10-20T04:43:47.880821Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Overwriting cuda_program.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc -o cuda_program cuda_program.cu","metadata":{"execution":{"iopub.status.busy":"2024-10-20T04:43:55.007347Z","iopub.execute_input":"2024-10-20T04:43:55.007733Z","iopub.status.idle":"2024-10-20T04:43:57.332652Z","shell.execute_reply.started":"2024-10-20T04:43:55.007695Z","shell.execute_reply":"2024-10-20T04:43:57.331359Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"!./cuda_program","metadata":{"execution":{"iopub.status.busy":"2024-10-20T04:44:31.113554Z","iopub.execute_input":"2024-10-20T04:44:31.114387Z","iopub.status.idle":"2024-10-20T04:44:32.278289Z","shell.execute_reply.started":"2024-10-20T04:44:31.114340Z","shell.execute_reply":"2024-10-20T04:44:32.277178Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Result:\n3 6 9 12 15 18 21 24 27 30 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### q4","metadata":{}},{"cell_type":"code","source":"%%writefile q.cu\n#include <stdio.h>\n#include <cuda.h>\n#include <math.h>\n\n__global__ void sine_angle(float* angle, float* sine) {\n    int i = threadIdx.x;\n    sine[i] = sinf(angle[i]); // Calculate sine of the angle\n}\n\nint main() {\n    int n = 10;\n    float a[10] = {0.0, 0.5236, 0.7854, 1.0472, 1.5708, 2.0944, 2.3562, 2.6180, 3.1416, 4.7124};//radians of pi/4 and all\n    float b[n];\n    float *d_angle, *d_sine;\n\n    // Allocate memory on the device\n    cudaMalloc((void**)&d_angle, n * sizeof(float));\n    cudaMalloc((void**)&d_sine, n * sizeof(float));\n\n    // Copy the data from host to device\n    cudaMemcpy(d_angle, a, n * sizeof(float), cudaMemcpyHostToDevice);\n\n    // Launch the kernel with one block and n threads\n    sine_angle<<<1, n>>>(d_angle, d_sine);\n\n    // Copy the result back to host memory\n    cudaMemcpy(b, d_sine, n * sizeof(float), cudaMemcpyDeviceToHost);\n\n    // Display the sine values of the angles\n    printf(\"The sine of the angles in radians are:\\n\");\n    for (int i = 0; i < n; i++) {\n        printf(\"sin(%f) = %f\\n\", a[i], b[i]);\n    }\n\n    // Free the device memory\n    cudaFree(d_angle);\n    cudaFree(d_sine);\n\n    return 0;\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T04:56:16.170946Z","iopub.execute_input":"2024-10-20T04:56:16.171703Z","iopub.status.idle":"2024-10-20T04:56:16.179145Z","shell.execute_reply.started":"2024-10-20T04:56:16.171650Z","shell.execute_reply":"2024-10-20T04:56:16.178119Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Writing q.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc -o q q.cu","metadata":{"execution":{"iopub.status.busy":"2024-10-20T04:56:40.333403Z","iopub.execute_input":"2024-10-20T04:56:40.333817Z","iopub.status.idle":"2024-10-20T04:56:42.625486Z","shell.execute_reply.started":"2024-10-20T04:56:40.333781Z","shell.execute_reply":"2024-10-20T04:56:42.624199Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"!./q","metadata":{"execution":{"iopub.status.busy":"2024-10-20T04:56:51.907777Z","iopub.execute_input":"2024-10-20T04:56:51.908466Z","iopub.status.idle":"2024-10-20T04:56:53.083957Z","shell.execute_reply.started":"2024-10-20T04:56:51.908415Z","shell.execute_reply":"2024-10-20T04:56:53.082920Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"The sine of the angles in radians are:\nsin(0.000000) = 0.000000\nsin(0.523600) = 0.500001\nsin(0.785400) = 0.707108\nsin(1.047200) = 0.866027\nsin(1.570800) = 1.000000\nsin(2.094400) = 0.866023\nsin(2.356200) = 0.707103\nsin(2.618000) = 0.499995\nsin(3.141600) = -0.000007\nsin(4.712400) = -1.000000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## week 8","metadata":{}},{"cell_type":"markdown","source":"### q1","metadata":{}},{"cell_type":"code","source":"%%writefile q.cu\n#include <stdio.h>\n#include <cuda.h>\n#include <string.h>\n\n__global__ void n_times(char *string, char *result, int string_len, int n) {\n    int i = threadIdx.x; // Each thread handles a character in the string\n    if (i < string_len) {\n        for (int j = 0; j < n; j++) {\n            result[j * string_len + i] = string[i]; // Copy each character n times\n        }\n    }\n}\n\nint main() {\n    char string[] = \"hello\";\n    int n = 3;\n    int string_len = strlen(string);\n    char result[3 * 5 + 1] = {0}; // +1 to accommodate the null terminator\n    char *d_string, *d_result;\n\n    // Allocate memory on the device\n    cudaMalloc((void**)&d_string, string_len * sizeof(char));\n    cudaMalloc((void**)&d_result, n * string_len * sizeof(char));\n\n    // Copy the string to device memory\n    cudaMemcpy(d_string, string, string_len * sizeof(char), cudaMemcpyHostToDevice);\n\n    // Launch the kernel with string_len threads\n    n_times<<<1, string_len>>>(d_string, d_result, string_len, n);\n\n    // Copy the result back to the host\n    cudaMemcpy(result, d_result, n * string_len * sizeof(char), cudaMemcpyDeviceToHost);\n\n    // Add a null terminator to the result\n    result[n * string_len] = '\\0';\n\n    printf(\"Result is:\\n%s\\n\", result);\n\n    // Free the device memory\n    cudaFree(d_string);\n    cudaFree(d_result);\n\n    return 0;\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T05:32:11.073017Z","iopub.execute_input":"2024-10-20T05:32:11.073435Z","iopub.status.idle":"2024-10-20T05:32:11.081291Z","shell.execute_reply.started":"2024-10-20T05:32:11.073393Z","shell.execute_reply":"2024-10-20T05:32:11.080329Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Overwriting q.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc -o q q.cu","metadata":{"execution":{"iopub.status.busy":"2024-10-20T05:32:12.807128Z","iopub.execute_input":"2024-10-20T05:32:12.807952Z","iopub.status.idle":"2024-10-20T05:32:15.079114Z","shell.execute_reply.started":"2024-10-20T05:32:12.807912Z","shell.execute_reply":"2024-10-20T05:32:15.077897Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"!./q","metadata":{"execution":{"iopub.status.busy":"2024-10-20T05:32:16.326929Z","iopub.execute_input":"2024-10-20T05:32:16.327906Z","iopub.status.idle":"2024-10-20T05:32:17.510110Z","shell.execute_reply.started":"2024-10-20T05:32:16.327861Z","shell.execute_reply":"2024-10-20T05:32:17.509068Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Result is:\nhellohellohello\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### q2","metadata":{}},{"cell_type":"code","source":"%%writefile q.cu\n#include <stdio.h>\n#include <cuda.h>\n#include <string.h>\n\n__global__ void rev_words_parallel(char* str, char* rev_str, int* words, int num_words, int str_length) {\n    int i = threadIdx.x;\n    if (i < num_words) { // Check for boundary\n        int start = words[i];\n        int end = (i == num_words - 1) ? str_length : words[i + 1]; // End of current word\n\n        // Reverse the current word\n        for (int x = start; x < end; x++) {\n            rev_str[start + (end - 1 - x)] = str[x]; // Reverse the word\n        }\n        rev_str[end] = ' '; // Add a space after each reversed word\n    }\n}\n\nint main() {\n    char str[] = \"my name is keerthan\";\n    char rev_str[100] = {0}; // Initialize to zero\n    int words[5]; // Enough to hold indices for 4 words + 1\n    int num_words = 0;\n\n    words[num_words++] = 0; // Start of the first word\n    // Fill words array with indices of spaces\n    for (int x = 0; x < strlen(str); x++) {\n        if (str[x] == ' ') {\n            words[num_words++] = x + 1; // Store the index of the character after the space\n        }\n    }\n    words[num_words++] = strlen(str); // End index for the last word\n\n    char *d_str, *d_rev_str;\n    int *d_words;\n\n    // Allocate memory on the device\n    cudaMalloc((void**)&d_str, strlen(str) * sizeof(char));\n    cudaMalloc((void**)&d_rev_str, strlen(str) * sizeof(char));\n    cudaMalloc((void**)&d_words, num_words * sizeof(int));\n\n    // Copy the string and words to device memory\n    cudaMemcpy(d_str, str, strlen(str) * sizeof(char), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_words, words, num_words * sizeof(int), cudaMemcpyHostToDevice);\n\n    // Launch the kernel with enough threads for the number of words\n    rev_words_parallel<<<1, num_words>>>(d_str, d_rev_str, d_words, num_words, strlen(str));\n\n    // Copy the result back to the host\n    cudaMemcpy(rev_str, d_rev_str, strlen(str) * sizeof(char), cudaMemcpyDeviceToHost);\n\n    // Add null terminator at the end, remove the last space\n    rev_str[strlen(str)] = '\\0';\n\n    printf(\"The reversed words string is:\\n\");\n    printf(\"%s\\n\", rev_str);\n\n    // Free device memory\n    cudaFree(d_str);\n    cudaFree(d_rev_str);\n    cudaFree(d_words);\n    \n    return 0;\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T06:58:12.007953Z","iopub.execute_input":"2024-10-20T06:58:12.008383Z","iopub.status.idle":"2024-10-20T06:58:12.016408Z","shell.execute_reply.started":"2024-10-20T06:58:12.008340Z","shell.execute_reply":"2024-10-20T06:58:12.015377Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"Overwriting q.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc -o q q.cu","metadata":{"execution":{"iopub.status.busy":"2024-10-20T06:58:12.967140Z","iopub.execute_input":"2024-10-20T06:58:12.967519Z","iopub.status.idle":"2024-10-20T06:58:15.225683Z","shell.execute_reply.started":"2024-10-20T06:58:12.967484Z","shell.execute_reply":"2024-10-20T06:58:15.224619Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"!./q","metadata":{"execution":{"iopub.status.busy":"2024-10-20T06:58:16.647250Z","iopub.execute_input":"2024-10-20T06:58:16.648051Z","iopub.status.idle":"2024-10-20T06:58:17.789108Z","shell.execute_reply.started":"2024-10-20T06:58:16.648006Z","shell.execute_reply":"2024-10-20T06:58:17.788018Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"The reversed words string is:\n ym eman si ahtreek\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### q3","metadata":{}},{"cell_type":"code","source":"%%writefile q.cu\n#include <stdio.h>\n#include <cuda.h>\n#include <string.h>\n\n// Kernel function to count the occurrence of a specific word\n__global__ void count_word(char *str, char *word, int *count, int words[]) {\n    int i = threadIdx.x;\n    int start = words[i];\n    int end = words[i + 1] - 1;\n    int j = 0;\n\n    for (int x = start; x < end; x++) {\n        if (str[x] != word[j]) {\n            return; // If any character does not match, return immediately\n        }\n        j++;\n    }\n    atomicAdd(count, 1); // Increase count atomically if a word match is found\n}\n\nint main() {\n    char str[] = \"wise man is wise man\";\n    char word[] = \"wise\";\n    int words[10] = {0}; // Adjusted array size to handle more words\n    int count = 0; // Corrected to an integer variable instead of a pointer\n    int i = 0;\n\n    // Finding the positions of words in the string\n    for (int x = 0; x < strlen(str); x++) {\n        if (str[x] == ' ') {\n            i = i + 1;\n            words[i] = x + 1; // Storing the location of the next word's start\n        }\n    }\n    i = i + 1;\n    words[i] = strlen(str) + 1;\n\n    // Device memory pointers\n    char *d_str, *d_word;\n    int *d_words;\n    int *d_count;\n\n    // Allocate device memory\n    cudaMalloc((void**)&d_str, (strlen(str) + 1) * sizeof(char));\n    cudaMalloc((void**)&d_word, (strlen(word) + 1) * sizeof(char));\n    cudaMalloc((void**)&d_words, (i + 1) * sizeof(int));\n    cudaMalloc((void**)&d_count, sizeof(int));\n\n    // Copy data to device memory\n    cudaMemcpy(d_str, str, (strlen(str) + 1) * sizeof(char), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_word, word, (strlen(word) + 1) * sizeof(char), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_words, words, (i + 1) * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemset(d_count, 0, sizeof(int)); // Initialize count to zero on the device\n\n    // Launch the kernel\n    count_word<<<1, i>>>(d_str, d_word, d_count, d_words);\n\n    // Copy the result back to host memory\n    cudaMemcpy(&count, d_count, sizeof(int), cudaMemcpyDeviceToHost);\n\n    printf(\"The number of occurrences of the word '%s' is: %d\\n\", word, count);\n\n    // Free device memory\n    cudaFree(d_str);\n    cudaFree(d_word);\n    cudaFree(d_words);\n    cudaFree(d_count);\n\n    return 0;\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:24:28.769222Z","iopub.execute_input":"2024-10-20T10:24:28.769819Z","iopub.status.idle":"2024-10-20T10:24:28.778123Z","shell.execute_reply.started":"2024-10-20T10:24:28.769775Z","shell.execute_reply":"2024-10-20T10:24:28.777166Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Overwriting q.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc -o q q.cu","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:24:30.998182Z","iopub.execute_input":"2024-10-20T10:24:30.999048Z","iopub.status.idle":"2024-10-20T10:24:33.218564Z","shell.execute_reply.started":"2024-10-20T10:24:30.999009Z","shell.execute_reply":"2024-10-20T10:24:33.216810Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"!./q","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:24:50.238899Z","iopub.execute_input":"2024-10-20T10:24:50.239866Z","iopub.status.idle":"2024-10-20T10:24:51.409284Z","shell.execute_reply.started":"2024-10-20T10:24:50.239822Z","shell.execute_reply":"2024-10-20T10:24:51.408031Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"The number of occurrences of the word 'wise' is: 2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### q4\nnormal reverse string so not doing","metadata":{}},{"cell_type":"markdown","source":"# Week 9","metadata":{}},{"cell_type":"markdown","source":"### q1","metadata":{}},{"cell_type":"code","source":"%%writefile q.cu\n#include<stdio.h>\n#include<cuda.h>\n#include<math.h>\n\n__global__ void replace_matrix(int *matrix,int width){\n    //when we have matrix we take it as array and do like this and passed as 1 block with mxn threads in 2d\n    int i = threadIdx.x;\n    int j = threadIdx.y;\n    if(i==0){\n        return;\n    }\n    if (i < width && j < width) {\n        matrix[i * width + j] = pow(matrix[i * width + j],i+1);//row major access\n    }\n}\nint main(){\n    int matrix[16] = {1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16};\n    int width = 4;\n    int *d_matrix;\n    cudaMalloc((void**)&d_matrix, 16 * sizeof(int));\n    cudaMemcpy(d_matrix, matrix, 16 * sizeof(int), cudaMemcpyHostToDevice);\n    replace_matrix<<<1,dim3(width,width)>>>(d_matrix, width);//it is a 4x4 matrix i.e actually taken m and n\n    cudaMemcpy(matrix,d_matrix,16*sizeof(int),cudaMemcpyDeviceToHost);\n    printf(\"the resultant matrix is \\n\");\n    for(int i=0;i<width;i++){\n        for(int j=0;j<width;j++){\n            printf(\"%d \",matrix[i*width+j]);\n        }\n        printf(\"\\n\");\n    }\n    cudaFree(d_matrix);\n    return 0;\n}","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:41:27.699277Z","iopub.execute_input":"2024-10-20T10:41:27.700230Z","iopub.status.idle":"2024-10-20T10:41:27.707089Z","shell.execute_reply.started":"2024-10-20T10:41:27.700186Z","shell.execute_reply":"2024-10-20T10:41:27.706170Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Overwriting q.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc -o q q.cu\n!./q","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:41:29.077885Z","iopub.execute_input":"2024-10-20T10:41:29.078252Z","iopub.status.idle":"2024-10-20T10:41:32.471146Z","shell.execute_reply.started":"2024-10-20T10:41:29.078216Z","shell.execute_reply":"2024-10-20T10:41:32.469958Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"the resultant matrix is \n1 2 3 4 \n25 36 49 64 \n729 1000 1331 1728 \n28561 38416 50625 65536 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### q2","metadata":{}},{"cell_type":"code","source":"%%writefile q.cu\n#include<stdio.h>\n#include<cuda.h>\n#include<math.h>\n\n__global__ void row_add(int *m,int *n,int *sum,int row,int col){\n    int i= threadIdx.x;//this is the row number\n    for(int j=0;j<col;j++){\n        sum[i*col+j]=m[i*col+j]+n[i*col+j];//adding using row major\n    }\n}\n__global__ void column_add(int *m,int *n,int *sum,int row,int col){\n    int i=threadIdx.x;//this is x but is passed as no of columns so\n    for(int j=0;j<row;j++){\n        sum[i*row+j]=m[i*row+j]+n[i*row+j];//adding using column major\n    }\n}\n\n__global__ void one_thread_add(int *m,int *n,int *sum,int row,int col){\n    int i=threadIdx.x;\n    int j=threadIdx.y;\n    sum[i*row+j]=m[i*row+j]+n[i*row+j];//doing one thread addition\n}\n\nint main(){\n    int matrix1[9] = {1,2,3,4,5,6,7,8,9};\n    int matrix2[9] = {1,2,3,4,5,6,7,8,9};\n    int matrix3[9];\n    int *d_matrix1;\n    int *d_matrix2;\n    int *d_matrix3;\n    cudaMalloc((void**)&d_matrix1, 9 * sizeof(int));\n    cudaMalloc((void**)&d_matrix2, 9 * sizeof(int));\n    cudaMalloc((void**)&d_matrix3, 9 * sizeof(int));\n    cudaMemcpy(d_matrix1, matrix1, 9 * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_matrix2, matrix2, 9 * sizeof(int), cudaMemcpyHostToDevice);\n    row_add<<<1,3>>>(d_matrix1,d_matrix2,d_matrix3,3,3);//here 3 is row\n    cudaMemcpy(matrix3,d_matrix3,9*sizeof(int),cudaMemcpyDeviceToHost);\n    printf(\"the resultant matrix by row add is \\n\");\n    for(int i=0;i<3;i++){\n        for(int j=0;j<3;j++){\n            printf(\"%d \",matrix3[i*3+j]);\n        }\n        printf(\"\\n\");\n    }\n    column_add<<<1,3>>>(d_matrix1,d_matrix2,d_matrix3,3,3);//here 3 is col\n    cudaMemcpy(matrix3,d_matrix3,9*sizeof(int),cudaMemcpyDeviceToHost);\n    printf(\"the resultant matrix by col add is \\n\");\n    for(int i=0;i<3;i++){\n        for(int j=0;j<3;j++){\n            printf(\"%d \",matrix3[i*3+j]);\n        }\n        printf(\"\\n\");\n    }\n    one_thread_add<<<1,dim3(3,3)>>>(d_matrix1,d_matrix2,d_matrix3,3,3);//here passed as 1 block with dim3\n    cudaMemcpy(matrix3,d_matrix3,9*sizeof(int),cudaMemcpyDeviceToHost);\n    printf(\"the resultant matrix by one thread addition is \\n\");\n    for(int i=0;i<3;i++){\n        for(int j=0;j<3;j++){\n            printf(\"%d \",matrix3[i*3+j]);\n        }\n        printf(\"\\n\");\n    }\n    cudaFree(d_matrix3);\n    cudaFree(d_matrix1);\n    cudaFree(d_matrix2);\n    return 0;\n}","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:54:52.760203Z","iopub.execute_input":"2024-10-20T10:54:52.761186Z","iopub.status.idle":"2024-10-20T10:54:52.769139Z","shell.execute_reply.started":"2024-10-20T10:54:52.761141Z","shell.execute_reply":"2024-10-20T10:54:52.768304Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Overwriting q.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc -o q q.cu\n!./q","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:54:53.919403Z","iopub.execute_input":"2024-10-20T10:54:53.919891Z","iopub.status.idle":"2024-10-20T10:54:57.325902Z","shell.execute_reply.started":"2024-10-20T10:54:53.919831Z","shell.execute_reply":"2024-10-20T10:54:57.324729Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"the resultant matrix by row add is \n2 4 6 \n8 10 12 \n14 16 18 \nthe resultant matrix by col add is \n2 4 6 \n8 10 12 \n14 16 18 \nthe resultant matrix by one thread addition is \n2 4 6 \n8 10 12 \n14 16 18 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### q3","metadata":{}},{"cell_type":"code","source":"%%writefile q.cu\n#include <stdio.h>\n#include <cuda.h>\n\n// Kernel for row-wise matrix multiplication\n__global__ void row_multiply(int *m, int *n, int *product, int row, int col, int common_dim) {\n    int i = threadIdx.x; // Row index\n    for (int j = 0; j < col; j++) { // Loop over columns of the result matrix\n        int sum = 0;\n        for (int k = 0; k < common_dim; k++) { // Loop over the shared dimension\n            sum += m[i * common_dim + k] * n[k * col + j];\n        }\n        product[i * col + j] = sum;\n    }\n}\n\n// Kernel for column-wise matrix multiplication\n__global__ void column_multiply(int *m, int *n, int *product, int row, int col, int common_dim) {\n    int j = threadIdx.x; // Column index\n    for (int i = 0; i < row; i++) { // Loop over rows of the result matrix\n        int sum = 0;\n        for (int k = 0; k < common_dim; k++) { // Loop over the shared dimension\n            sum += m[i * common_dim + k] * n[k * col + j];\n        }\n        product[i * col + j] = sum;\n    }\n}\n\n// Kernel for matrix multiplication using one thread per element\n__global__ void one_thread_multiply(int *m, int *n, int *product, int row, int col, int common_dim) {\n    int i = threadIdx.x; // Row index\n    int j = threadIdx.y; // Column index\n    int sum = 0;\n    for (int k = 0; k < common_dim; k++) { // Loop over the shared dimension\n        sum += m[i * common_dim + k] * n[k * col + j];\n    }\n    product[i * col + j] = sum;\n}\n\nint main() {\n    int matrix1[9] = {1, 2, 3, 4, 5, 6, 7, 8, 9};  // 3x3 matrix\n    int matrix2[9] = {9, 8, 7, 6, 5, 4, 3, 2, 1};  // 3x3 matrix\n    int matrix3[9];  // Resultant matrix\n\n    int *d_matrix1, *d_matrix2, *d_matrix3;\n    cudaMalloc((void**)&d_matrix1, 9 * sizeof(int));\n    cudaMalloc((void**)&d_matrix2, 9 * sizeof(int));\n    cudaMalloc((void**)&d_matrix3, 9 * sizeof(int));\n\n    cudaMemcpy(d_matrix1, matrix1, 9 * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_matrix2, matrix2, 9 * sizeof(int), cudaMemcpyHostToDevice);\n\n    // Row-wise matrix multiplication\n    row_multiply<<<1, 3>>>(d_matrix1, d_matrix2, d_matrix3, 3, 3, 3);\n    cudaMemcpy(matrix3, d_matrix3, 9 * sizeof(int), cudaMemcpyDeviceToHost);\n    printf(\"The resultant matrix by row-wise multiplication is:\\n\");\n    for (int i = 0; i < 3; i++) {\n        for (int j = 0; j < 3; j++) {\n            printf(\"%d \", matrix3[i * 3 + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    // Column-wise matrix multiplication\n    column_multiply<<<1, 3>>>(d_matrix1, d_matrix2, d_matrix3, 3, 3, 3);\n    cudaMemcpy(matrix3, d_matrix3, 9 * sizeof(int), cudaMemcpyDeviceToHost);\n    printf(\"The resultant matrix by column-wise multiplication is:\\n\");\n    for (int i = 0; i < 3; i++) {\n        for (int j = 0; j < 3; j++) {\n            printf(\"%d \", matrix3[i * 3 + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    // One thread per element matrix multiplication\n    one_thread_multiply<<<1, dim3(3, 3)>>>(d_matrix1, d_matrix2, d_matrix3, 3, 3, 3);\n    cudaMemcpy(matrix3, d_matrix3, 9 * sizeof(int), cudaMemcpyDeviceToHost);\n    printf(\"The resultant matrix by one thread multiplication is:\\n\");\n    for (int i = 0; i < 3; i++) {\n        for (int j = 0; j < 3; j++) {\n            printf(\"%d \", matrix3[i * 3 + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    cudaFree(d_matrix1);\n    cudaFree(d_matrix2);\n    cudaFree(d_matrix3);\n\n    return 0;\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T11:07:27.539948Z","iopub.execute_input":"2024-10-20T11:07:27.540892Z","iopub.status.idle":"2024-10-20T11:07:27.550066Z","shell.execute_reply.started":"2024-10-20T11:07:27.540845Z","shell.execute_reply":"2024-10-20T11:07:27.548980Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Overwriting q.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc -o q q.cu\n!./q","metadata":{"execution":{"iopub.status.busy":"2024-10-20T11:07:37.288454Z","iopub.execute_input":"2024-10-20T11:07:37.289113Z","iopub.status.idle":"2024-10-20T11:07:40.784664Z","shell.execute_reply.started":"2024-10-20T11:07:37.289072Z","shell.execute_reply":"2024-10-20T11:07:40.783676Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"The resultant matrix by row-wise multiplication is:\n30 24 18 \n84 69 54 \n138 114 90 \nThe resultant matrix by column-wise multiplication is:\n30 24 18 \n84 69 54 \n138 114 90 \nThe resultant matrix by one thread multiplication is:\n30 24 18 \n84 69 54 \n138 114 90 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### q4","metadata":{}},{"cell_type":"code","source":"%%writefile q.cu\n#include <stdio.h>\n#include <cuda.h>\n\n// CUDA kernel to compute 1's complement for non-border elements\n__global__ void complement(int *a, int rows, int cols) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    int row = idx / cols;\n    int col = idx % cols;//just for easy way to check the for non border ele\n\n    // Check if the element is a non-border element\n    if (row == 0 || row == rows - 1 || col == 0 || col == cols - 1) return;\n\n    // Calculate the smallest power of 2 greater than the value of a[idx]\n    int pow2 = 1;\n    while (pow2 <= a[idx]) pow2 *= 2;\n\n    // Perform the 1's complement operation\n    int complementValue = a[idx] ^ (pow2 - 1);//taking pow2-1 as mask and do bitwise xor we get\n\n    // Convert the 1's complement value to its binary representation (in decimal format)\n    int binary = 0, offset = 1;\n    while (complementValue > 0) {\n        binary += (complementValue % 2) * offset;\n        offset *= 10;\n        complementValue /= 2;\n    }\n\n    // Store the binary representation back into the matrix\n    a[idx] = binary;\n}\n\nint main() {\n    // Define the dimensions of the matrix\n    int rows = 4;\n    int cols = 4;\n\n    // Example matrix A of size 4x4\n    int h_matrix[] = {\n        1, 2, 3, 4,\n        6, 5, 8, 3,\n        2, 4, 10,1,\n        9, 1, 2, 5\n    };\n\n    int size = rows * cols * sizeof(int);\n\n    // Allocate device memory for the matrix\n    int *d_matrix;\n    cudaMalloc((void**)&d_matrix, size);\n\n    // Copy the matrix from host to device\n    cudaMemcpy(d_matrix, h_matrix, size, cudaMemcpyHostToDevice);\n\n    // Launch the kernel with one thread per element\n    complement<<<1, rows * cols>>>(d_matrix, rows, cols);\n\n    // Copy the result back to the host\n    cudaMemcpy(h_matrix, d_matrix, size, cudaMemcpyDeviceToHost);\n\n    // Display the resultant matrix\n    printf(\"Resultant matrix with 1's complement for non-border elements:\\n\");\n    for (int i = 0; i < rows; i++) {\n        for (int j = 0; j < cols; j++) {\n            printf(\"%d\\t\", h_matrix[i * cols + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    // Free device memory\n    cudaFree(d_matrix);\n\n    return 0;\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T11:18:29.998703Z","iopub.execute_input":"2024-10-20T11:18:29.999116Z","iopub.status.idle":"2024-10-20T11:18:30.006843Z","shell.execute_reply.started":"2024-10-20T11:18:29.999077Z","shell.execute_reply":"2024-10-20T11:18:30.005882Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Overwriting q.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc -o q q.cu\n!./q\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T11:18:30.817334Z","iopub.execute_input":"2024-10-20T11:18:30.817710Z","iopub.status.idle":"2024-10-20T11:18:34.250571Z","shell.execute_reply.started":"2024-10-20T11:18:30.817674Z","shell.execute_reply":"2024-10-20T11:18:34.249330Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Resultant matrix with 1's complement for non-border elements:\n1\t2\t3\t4\t\n6\t10\t111\t3\t\n2\t11\t101\t1\t\n9\t1\t2\t5\t\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Week 10","metadata":{}},{"cell_type":"markdown","source":"### q1","metadata":{}},{"cell_type":"code","source":"%%writefile q.cu\n#include <stdio.h>\n#include <cuda.h>\n\n// CUDA kernel for matrix multiplication\n__global__ void matrix_multiply(int *a, int *b, int *c, int width) {\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (row < width && col < width) {\n        int sum = 0;\n        for (int i = 0; i < width; i++) {\n            sum += a[row * width + i] * b[i * width + col];\n        }\n        c[row * width + col] = sum;\n    }\n}\n\nint main() {\n    int width = 4;\n    int a[16] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16};\n    int b[16] = {16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1};\n    int c[16];\n\n    int *d_a, *d_b, *d_c;\n    cudaMalloc((void**)&d_a, width * width * sizeof(int));\n    cudaMalloc((void**)&d_b, width * width * sizeof(int));\n    cudaMalloc((void**)&d_c, width * width * sizeof(int));\n\n    cudaMemcpy(d_a, a, width * width * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, b, width * width * sizeof(int), cudaMemcpyHostToDevice);\n\n    // Define a 2D block and grid size for matrix multiplication\n    dim3 block(2, 2, 1);  // 2x2 threads per block\n    //dim3 grid((width + block.x - 1) / block.x, (width + block.y - 1) / block.y, 1);->is one way else\n    dim3 grid(ceil(width / 2.0), ceil(width / 2.0), 1);\n\n    // Launch the kernel\n    matrix_multiply<<<grid, block>>>(d_a, d_b, d_c, width);\n\n    // Copy the result back to the host\n    cudaMemcpy(c, d_c, width * width * sizeof(int), cudaMemcpyDeviceToHost);\n\n    // Print the resultant matrix\n    printf(\"The resultant matrix is:\\n\");\n    for (int i = 0; i < width; i++) {\n        for (int j = 0; j < width; j++) {\n            printf(\"%d \", c[i * width + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    // Free device memory\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    return 0;\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T11:55:38.497594Z","iopub.execute_input":"2024-10-20T11:55:38.498336Z","iopub.status.idle":"2024-10-20T11:55:38.506779Z","shell.execute_reply.started":"2024-10-20T11:55:38.498293Z","shell.execute_reply":"2024-10-20T11:55:38.505774Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Overwriting q.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc -o q q.cu\n!./q","metadata":{"execution":{"iopub.status.busy":"2024-10-20T11:55:39.695798Z","iopub.execute_input":"2024-10-20T11:55:39.696704Z","iopub.status.idle":"2024-10-20T11:55:43.093215Z","shell.execute_reply.started":"2024-10-20T11:55:39.696657Z","shell.execute_reply":"2024-10-20T11:55:43.092089Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"The resultant matrix is:\n80 70 60 50 \n240 214 188 162 \n400 358 316 274 \n560 502 444 386 \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}